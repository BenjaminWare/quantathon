{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6519862f-8a25-4029-baef-c87cf6111efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-30 12:43:01,711\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-03-30 12:43:02,042\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import math\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import LSTM, NHITS, RNN, MLP, Informer, FEDformer,StemGNN,NBEATSx\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import AutoARIMA,MSTL\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "from neuralforecast.auto import AutoNHITS\n",
    "import matplotlib.pyplot as plt\n",
    "from neuralforecast.losses.pytorch import HuberLoss\n",
    "from ray import tune\n",
    "from datetime import datetime\n",
    "from datetime import date, timedelta\n",
    "\n",
    "from ray import tune\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.auto import AutoNHITS, AutoLSTM\n",
    "from neuralforecast.losses.pytorch import MQLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89387f41-ab10-4b2a-ba9a-837fdda31547",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pd.read_csv('data/DAL_data.csv')\n",
    "oil = pd.read_csv('data/CLF_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "538b4a8a-9a75-44a8-a210-85bf4c57b8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-03-24</td>\n",
       "      <td>33.110001</td>\n",
       "      <td>33.529999</td>\n",
       "      <td>32.520000</td>\n",
       "      <td>33.320000</td>\n",
       "      <td>29.590050</td>\n",
       "      <td>11289700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-03-25</td>\n",
       "      <td>33.459999</td>\n",
       "      <td>34.509998</td>\n",
       "      <td>33.459999</td>\n",
       "      <td>34.430000</td>\n",
       "      <td>30.575798</td>\n",
       "      <td>11544300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-03-26</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>34.549999</td>\n",
       "      <td>33.910000</td>\n",
       "      <td>33.959999</td>\n",
       "      <td>30.158407</td>\n",
       "      <td>12058800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-03-27</td>\n",
       "      <td>33.900002</td>\n",
       "      <td>34.290001</td>\n",
       "      <td>32.970001</td>\n",
       "      <td>34.130001</td>\n",
       "      <td>30.309376</td>\n",
       "      <td>11952200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-03-28</td>\n",
       "      <td>34.139999</td>\n",
       "      <td>34.689999</td>\n",
       "      <td>33.509998</td>\n",
       "      <td>33.529999</td>\n",
       "      <td>29.776543</td>\n",
       "      <td>10434900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close    Volume\n",
       "0  2014-03-24  33.110001  33.529999  32.520000  33.320000  29.590050  11289700\n",
       "1  2014-03-25  33.459999  34.509998  33.459999  34.430000  30.575798  11544300\n",
       "2  2014-03-26  34.500000  34.549999  33.910000  33.959999  30.158407  12058800\n",
       "3  2014-03-27  33.900002  34.290001  32.970001  34.130001  30.309376  11952200\n",
       "4  2014-03-28  34.139999  34.689999  33.509998  33.529999  29.776543  10434900"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e97827-2664-4fc6-b2c6-8c5ce01957ea",
   "metadata": {},
   "source": [
    "## turn the data into format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d958c090-3253-4755-9b4d-8b52637911a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = oil[['Date', 'Adj Close']]\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.rename(columns={'Date': 'ds', 'Adj Close': 'y'})\n",
    "df['unique_id'] = 0\n",
    "df = df.set_index('ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9106c88b-ddb5-47a2-abf4-42ab70d374c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-03-24</th>\n",
       "      <td>99.599998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-25</th>\n",
       "      <td>99.190002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-26</th>\n",
       "      <td>100.260002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-27</th>\n",
       "      <td>101.279999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-28</th>\n",
       "      <td>101.669998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-18</th>\n",
       "      <td>82.720001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-19</th>\n",
       "      <td>83.470001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-20</th>\n",
       "      <td>81.680000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-21</th>\n",
       "      <td>81.070000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-22</th>\n",
       "      <td>80.629997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2517 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     y  unique_id\n",
       "ds                               \n",
       "2014-03-24   99.599998          0\n",
       "2014-03-25   99.190002          0\n",
       "2014-03-26  100.260002          0\n",
       "2014-03-27  101.279999          0\n",
       "2014-03-28  101.669998          0\n",
       "...                ...        ...\n",
       "2024-03-18   82.720001          0\n",
       "2024-03-19   83.470001          0\n",
       "2024-03-20   81.680000          0\n",
       "2024-03-21   81.070000          0\n",
       "2024-03-22   80.629997          0\n",
       "\n",
       "[2517 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "08b464b6-afca-4e31-8925-e101335aa032",
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_features = pd.read_feather('oil_features')\n",
    "features_df = df.join(oil_features).drop(columns=['Date']).iloc[:-48].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b5a2973c-307d-47f6-836b-4010c833ebd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>U.S. Field Production of Crude Oil (Thousand Barrels per Day)</th>\n",
       "      <th>spy</th>\n",
       "      <th>dji</th>\n",
       "      <th>ndq</th>\n",
       "      <th>eur</th>\n",
       "      <th>DHHNGSP</th>\n",
       "      <th>DCOILBRENTEU</th>\n",
       "      <th>DCOILWTICO</th>\n",
       "      <th>DFF</th>\n",
       "      <th>RTWEXBGS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-03-24</th>\n",
       "      <td>99.599998</td>\n",
       "      <td>0</td>\n",
       "      <td>8296.0</td>\n",
       "      <td>154.965622</td>\n",
       "      <td>16276.690430</td>\n",
       "      <td>4226.390137</td>\n",
       "      <td>0.72487</td>\n",
       "      <td>4.42</td>\n",
       "      <td>106.59</td>\n",
       "      <td>100.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>89.9367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-25</th>\n",
       "      <td>99.190002</td>\n",
       "      <td>0</td>\n",
       "      <td>8296.0</td>\n",
       "      <td>155.701050</td>\n",
       "      <td>16367.879883</td>\n",
       "      <td>4234.270020</td>\n",
       "      <td>0.72260</td>\n",
       "      <td>4.53</td>\n",
       "      <td>107.01</td>\n",
       "      <td>99.66</td>\n",
       "      <td>0.09</td>\n",
       "      <td>89.9367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-26</th>\n",
       "      <td>100.260002</td>\n",
       "      <td>0</td>\n",
       "      <td>8296.0</td>\n",
       "      <td>154.581177</td>\n",
       "      <td>16268.990234</td>\n",
       "      <td>4173.580078</td>\n",
       "      <td>0.72364</td>\n",
       "      <td>4.44</td>\n",
       "      <td>105.90</td>\n",
       "      <td>100.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>89.9367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-27</th>\n",
       "      <td>101.279999</td>\n",
       "      <td>0</td>\n",
       "      <td>8296.0</td>\n",
       "      <td>154.255234</td>\n",
       "      <td>16264.230469</td>\n",
       "      <td>4151.229980</td>\n",
       "      <td>0.72558</td>\n",
       "      <td>4.39</td>\n",
       "      <td>106.58</td>\n",
       "      <td>101.25</td>\n",
       "      <td>0.08</td>\n",
       "      <td>89.9367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-28</th>\n",
       "      <td>101.669998</td>\n",
       "      <td>0</td>\n",
       "      <td>8296.0</td>\n",
       "      <td>155.015732</td>\n",
       "      <td>16323.059570</td>\n",
       "      <td>4155.759766</td>\n",
       "      <td>0.72773</td>\n",
       "      <td>4.50</td>\n",
       "      <td>106.64</td>\n",
       "      <td>101.73</td>\n",
       "      <td>0.08</td>\n",
       "      <td>89.9367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-08</th>\n",
       "      <td>70.769997</td>\n",
       "      <td>0</td>\n",
       "      <td>13295.0</td>\n",
       "      <td>473.129974</td>\n",
       "      <td>37683.011719</td>\n",
       "      <td>14843.769531</td>\n",
       "      <td>0.91389</td>\n",
       "      <td>2.72</td>\n",
       "      <td>75.47</td>\n",
       "      <td>71.06</td>\n",
       "      <td>5.33</td>\n",
       "      <td>114.2542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-09</th>\n",
       "      <td>72.239998</td>\n",
       "      <td>0</td>\n",
       "      <td>13295.0</td>\n",
       "      <td>472.412201</td>\n",
       "      <td>37525.160156</td>\n",
       "      <td>14857.709961</td>\n",
       "      <td>0.91310</td>\n",
       "      <td>3.25</td>\n",
       "      <td>77.97</td>\n",
       "      <td>72.43</td>\n",
       "      <td>5.33</td>\n",
       "      <td>114.2542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10</th>\n",
       "      <td>71.370003</td>\n",
       "      <td>0</td>\n",
       "      <td>13295.0</td>\n",
       "      <td>475.083893</td>\n",
       "      <td>37695.730469</td>\n",
       "      <td>14969.650391</td>\n",
       "      <td>0.91471</td>\n",
       "      <td>3.25</td>\n",
       "      <td>78.46</td>\n",
       "      <td>71.57</td>\n",
       "      <td>5.33</td>\n",
       "      <td>114.2542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-11</th>\n",
       "      <td>72.019997</td>\n",
       "      <td>0</td>\n",
       "      <td>13295.0</td>\n",
       "      <td>474.874542</td>\n",
       "      <td>37711.019531</td>\n",
       "      <td>14970.190430</td>\n",
       "      <td>0.91115</td>\n",
       "      <td>3.15</td>\n",
       "      <td>80.21</td>\n",
       "      <td>72.15</td>\n",
       "      <td>5.33</td>\n",
       "      <td>114.2542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-12</th>\n",
       "      <td>72.680000</td>\n",
       "      <td>0</td>\n",
       "      <td>13295.0</td>\n",
       "      <td>475.203522</td>\n",
       "      <td>37592.980469</td>\n",
       "      <td>14972.759766</td>\n",
       "      <td>0.91061</td>\n",
       "      <td>13.20</td>\n",
       "      <td>79.89</td>\n",
       "      <td>72.94</td>\n",
       "      <td>5.33</td>\n",
       "      <td>114.2542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2426 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     y  unique_id  \\\n",
       "ds                                  \n",
       "2014-03-24   99.599998          0   \n",
       "2014-03-25   99.190002          0   \n",
       "2014-03-26  100.260002          0   \n",
       "2014-03-27  101.279999          0   \n",
       "2014-03-28  101.669998          0   \n",
       "...                ...        ...   \n",
       "2024-01-08   70.769997          0   \n",
       "2024-01-09   72.239998          0   \n",
       "2024-01-10   71.370003          0   \n",
       "2024-01-11   72.019997          0   \n",
       "2024-01-12   72.680000          0   \n",
       "\n",
       "            U.S. Field Production of Crude Oil (Thousand Barrels per Day)  \\\n",
       "ds                                                                          \n",
       "2014-03-24                                             8296.0               \n",
       "2014-03-25                                             8296.0               \n",
       "2014-03-26                                             8296.0               \n",
       "2014-03-27                                             8296.0               \n",
       "2014-03-28                                             8296.0               \n",
       "...                                                       ...               \n",
       "2024-01-08                                            13295.0               \n",
       "2024-01-09                                            13295.0               \n",
       "2024-01-10                                            13295.0               \n",
       "2024-01-11                                            13295.0               \n",
       "2024-01-12                                            13295.0               \n",
       "\n",
       "                   spy           dji           ndq      eur  DHHNGSP  \\\n",
       "ds                                                                     \n",
       "2014-03-24  154.965622  16276.690430   4226.390137  0.72487     4.42   \n",
       "2014-03-25  155.701050  16367.879883   4234.270020  0.72260     4.53   \n",
       "2014-03-26  154.581177  16268.990234   4173.580078  0.72364     4.44   \n",
       "2014-03-27  154.255234  16264.230469   4151.229980  0.72558     4.39   \n",
       "2014-03-28  155.015732  16323.059570   4155.759766  0.72773     4.50   \n",
       "...                ...           ...           ...      ...      ...   \n",
       "2024-01-08  473.129974  37683.011719  14843.769531  0.91389     2.72   \n",
       "2024-01-09  472.412201  37525.160156  14857.709961  0.91310     3.25   \n",
       "2024-01-10  475.083893  37695.730469  14969.650391  0.91471     3.25   \n",
       "2024-01-11  474.874542  37711.019531  14970.190430  0.91115     3.15   \n",
       "2024-01-12  475.203522  37592.980469  14972.759766  0.91061    13.20   \n",
       "\n",
       "            DCOILBRENTEU  DCOILWTICO   DFF  RTWEXBGS  \n",
       "ds                                                    \n",
       "2014-03-24        106.59      100.05  0.09   89.9367  \n",
       "2014-03-25        107.01       99.66  0.09   89.9367  \n",
       "2014-03-26        105.90      100.61  0.08   89.9367  \n",
       "2014-03-27        106.58      101.25  0.08   89.9367  \n",
       "2014-03-28        106.64      101.73  0.08   89.9367  \n",
       "...                  ...         ...   ...       ...  \n",
       "2024-01-08         75.47       71.06  5.33  114.2542  \n",
       "2024-01-09         77.97       72.43  5.33  114.2542  \n",
       "2024-01-10         78.46       71.57  5.33  114.2542  \n",
       "2024-01-11         80.21       72.15  5.33  114.2542  \n",
       "2024-01-12         79.89       72.94  5.33  114.2542  \n",
       "\n",
       "[2426 rows x 12 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ac5738cb-bea2-465b-b5e1-6ab7309dd228",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a768b79-536e-41ac-9d31-a56be649db74",
   "metadata": {},
   "source": [
    "## create NeuralForecast class, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "73fda14e-36a4-46eb-bc18-269f9f0b82c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_samples recommended above 20\n",
    "# nf = NeuralForecast(\n",
    "#     models=[\n",
    "#         NHITS(h=7, loss=MQLoss()),\n",
    "#         # AutoLSTM(h=7, loss=MQLoss(), num_samples=2),\n",
    "#     ],\n",
    "#     freq='D'\n",
    "# )\n",
    "\n",
    "config_nhits = {\n",
    "    \"input_size\": tune.choice([7, 7*2, 7*3]),              # Length of input window\n",
    "    \"start_padding_enabled\": True,\n",
    "    \"n_freq_downsample\": tune.choice([[8, 4, 2, 1, 1],\n",
    "                                      [1, 1, 1, 1, 1]]),            # Interpolation expressivity ratios\n",
    "    \"learning_rate\": tune.loguniform(1e-4, 1e-2),                   # Initial Learning rate\n",
    "    \"scaler_type\": tune.choice(['robust']),                             # Scaler type\n",
    "    \"random_seed\": tune.randint(1, 5),                             # Random seed\n",
    "}\n",
    "horizon = 1 # day-ahead daily forecast\n",
    "models = [AutoNHITS(h=7, config=config_nhits, loss=HuberLoss(),  num_samples=20)]\n",
    "# hist_exog_list = features_df.drop(columns=['ds', 'y', 'unique_id']).columns,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b4a4f83f-083f-4f98-b291-9e1d86ae2c48",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=41747)\u001b[0m Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930]       \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900]        \n",
      "Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.53it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830]\n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900]        \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650]        \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490]        \n",
      "Epoch 79: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.95it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.490]\n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600]        \n",
      "Epoch 85: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.44it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570]\n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530]        \n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.15it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.500]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 403.07it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=1.310]       \n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=1.310]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=1.310]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=1.310]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=1.310]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=1.310]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=1.310]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=1.310]        \n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=1.310]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=1.310]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=1.310]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=1.310]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=1.310]        \n",
      "Epoch 126: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.58it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=1.310]\n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=1.310]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=1.310]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=1.310]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=1.310]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=1.310]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=1.310]        \n",
      "Epoch 138: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.72it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=1.310]\n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=1.310]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=1.310]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=1.310]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=1.310]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=1.310]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=1.310]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=1.310]        \n",
      "Epoch 154: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.36it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.310]\n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.310]        \n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=1.310]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=1.310]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=1.310]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.310]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.310]        \n",
      "Epoch 164: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.38it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=1.310]\n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=1.310]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=1.310]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.310]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=1.310]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=1.310]        \n",
      "Epoch 173: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.74it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=1.310]\n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.991, train_loss_epoch=0.991, valid_loss=1.310]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.310]        \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=1.310]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=1.310]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.310]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.310]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=1.310]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=1.310]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=1.310]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=1.310]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940, valid_loss=1.310]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=1.310]        \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=0.878, valid_loss=1.310]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.87it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.878, valid_loss=1.310]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 411.97it/s]\u001b[A\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=2.800]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=2.800]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=0.876, valid_loss=2.800]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956, valid_loss=2.800]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.912, train_loss_epoch=0.912, valid_loss=2.800]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.844, train_loss_epoch=0.844, valid_loss=2.800]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=2.800]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=2.800]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=2.800]        \n",
      "Epoch 219: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.98it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905, valid_loss=2.800]\n",
      "Epoch 219: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.26it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873, valid_loss=2.800]\n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873, valid_loss=2.800]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.884, valid_loss=2.800]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=0.937, valid_loss=2.800]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=2.800]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=0.851, valid_loss=2.800]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.826, train_loss_epoch=0.826, valid_loss=2.800]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.833, train_loss_epoch=0.833, valid_loss=2.800]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.875, train_loss_epoch=0.875, valid_loss=2.800]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.821, train_loss_epoch=0.821, valid_loss=2.800]        \n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.830, valid_loss=2.800]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806, valid_loss=2.800]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854, valid_loss=2.800]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=2.800]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.821, train_loss_epoch=0.821, valid_loss=2.800]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=2.800]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.785, train_loss_epoch=0.785, valid_loss=2.800]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.785, train_loss_epoch=0.785, valid_loss=2.800]\n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.891, train_loss_epoch=0.891, valid_loss=2.800]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806, valid_loss=2.800]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=2.800]        \n",
      "Epoch 255: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.74it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=0.914, valid_loss=2.800]\n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=0.889, valid_loss=2.800]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=2.800]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860, valid_loss=2.800]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873, valid_loss=2.800]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.775, train_loss_epoch=0.775, valid_loss=2.800]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=2.800]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737, valid_loss=2.800]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.747, valid_loss=2.800]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=2.800]        \n",
      "Epoch 272: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.25it/s, v_num=0, train_loss_step=0.736, train_loss_epoch=0.797, valid_loss=2.800]\n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.736, train_loss_epoch=0.736, valid_loss=2.800]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759, valid_loss=2.800]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780, valid_loss=2.800]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=2.800]        \n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.738, train_loss_epoch=0.738, valid_loss=2.800]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724, valid_loss=2.800]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.755, train_loss_epoch=0.755, valid_loss=2.800]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.717, train_loss_epoch=0.717, valid_loss=2.800]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.713, train_loss_epoch=0.713, valid_loss=2.800]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.766, valid_loss=2.800]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.728, train_loss_epoch=0.728, valid_loss=2.800]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=2.800]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=2.800]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=2.800]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.13it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.674, valid_loss=2.800]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 403.22it/s]\u001b[A\n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719, valid_loss=2.380]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.768, train_loss_epoch=0.768, valid_loss=2.380]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=2.380]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704, valid_loss=2.380]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704, valid_loss=2.380]        \n",
      "Epoch 309: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.00it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=2.380]\n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=2.380]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.750, train_loss_epoch=0.750, valid_loss=2.380]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.753, train_loss_epoch=0.753, valid_loss=2.380]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=2.380]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.721, train_loss_epoch=0.721, valid_loss=2.380]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.753, train_loss_epoch=0.753, valid_loss=2.380]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.696, train_loss_epoch=0.696, valid_loss=2.380]        \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=2.380]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=2.380]        \n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=2.380]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=2.380]        \n",
      "Epoch 329: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.75it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=2.380]\n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=2.380]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=2.380]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=2.380]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=2.380]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.666, train_loss_epoch=0.666, valid_loss=2.380]        \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=2.380]        \n",
      "Epoch 339: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.65it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=2.380]\n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=2.380]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=2.380]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=2.380]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.633, train_loss_epoch=0.633, valid_loss=2.380]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.640, train_loss_epoch=0.640, valid_loss=2.380]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=2.380]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=2.380]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=2.380]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=2.380]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=2.380]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=2.380]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=2.380]        \n",
      "Epoch 361: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.04it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=2.380]\n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=2.380]        \n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=2.380]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=2.380]        \n",
      "Epoch 365: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.12it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.613, valid_loss=2.380]\n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=2.380]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=2.380]        \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=2.380]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597, valid_loss=2.380]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=2.380]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=2.380]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=2.380]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=2.380]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=2.380]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=2.380]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=2.380]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=2.380]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=2.380]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=2.380]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=2.380]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=2.380]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=2.380]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=2.380]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.62it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.576, valid_loss=2.380]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 388.65it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=2.940]        \n",
      "Epoch 401: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.00it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=2.940]\n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=2.940]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=2.940]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=2.940]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=2.940]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=2.940]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=2.940]        \n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=2.940]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=2.940]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=2.940]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=2.940]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=2.940]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=2.940]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=2.940]        \n",
      "Epoch 426: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.15it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.552, valid_loss=2.940]\n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=2.940]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=2.940]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=2.940]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=2.940]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=2.940]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=2.940]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=2.940]        \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=2.940]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=2.940]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=2.940]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=2.940]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=2.940]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=2.940]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=2.940]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=2.940]        \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=2.940]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=2.940]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=2.940]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=2.940]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=2.940]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=2.940]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=2.940]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=2.940]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=2.940]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=2.940]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=2.940]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=2.940]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=2.940]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=2.940]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=2.940]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=2.940]        \n",
      "Epoch 483: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.91it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=2.940]\n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=2.940]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=2.940]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=2.940]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=2.940]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=2.940]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=2.940]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=2.940]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=2.940]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=2.940]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.25it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.488, valid_loss=2.940]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 397.30it/s]\u001b[A\n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=2.660]        \n",
      "Epoch 502: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.49it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=2.660]\n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=2.660]        \n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=2.660]        \n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=2.660]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=2.660]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=2.660]        \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=2.660]        \n",
      "Epoch 512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.11it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.495, valid_loss=2.660]\n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=2.660]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=2.660]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=2.660]        \n",
      "Epoch 518: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.60it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.525, valid_loss=2.660]\n",
      "Epoch 518: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.12it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=2.660]\n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=2.660]        \n",
      "Epoch 520: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.58it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.523, valid_loss=2.660]\n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=2.660]        \n",
      "Epoch 522: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.83it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=2.660]\n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=2.660]        \n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=2.660]        \n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=2.660]        \n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=2.660]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=2.660]        \n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=2.660]\n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=2.660]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=2.660]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=2.660]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=2.660]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=2.660]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=2.660]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=2.660]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=2.660]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=2.660]        \n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=2.660]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=2.660]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=2.660]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=2.660]        \n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=2.660]        \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=2.660]        \n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=2.660]        \n",
      "Epoch 561: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.31it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.462, valid_loss=2.660]\n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=2.660]        \n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=2.660]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=2.660]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=2.660]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=2.660]        \n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=2.660]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=2.660]        \n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=2.660]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=2.660]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=2.660]        \n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=2.660]        \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=2.660]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=2.660]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=2.660]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=2.660]        \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=2.660]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=2.660]        \n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=2.660]        \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=2.660]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=2.660]        \n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=2.660]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.35it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.466, valid_loss=2.660]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 380.78it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=3.340]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=3.340]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=3.340]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=3.340]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=3.340]        \n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=3.340]        \n",
      "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=3.340]        \n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=3.340]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=3.340]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=3.340]        \n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=3.340]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=3.340]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=3.340]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=3.340]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=3.340]        \n",
      "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=3.340]        \n",
      "Epoch 628: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.36it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.446, valid_loss=3.340]\n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=3.340]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=3.340]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=3.340]        \n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=3.340]        \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=3.340]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=3.340]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=3.340]        \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=3.340]        \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=3.340]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=3.340]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=3.340]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=3.340]        \n",
      "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=3.340]        \n",
      "Epoch 653: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.13it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=3.340]\n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=3.340]        \n",
      "Epoch 655: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.36it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=3.340]\n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=3.340]        \n",
      "Epoch 657: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.56it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.465, valid_loss=3.340]\n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=3.340]        \n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=3.340]        \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=3.340]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=3.340]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=3.340]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=3.340]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=3.340]        \n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=3.340]        \n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=3.340]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=3.340]        \n",
      "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=3.340]        \n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=3.340]        \n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=3.340]        \n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=3.340]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=3.340]        \n",
      "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=3.340]        \n",
      "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=3.340]        \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=3.340]        \n",
      "Epoch 690: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.39it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=3.340]\n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=3.340]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=3.340]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=3.340]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=3.340]        \n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=3.340]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 24.74it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.390, valid_loss=3.340]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 396.66it/s]\u001b[A\n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=2.900]        \n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=2.900]        \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=2.900]        \n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=2.900]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=2.900]        \n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=2.900]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.391, valid_loss=2.900]        \n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=2.900]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=2.900]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=2.900]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=2.900]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=2.900]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=2.900]        \n",
      "Epoch 724: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.98it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.406, valid_loss=2.900]\n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.391, valid_loss=2.900]        \n",
      "Epoch 726: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.89it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=2.900]\n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=2.900]        \n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=2.900]        \n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=2.900]        \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=2.900]        \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=2.900]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=2.900]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=2.900]        \n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=2.900]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=2.900]        \n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=2.900]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=2.900]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=2.900]        \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=2.900]        \n",
      "Epoch 750: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.96it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.390, valid_loss=2.900]\n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=2.900]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=2.900]        \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=2.900]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=2.900]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=2.900]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=2.900]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=2.900]        \n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=2.900]        \n",
      "Epoch 765: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.96it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.363, valid_loss=2.900]\n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=2.900]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=2.900]        \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=2.900]        \n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=2.900]        \n",
      "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=2.900]        \n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=2.900]        \n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=2.900]        \n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=2.900]        \n",
      "Epoch 780: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.53it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=2.900]\n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=2.900]        \n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=2.900]        \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=2.900]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=2.900]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=2.900]        \n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=2.900]        \n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=2.900]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=2.900]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=2.900]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=2.900]        \n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=2.900]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.76it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.385, valid_loss=2.900]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 380.50it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=2.840]        \n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=2.840]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=2.840]        \n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=2.840]        \n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=2.840]        \n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=2.840]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=2.840]        \n",
      "Epoch 813: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.79it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.388, valid_loss=2.840]\n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=2.840]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=2.840]\n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=2.840]        \n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=2.840]        \n",
      "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=2.840]        \n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=2.840]        \n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=2.840]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=2.840]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=2.840]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=2.840]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=2.840]        \n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=2.840]        \n",
      "Epoch 833: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.99it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.398, valid_loss=2.840]\n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=2.840]        \n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=2.840]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=2.840]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=2.840]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=2.840]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=2.840]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=2.840]        \n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=2.840]        \n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=2.840]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=2.840]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=2.840]        \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=2.840]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=2.840]        \n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=2.840]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=2.840]        \n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=2.840]        \n",
      "Epoch 860: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.31it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=2.840]\n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=2.840]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=2.840]        \n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=2.840]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=2.840]        \n",
      "Epoch 866: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.69it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.365, valid_loss=2.840]\n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=2.840]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=2.840]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=2.840]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=2.840]        \n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=2.840]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=2.840]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=2.840]        \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=2.840]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=2.840]        \n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=2.840]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=2.840]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=2.840]        \n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=2.840]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=2.840]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=2.840]        \n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=2.840]        \n",
      "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=2.840]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=2.840]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=2.840]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.09it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.348, valid_loss=2.840]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 393.43it/s]\u001b[A\n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=2.940]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=2.940]        \n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=2.940]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=2.940]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=2.940]        \n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=2.940]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=2.940]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=2.940]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=2.940]        \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=2.940]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=2.940]        \n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=2.940]        \n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=2.940]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=2.940]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=2.940]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=2.940]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=2.940]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=2.940]        \n",
      "Epoch 933: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.05it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=2.940]\n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=2.940]        \n",
      "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=2.940]        \n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=2.940]        \n",
      "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=2.940]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=2.940]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=2.940]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=2.940]        \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=2.940]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=2.940]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=2.940]        \n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=2.940]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=2.940]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=2.940]        \n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=2.940]        \n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=2.940]        \n",
      "Epoch 958: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.28it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=2.940]\n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=2.940]        \n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=2.940]        \n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=2.940]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=2.940]        \n",
      "Epoch 963: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.16it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=2.940]\n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=2.940]        \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=2.940]        \n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=2.940]        \n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=2.940]        \n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=2.940]        \n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=2.940]        \n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=2.940]        \n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=2.940]        \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=2.940]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=2.940]        \n",
      "Epoch 979: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.12it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=2.940]\n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=2.940]        \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=2.940]        \n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=2.940]        \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=2.940]        \n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=2.940]        \n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=2.940]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=2.940]        \n",
      "Epoch 992: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.12it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=2.940]\n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=2.940]        \n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=2.940]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=2.940]        \n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=2.940]        \n",
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=2.940]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.19it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.360, valid_loss=2.940]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=41747)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=41747)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=41747)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 364.85it/s]\u001b[A\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.24it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.060]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=42259)\u001b[0m Seed set to 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.270, train_loss_epoch=8.270]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=90.20, train_loss_epoch=90.20]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.170, train_loss_epoch=7.170]        \n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.670, train_loss_epoch=3.670]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430]        \n",
      "Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.79it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430]\n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]        \n",
      "Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.33it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]\n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 76: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.07it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.100]\n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.87it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.020]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 397.45it/s]\u001b[A\n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.379]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.379]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=0.941, valid_loss=0.379]        \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.379]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.379]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=0.379]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.944, train_loss_epoch=0.944, valid_loss=0.379]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=0.379]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.907, train_loss_epoch=0.907, valid_loss=0.379]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942, valid_loss=0.379]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=0.379]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=0.379]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=0.379]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=0.379]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.379]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.379]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=0.932, valid_loss=0.379]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=0.379]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=0.968, valid_loss=0.379]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=0.968, valid_loss=0.379]\n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=0.923, valid_loss=0.379]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.934, train_loss_epoch=0.934, valid_loss=0.379]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=0.879, valid_loss=0.379]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.898, train_loss_epoch=0.898, valid_loss=0.379]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870, valid_loss=0.379]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=0.379]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870, valid_loss=0.379]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905, valid_loss=0.379]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873, valid_loss=0.379]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=0.894, valid_loss=0.379]        \n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.832, train_loss_epoch=0.832, valid_loss=0.379]        \n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.849, valid_loss=0.379]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854, valid_loss=0.379]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=0.379]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850, valid_loss=0.379]        \n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.853, train_loss_epoch=0.853, valid_loss=0.379]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=0.379]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.795, train_loss_epoch=0.795, valid_loss=0.379]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=0.846, valid_loss=0.379]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=0.379]        \n",
      "Epoch 171: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.10it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.874, valid_loss=0.379]\n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=0.379]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.833, train_loss_epoch=0.833, valid_loss=0.379]        \n",
      "Epoch 175: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.63it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=0.889, valid_loss=0.379]\n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.889, train_loss_epoch=0.889, valid_loss=0.379]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=0.379]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.840, train_loss_epoch=0.840, valid_loss=0.379]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=0.819, valid_loss=0.379]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.818, train_loss_epoch=0.818, valid_loss=0.379]        \n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=0.799, valid_loss=0.379]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.821, train_loss_epoch=0.821, valid_loss=0.379]        \n",
      "Epoch 188: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.03it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.783, valid_loss=0.379]\n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.783, valid_loss=0.379]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.790, train_loss_epoch=0.790, valid_loss=0.379]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.783, valid_loss=0.379]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.769, valid_loss=0.379]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.732, train_loss_epoch=0.732, valid_loss=0.379]        \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=0.379]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.62it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.838, valid_loss=0.379]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 370.23it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.766, valid_loss=1.350]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.828, train_loss_epoch=0.828, valid_loss=1.350]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.769, valid_loss=1.350]        \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.745, train_loss_epoch=0.745, valid_loss=1.350]        \n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=0.762, valid_loss=1.350]        \n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.716, valid_loss=1.350]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.800, train_loss_epoch=0.800, valid_loss=1.350]        \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737, valid_loss=1.350]        \n",
      "Epoch 214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.92it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737, valid_loss=1.350]\n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.769, valid_loss=1.350]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741, valid_loss=1.350]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.779, train_loss_epoch=0.779, valid_loss=1.350]        \n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=1.350]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=1.350]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.771, train_loss_epoch=0.771, valid_loss=1.350]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.722, train_loss_epoch=0.722, valid_loss=1.350]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737, valid_loss=1.350]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.723, train_loss_epoch=0.723, valid_loss=1.350]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=1.350]        \n",
      "Epoch 231: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.32it/s, v_num=0, train_loss_step=0.745, train_loss_epoch=0.745, valid_loss=1.350]\n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.745, train_loss_epoch=0.745, valid_loss=1.350]        \n",
      "Epoch 233: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.04it/s, v_num=0, train_loss_step=0.782, train_loss_epoch=0.792, valid_loss=1.350]\n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.782, train_loss_epoch=0.782, valid_loss=1.350]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.764, train_loss_epoch=0.764, valid_loss=1.350]        \n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.774, train_loss_epoch=0.774, valid_loss=1.350]        \n",
      "Epoch 239: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.20it/s, v_num=0, train_loss_step=0.792, train_loss_epoch=0.728, valid_loss=1.350]\n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.792, train_loss_epoch=0.792, valid_loss=1.350]        \n",
      "Epoch 241: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.79it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=1.350]\n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=1.350]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.723, train_loss_epoch=0.723, valid_loss=1.350]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678, valid_loss=1.350]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.731, train_loss_epoch=0.731, valid_loss=1.350]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.729, train_loss_epoch=0.729, valid_loss=1.350]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.713, train_loss_epoch=0.713, valid_loss=1.350]        \n",
      "Epoch 251: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.57it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.680, valid_loss=1.350]\n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.680, valid_loss=1.350]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=1.350]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=1.350]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=1.350]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=1.350]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.710, train_loss_epoch=0.710, valid_loss=1.350]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746, valid_loss=1.350]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=1.350]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.710, train_loss_epoch=0.710, valid_loss=1.350]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=1.350]        \n",
      "Epoch 267: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.33it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.747, valid_loss=1.350]\n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.747, valid_loss=1.350]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.720, train_loss_epoch=0.720, valid_loss=1.350]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719, valid_loss=1.350]        \n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=1.350]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.717, train_loss_epoch=0.717, valid_loss=1.350]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=1.350]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.671, train_loss_epoch=0.671, valid_loss=1.350]        \n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.701, train_loss_epoch=0.701, valid_loss=1.350]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=1.350]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=1.350]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=1.350]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=1.350]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=1.350]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=1.350]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=1.350]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=1.350]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=1.350]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=1.350]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.72it/s, v_num=0, train_loss_step=0.647, train_loss_epoch=0.674, valid_loss=1.350]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 378.38it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.647, train_loss_epoch=0.647, valid_loss=1.600]        \n",
      "Epoch 300: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.03it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.647, valid_loss=1.600]\n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=1.600]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=1.600]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=1.600]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=1.600]        \n",
      "Epoch 306: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.48it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=1.600]\n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=1.600]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.636, train_loss_epoch=0.636, valid_loss=1.600]        \n",
      "Epoch 308: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.46it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.636, valid_loss=1.600]\n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=1.600]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=1.600]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=1.600]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=1.600]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=1.600]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=1.600]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=1.600]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.612, train_loss_epoch=0.612, valid_loss=1.600]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=1.600]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=1.600]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=1.600]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=1.600]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=1.600]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.624, train_loss_epoch=0.624, valid_loss=1.600]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=1.600]        \n",
      "Epoch 332: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.05it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=1.600]\n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=1.600]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=1.600]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=1.600]        \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=1.600]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=1.600]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=1.600]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=1.600]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=1.600]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=1.600]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=1.600]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=1.600]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=1.600]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=1.600]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=1.600]        \n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=1.600]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=1.600]        \n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=1.600]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=1.600]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=1.600]        \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=1.600]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=1.600]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=1.600]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=1.600]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=1.600]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=1.600]        \n",
      "Epoch 380: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.92it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.449, valid_loss=1.600]\n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=1.600]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=1.600]        \n",
      "Epoch 384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.84it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=1.600]\n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=1.600]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=1.600]        \n",
      "Epoch 386: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.81it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.436, valid_loss=1.600]\n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=1.600]        \n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=1.600]        \n",
      "Epoch 390: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.55it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=1.600]\n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=1.600]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=1.600]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=1.600]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=1.600]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=1.600]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.56it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.412, valid_loss=1.600]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 378.75it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=1.450]        \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=1.450]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=1.450]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=1.450]        \n",
      "Epoch 405: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.97it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.440, valid_loss=1.450]\n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=1.450]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=1.450]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=1.450]        \n",
      "Epoch 411: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.65it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=1.450]\n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=1.450]        \n",
      "Epoch 413: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.03it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=1.450]\n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=1.450]        \n",
      "Epoch 415: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.74it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=1.450]\n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=1.450]        \n",
      "Epoch 417: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.07it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=1.450]\n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=1.450]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=1.450]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=1.450]        \n",
      "Epoch 423: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.62it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=1.450]\n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=1.450]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=1.450]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=1.450]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=1.450]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=1.450]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=1.450]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=1.450]        \n",
      "Epoch 435: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.74it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=1.450]\n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=1.450]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=1.450]        \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=1.450]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=1.450]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=1.450]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=1.450]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=1.450]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=1.450]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=1.450]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=1.450]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=1.450]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=1.450]\n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=1.450]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=1.450]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=1.450]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=1.450]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=1.450]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=1.450]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=1.450]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=1.450]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=1.450]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=1.450]        \n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=1.450]        \n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=1.450]        \n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=1.450]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=1.450]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=1.450]        \n",
      "Epoch 477: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.54it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=1.450]\n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=1.450]        \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=1.450]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=1.450]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=1.450]        \n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=1.450]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=1.450]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=1.450]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=1.450]        \n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=1.450]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=1.450]        \n",
      "Epoch 493: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.26it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=1.450]\n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=1.450]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=1.450]        \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417, valid_loss=1.450]        \n",
      "Epoch 498: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.13it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.381, valid_loss=1.450]\n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=1.450]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.42it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.418, valid_loss=1.450]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 302.03it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=2.070]        \n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=2.070]        \n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=2.070]        \n",
      "Epoch 502: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.49it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=2.070]\n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=2.070]        \n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=2.070]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=2.070]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=2.070]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=2.070]        \n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=2.070]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=2.070]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=2.070]        \n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=2.070]        \n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=2.070]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=2.070]        \n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=2.070]        \n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=2.070]        \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=2.070]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=2.070]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=2.070]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=2.070]        \n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=2.070]        \n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=2.070]        \n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=2.070]        \n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=2.070]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=2.070]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=2.070]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=2.070]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=2.070]        \n",
      "Epoch 545: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.47it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=2.070]\n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=2.070]        \n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=2.070]        \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=2.070]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=2.070]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=2.070]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=2.070]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=2.070]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=2.070]        \n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=2.070]        \n",
      "Epoch 561: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.41it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=2.070]\n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=2.070]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=2.070]        \n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=2.070]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=2.070]        \n",
      "Epoch 566: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.56it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=2.070]\n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=2.070]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=2.070]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=2.070]        \n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=2.070]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=2.070]        \n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=2.070]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=2.070]        \n",
      "Epoch 577: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.75it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.388, valid_loss=2.070]\n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=2.070]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=2.070]        \n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=2.070]        \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=2.070]        \n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=2.070]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=2.070]        \n",
      "Epoch 588: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.83it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=2.070]\n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=2.070]        \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=2.070]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=2.070]        \n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=2.070]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=2.070]        \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=2.070]        \n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=2.070]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.66it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.347, valid_loss=2.070]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 308.63it/s]\u001b[A\n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=1.910]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=1.910]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=1.910]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=1.910]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=1.910]        \n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=1.910]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=1.910]        \n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=1.910]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=1.910]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=1.910]        \n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=1.910]        \n",
      "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=1.910]        \n",
      "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=1.910]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=1.910]        \n",
      "Epoch 623: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.34it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=1.910]\n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=1.910]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=1.910]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=1.910]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=1.910]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=1.910]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=1.910]        \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=1.910]        \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=1.910]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=1.910]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=1.910]        \n",
      "Epoch 641: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.80it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=1.910]\n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=1.910]        \n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=1.910]        \n",
      "Epoch 643: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.27it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.325, valid_loss=1.910]\n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=1.910]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=1.910]        \n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=1.910]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=1.910]        \n",
      "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=1.910]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=1.910]        \n",
      "Epoch 652: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.01it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=1.910]\n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=1.910]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=1.910]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=1.910]        \n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=1.910]        \n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=1.910]        \n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=1.910]        \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=1.910]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=1.910]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=1.910]        \n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=1.910]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=1.910]        \n",
      "Epoch 667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.36it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=1.910]\n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=1.910]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=1.910]        \n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=1.910]        \n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=1.910]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=1.910]        \n",
      "Epoch 674: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.69it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=1.910]\n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=1.910]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=1.910]        \n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=1.910]        \n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=1.910]        \n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=1.910]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=1.910]        \n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=1.910]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=1.910]        \n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=1.910]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=1.910]        \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=1.910]        \n",
      "Epoch 690: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.51it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=1.910]\n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=1.910]        \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=1.910]        \n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=1.910]        \n",
      "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=1.910]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=1.910]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=1.910]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.31it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.320, valid_loss=1.910]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 385.05it/s]\u001b[A\n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=2.280]        \n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=2.280]        \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=2.280]        \n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=2.280]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=2.280]        \n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=2.280]        \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=2.280]        \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=2.280]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=2.280]\n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=2.280]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=2.280]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=2.280]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=2.280]        \n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=2.280]        \n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=2.280]        \n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=2.280]        \n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=2.280]        \n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=2.280]        \n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=2.280]        \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=2.280]        \n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=2.280]        \n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=2.280]        \n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=2.280]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=2.280]        \n",
      "Epoch 738: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.04it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=2.280]\n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=2.280]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=2.280]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=2.280]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=2.280]        \n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=2.280]        \n",
      "Epoch 747: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.02it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.276, valid_loss=2.280]\n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=2.280]        \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=2.280]        \n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=2.280]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=2.280]        \n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=2.280]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=2.280]        \n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=2.280]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=2.280]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=2.280]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=2.280]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=2.280]        \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=2.280]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=2.280]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=2.280]        \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=2.280]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=2.280]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=2.280]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=2.280]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=2.280]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=2.280]        \n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=2.280]        \n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=2.280]        \n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=2.280]        \n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=2.280]        \n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=2.280]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=2.280]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=2.280]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=2.280]        \n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=2.280]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=2.280]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=2.280]        \n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=2.280]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.53it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.275, valid_loss=2.280]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 381.40it/s]\u001b[A\n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=2.380]        \n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=2.380]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=2.380]        \n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=2.380]        \n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=2.380]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=2.380]        \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=2.380]        \n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=2.380]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=2.380]        \n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=2.380]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=2.380]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=2.380]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=2.380]        \n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=2.380]        \n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=2.380]        \n",
      "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=2.380]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=2.380]        \n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=2.380]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=2.380]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=2.380]        \n",
      "Epoch 833: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.23it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=2.380]\n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=2.380]        \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=2.380]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=2.380]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=2.380]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=2.380]        \n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=2.380]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=2.380]        \n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=2.380]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=2.380]        \n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=2.380]        \n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=2.380]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=2.380]        \n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=2.380]\n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=2.380]        \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=2.380]        \n",
      "Epoch 854: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.12it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.265, valid_loss=2.380]\n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=2.380]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=2.380]        \n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=2.380]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=2.380]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=2.380]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=2.380]        \n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=2.380]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=2.380]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=2.380]        \n",
      "Epoch 867: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.51it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=2.380]\n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=2.380]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=2.380]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=2.380]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=2.380]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=2.380]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=2.380]        \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=2.380]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=2.380]        \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=2.380]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=2.380]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=2.380]        \n",
      "Epoch 883: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.40it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=2.380]\n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=2.380]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=2.380]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=2.380]        \n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=2.380]        \n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=2.380]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=2.380]        \n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=2.380]        \n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=2.380]        \n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=2.380]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=2.380]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.76it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.252, valid_loss=2.380]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 385.65it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=2.470]        \n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=2.470]        \n",
      "Epoch 902: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.19it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.258, valid_loss=2.470]\n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=2.470]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=2.470]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=2.470]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=2.470]        \n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=2.470]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=2.470]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=2.470]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=2.470]        \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=2.470]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=2.470]        \n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=2.470]        \n",
      "Epoch 922: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.81it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=2.470]\n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=2.470]        \n",
      "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=2.470]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=2.470]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=2.470]        \n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=2.470]        \n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=2.470]        \n",
      "Epoch 932: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.34it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.267, valid_loss=2.470]\n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=2.470]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=2.470]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=2.470]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=2.470]        \n",
      "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=2.470]        \n",
      "Epoch 939: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.27it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=2.470]\n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=2.470]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=2.470]        \n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=2.470]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=2.470]        \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=2.470]        \n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=2.470]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=2.470]        \n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=2.470]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=2.470]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=2.470]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=2.470]        \n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=2.470]        \n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=2.470]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=2.470]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=2.470]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=2.470]        \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=2.470]        \n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=2.470]        \n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=2.470]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=2.470]        \n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=2.470]        \n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=2.470]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=2.470]        \n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=2.470]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=2.470]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=2.470]        \n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=2.470]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=2.470]        \n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=2.470]        \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=2.470]        \n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=2.470]        \n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=2.470]        \n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=2.470]        \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=2.470]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=2.470]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=2.470]        \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=2.470]        \n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=2.470]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.33it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.245, valid_loss=2.470]\n",
      "\u001b[36m(_train_tune pid=42259)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 232.06it/s]\u001b[A\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.19it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=2.520]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=42259)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=42259)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[36m(_train_tune pid=42803)\u001b[0m Seed set to 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100]        \n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.43it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=3.080]\n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940]        \n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.98it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840]\n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840]        \n",
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.82it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.120]\n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930]        \n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.060, train_loss_epoch=3.060]        \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.060, train_loss_epoch=3.060]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.060, train_loss_epoch=3.060]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070]        \n",
      "Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.35it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.070]\n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010]        \n",
      "Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.23it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010]\n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020]        \n",
      "Epoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.41it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=2.970]\n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020]        \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.240, train_loss_epoch=3.240]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100]        \n",
      "Epoch 71: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.50it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880]\n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=3.130]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800]        \n",
      "Epoch 89: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.09it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940]\n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910]        \n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.97it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.950]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 378.38it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.710]       \n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.710]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.710]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=0.710]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.710]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.710]        \n",
      "Epoch 110: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.26it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.860, valid_loss=0.710]\n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.710]        \n",
      "Epoch 112: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.08it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=3.050, valid_loss=0.710]\n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=0.710]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.710]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.710]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.710]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.710]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.710]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.710]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.710]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.710]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.710]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.710]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890, valid_loss=0.710]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.710]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.710]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.710]        \n",
      "Epoch 141: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.01it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.710]\n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.710]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.710]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.710]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.710]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.710]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.710]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.710]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.710]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.710]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.710]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.710]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.710]        \n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.710]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.710]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.710]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.710]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.710]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.710]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.710]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.710]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.710]        \n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.710]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.710]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.710]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.710]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.710]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.710]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.710]        \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.710]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.76it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.610, valid_loss=0.710]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 390.79it/s]\u001b[A\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.910]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.910]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.910]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.910]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.910]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.910]        \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.910]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.910]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.910]        \n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.910]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.910]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.910]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.910]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.910]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.910]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.910]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.910]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.910]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.910]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.910]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.910]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.910]        \n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.910]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.910]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.910]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.910]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.910]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.910]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.910]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.910]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.910]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.910]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.910]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.910]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.910]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.910]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.910]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.910]        \n",
      "Epoch 273: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.62it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.430, valid_loss=0.910]\n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.910]        \n",
      "Epoch 275: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.23it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.910]\n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.910]        \n",
      "Epoch 277: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.07it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.910]\n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.910]        \n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.910]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.910]        \n",
      "Epoch 283: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.84it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.440, valid_loss=0.910]\n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.910]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.910]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.910]        \n",
      "Epoch 287: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.49it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.910]\n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.910]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.910]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.910]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.910]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.910]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.910]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.910]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.95it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.390, valid_loss=0.910]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 368.99it/s]\u001b[A\n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.943]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.943]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.943]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.943]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.943]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.943]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.943]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.943]        \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.943]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.943]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.943]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.943]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.943]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.943]        \n",
      "Epoch 326: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.62it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.943]\n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.943]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.943]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.943]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.943]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.943]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.943]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.943]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.943]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.943]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.943]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.943]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.943]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.943]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.943]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.943]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.943]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.943]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.943]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.943]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.943]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.943]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.943]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.943]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.943]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.943]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.943]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.943]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.943]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.943]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.943]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.943]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.943]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.943]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.943]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.943]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.943]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.943]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.943]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.99it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.140, valid_loss=0.943]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 395.06it/s]\u001b[A\n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=1.140]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=1.140]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=1.140]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=1.140]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=1.140]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=1.140]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=1.140]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=1.140]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=1.140]        \n",
      "Epoch 418: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.69it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=1.140]\n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=1.140]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=1.140]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=1.140]        \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=1.140]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=1.140]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=1.140]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=1.140]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=1.140]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=1.140]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=1.140]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=1.140]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=1.140]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=1.140]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=1.140]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=1.140]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=1.140]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=1.140]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=1.140]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=1.140]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=1.140]        \n",
      "Epoch 457: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.95it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=1.140]\n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=1.140]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=1.140]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=1.140]        \n",
      "Epoch 461: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.64it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=1.140]\n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=1.140]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=1.140]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=1.140]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=1.140]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=1.140]        \n",
      "Epoch 468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.08it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=1.140]\n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=1.140]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=1.140]        \n",
      "Epoch 472: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.06it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.900, valid_loss=1.140]\n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=1.140]        \n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=1.140]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=1.140]        \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=1.140]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=1.140]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=1.140]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=1.140]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=1.140]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=1.140]        \n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=1.140]        \n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=1.140]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=1.140]        \n",
      "Epoch 494: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.24it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=1.140]\n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=1.140]        \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=1.140]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=1.140]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.55it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=2.050, valid_loss=1.140]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 369.84it/s]\u001b[A\n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=1.130]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=1.130]        \n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=1.130]        \n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=1.130]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=1.130]        \n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=1.130]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=1.130]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=1.130]        \n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=1.130]        \n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=1.130]        \n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=1.130]        \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=1.130]        \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=1.130]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=1.130]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=1.130]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=1.130]        \n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=1.130]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=1.130]        \n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=1.130]        \n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=1.130]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=1.130]        \n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=1.130]        \n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=1.130]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=1.130]        \n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=1.130]        \n",
      "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=1.130]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=1.130]        \n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=1.130]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=1.130]        \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=1.130]        \n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=1.130]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=1.130]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=1.130]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=1.130]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=1.130]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=1.130]        \n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=1.130]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=1.130]        \n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=1.130]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=1.130]        \n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=1.130]        \n",
      "Epoch 568: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.06it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=1.130]\n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=1.130]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=1.130]        \n",
      "Epoch 571: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.44it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.910, valid_loss=1.130]\n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=1.130]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=1.130]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=1.130]        \n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=1.130]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=1.130]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=1.130]        \n",
      "Epoch 579: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.95it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.790, valid_loss=1.130]\n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=1.130]        \n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=1.130]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=1.130]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=1.130]        \n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=1.130]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=1.130]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=1.130]        \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=1.130]        \n",
      "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=1.130]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=1.130]        \n",
      "Epoch 593: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.46it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.890, valid_loss=1.130]\n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=1.130]        \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=1.130]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=1.130]        \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=1.130]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.57it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.800, valid_loss=1.130]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 303.58it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=42803)\u001b[0m \n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.836]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.836]        \n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.836]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.836]        \n",
      "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.836]        \n",
      "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.836]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.836]        \n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.836]        \n",
      "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.836]        \n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.836]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.836]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.836]        \n",
      "Epoch 616: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.39it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.836]\n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.836]        \n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.836]        \n",
      "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.836]        \n",
      "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.836]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.836]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.836]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.836]        \n",
      "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.836]        \n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.836]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.836]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.836]        \n",
      "Epoch 634: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.39it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.836]\n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.836]        \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.836]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.836]        \n",
      "Epoch 637: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.52it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.800, valid_loss=0.836]\n",
      "Epoch 637: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.19it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.836]\n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.836]        \n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.836]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.836]        \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.836]        \n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.836]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.836]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.836]        \n",
      "Epoch 646: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.51it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.836]\n",
      "Epoch 646: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.17it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.836]\n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.836]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.836]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.836]        \n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.836]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.836]        \n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.836]        \n",
      "Epoch 653: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.88it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.836]\n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.836]        \n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.836]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.836]        \n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.836]        \n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.836]        \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.836]        \n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.836]        \n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.836]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.836]\n",
      "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.836]        \n",
      "Epoch 665: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.07it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.870, valid_loss=0.836]\n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.836]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.836]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.836]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.836]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.836]        \n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.836]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.836]        \n",
      "Epoch 674: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.76it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.836]\n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.836]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.836]        \n",
      "Epoch 677: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.07it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.836]\n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.836]        \n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.836]        \n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.836]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.836]        \n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.836]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.836]        \n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.836]        \n",
      "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.836]        \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.836]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.836]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.836]        \n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.836]        \n",
      "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.836]        \n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.836]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.836]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.84it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.790, valid_loss=0.836]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 277.18it/s]\u001b[A\n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.938]        \n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.938]        \n",
      "Epoch 703: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.01it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.780, valid_loss=0.938]\n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.938]        \n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.938]        \n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.938]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.938]        \n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.938]        \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.938]        \n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.938]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.938]        \n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.938]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.938]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.938]        \n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.938]        \n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.938]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.938]        \n",
      "Epoch 723: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.69it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.720, valid_loss=0.938]\n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.938]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.938]        \n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.938]        \n",
      "Epoch 726: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.45it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.938]\n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.938]        \n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.938]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.938]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.938]        \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.938]        \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.938]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.938]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.938]        \n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.938]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.938]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.938]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.938]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.938]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.938]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.938]        \n",
      "Epoch 748: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.37it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.938]\n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.938]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.938]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.938]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.938]        \n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.938]        \n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.938]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.938]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.938]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.938]        \n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.938]        \n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.938]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.938]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.938]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.938]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.938]        \n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.938]        \n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.938]        \n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.938]        \n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.938]        \n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.938]        \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.938]        \n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.938]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.938]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.938]        \n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.938]        \n",
      "Epoch 791: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.79it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.938]\n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.938]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.938]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.938]        \n",
      "Epoch 796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.57it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.938]\n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.938]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.938]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.92it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.938]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 385.05it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.901]        \n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.901]        \n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.901]        \n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.901]        \n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.901]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.901]        \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.901]        \n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.901]        \n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.901]        \n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.901]        \n",
      "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.901]        \n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.901]        \n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.901]        \n",
      "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.901]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.901]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.901]        \n",
      "Epoch 830: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.25it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.901]\n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.901]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.901]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.901]        \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.901]        \n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.901]        \n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.901]        \n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.901]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.901]        \n",
      "Epoch 843: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.13it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.901]\n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.901]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.901]        \n",
      "Epoch 845: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.31it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.901]\n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.901]        \n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.901]        \n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.901]        \n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.901]        \n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.901]        \n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.901]        \n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.901]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.901]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.901]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.901]        \n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.901]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.901]        \n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.901]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.901]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.901]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.901]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.901]        \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.901]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.901]        \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.901]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.901]        \n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.901]        \n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.901]        \n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.901]        \n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.901]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.901]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.901]        \n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.901]        \n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.901]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.901]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.09it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.660, valid_loss=0.901]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 355.63it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.710]        \n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.710]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.710]        \n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.710]        \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.710]        \n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.710]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.710]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.710]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.710]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.710]        \n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.710]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.710]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.710]        \n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.710]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.710]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.710]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.710]        \n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.710]        \n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.710]        \n",
      "Epoch 932: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.61it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.560, valid_loss=0.710]\n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.710]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.710]        \n",
      "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.710]        \n",
      "Epoch 935: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.98it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.710]\n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.710]        \n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.710]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.710]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.710]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.710]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.710]        \n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.710]        \n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.710]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.710]        \n",
      "Epoch 949: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.58it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.710]\n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.710]        \n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.710]        \n",
      "Epoch 951: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.16it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.620, valid_loss=0.710]\n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.710]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.710]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.710]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.710]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.710]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.710]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.710]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.710]        \n",
      "Epoch 966: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.59it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.710]\n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.710]        \n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.710]        \n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.710]        \n",
      "Epoch 971: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.78it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.710]\n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.710]        \n",
      "Epoch 973: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.74it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.610, valid_loss=0.710]\n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.710]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.710]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.710]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.710]        \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.710]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.710]        \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.710]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.710]        \n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.710]        \n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.710]        \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.710]        \n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.710]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.710]        \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.710]        \n",
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.710]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.90it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.550, valid_loss=0.710]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 387.43it/s]\u001b[A\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.76it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.787]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=42803)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=42803)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[36m(_train_tune pid=43367)\u001b[0m Seed set to 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]       \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.10it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]\n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931]        \n",
      "Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.60it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930]\n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930]        \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.955, train_loss_epoch=0.955]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919]        \n",
      "Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.80it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.890]\n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.844, train_loss_epoch=0.844]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.750, train_loss_epoch=0.750]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.715]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.727, train_loss_epoch=0.727]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.682, train_loss_epoch=0.682]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.708]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616]        \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.633, train_loss_epoch=0.633]        \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557]        \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542]        \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468]        \n",
      "Epoch 96: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.99it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.456]\n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492]        \n",
      "Epoch 98: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.64it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464]\n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.82it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.464]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 410.36it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=3.340]       \n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=3.340]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=3.340]        \n",
      "Epoch 104: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.19it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=3.340]\n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=3.340]        \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=3.340]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=3.340]        \n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=3.340]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.340]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=3.340]        \n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.340]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.340]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.340]        \n",
      "Epoch 119: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.08it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=3.340]\n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=3.340]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.340]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.340]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=3.340]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.340]        \n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.340]        \n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=3.340]        \n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=3.340]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=3.340]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=3.340]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=3.340]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=3.340]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=3.340]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=3.340]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=3.340]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=3.340]        \n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=3.340]        \n",
      "Epoch 150: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.34it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.242, valid_loss=3.340]\n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.340]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=3.340]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=3.340]        \n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.340]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=3.340]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=3.340]        \n",
      "Epoch 160: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.22it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.340]\n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.340]        \n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=3.340]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=3.340]        \n",
      "Epoch 166: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.99it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=3.340]\n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=3.340]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=3.340]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=3.340]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=3.340]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=3.340]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=3.340]        \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=3.340]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=3.340]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=3.340]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=3.340]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=3.340]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=3.340]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=3.340]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=3.340]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=3.340]          \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.116, train_loss_epoch=0.116, valid_loss=3.340]        \n",
      "Epoch 197: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.80it/s, v_num=0, train_loss_step=0.0995, train_loss_epoch=0.0995, valid_loss=3.340]\n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0995, train_loss_epoch=0.0995, valid_loss=3.340]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.90it/s, v_num=0, train_loss_step=0.0943, train_loss_epoch=0.101, valid_loss=3.340] \n",
      "\u001b[36m(_train_tune pid=43367)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=43367)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 345.04it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=43367)\u001b[0m \n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0953, train_loss_epoch=0.0953, valid_loss=2.510]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0966, train_loss_epoch=0.0966, valid_loss=2.510]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0947, train_loss_epoch=0.0947, valid_loss=2.510]        \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0824, train_loss_epoch=0.0824, valid_loss=2.510]        \n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0787, train_loss_epoch=0.0787, valid_loss=2.510]        \n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0759, train_loss_epoch=0.0759, valid_loss=2.510]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0815, train_loss_epoch=0.0815, valid_loss=2.510]        \n",
      "Epoch 213: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.52it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=2.510]  \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=2.510]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=2.510]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=2.510]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0858, train_loss_epoch=0.0858, valid_loss=2.510]        \n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=2.510]          \n",
      "Epoch 221: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.17it/s, v_num=0, train_loss_step=0.0923, train_loss_epoch=0.0923, valid_loss=2.510]\n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0923, train_loss_epoch=0.0923, valid_loss=2.510]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=2.510]          \n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=2.510]        \n",
      "Epoch 225: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.35it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.113, valid_loss=2.510]\n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=2.510]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0914, train_loss_epoch=0.0914, valid_loss=2.510]        \n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0958, train_loss_epoch=0.0958, valid_loss=2.510]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0814, train_loss_epoch=0.0814, valid_loss=2.510]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0781, train_loss_epoch=0.0781, valid_loss=2.510]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0748, train_loss_epoch=0.0748, valid_loss=2.510]        \n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.068, train_loss_epoch=0.068, valid_loss=2.510]          \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0699, train_loss_epoch=0.0699, valid_loss=2.510]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0716, train_loss_epoch=0.0716, valid_loss=2.510]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0532, train_loss_epoch=0.0532, valid_loss=2.510]        \n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0569, train_loss_epoch=0.0569, valid_loss=2.510]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0546, train_loss_epoch=0.0546, valid_loss=2.510]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0608, train_loss_epoch=0.0608, valid_loss=2.510]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0513, train_loss_epoch=0.0513, valid_loss=2.510]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0468, train_loss_epoch=0.0468, valid_loss=2.510]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0462, train_loss_epoch=0.0462, valid_loss=2.510]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0466, train_loss_epoch=0.0466, valid_loss=2.510]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0474, train_loss_epoch=0.0474, valid_loss=2.510]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0429, train_loss_epoch=0.0429, valid_loss=2.510]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0467, train_loss_epoch=0.0467, valid_loss=2.510]        \n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0467, train_loss_epoch=0.0467, valid_loss=2.510]\n",
      "Epoch 264: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.72it/s, v_num=0, train_loss_step=0.0389, train_loss_epoch=0.0389, valid_loss=2.510]\n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0389, train_loss_epoch=0.0389, valid_loss=2.510]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0472, train_loss_epoch=0.0472, valid_loss=2.510]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0454, train_loss_epoch=0.0454, valid_loss=2.510]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0434, train_loss_epoch=0.0434, valid_loss=2.510]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0449, train_loss_epoch=0.0449, valid_loss=2.510]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418, valid_loss=2.510]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0347, valid_loss=2.510]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.0396, valid_loss=2.510]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=2.510]        \n",
      "Epoch 279: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.92it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0341, valid_loss=2.510]\n",
      "Epoch 279: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.75it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0317, valid_loss=2.510]\n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0317, valid_loss=2.510]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0271, train_loss_epoch=0.0271, valid_loss=2.510]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0272, train_loss_epoch=0.0272, valid_loss=2.510]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=2.510]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=2.510]\n",
      "Epoch 285: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.22it/s, v_num=0, train_loss_step=0.0283, train_loss_epoch=0.0283, valid_loss=2.510]\n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0283, train_loss_epoch=0.0283, valid_loss=2.510]        \n",
      "Epoch 287: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.66it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=2.510]\n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=2.510]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0285, train_loss_epoch=0.0285, valid_loss=2.510]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=2.510]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0247, train_loss_epoch=0.0247, valid_loss=2.510]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=2.510]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0222, train_loss_epoch=0.0222, valid_loss=2.510]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.024, train_loss_epoch=0.024, valid_loss=2.510]          \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.95it/s, v_num=0, train_loss_step=0.0229, train_loss_epoch=0.024, valid_loss=2.510]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 374.66it/s]\u001b[A\n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=2.970]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=2.970]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0197, train_loss_epoch=0.0197, valid_loss=2.970]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=2.970]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=2.970]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=2.970]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=2.970]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0241, valid_loss=2.970]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=2.970]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.021, train_loss_epoch=0.021, valid_loss=2.970]          \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0269, train_loss_epoch=0.0269, valid_loss=2.970]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=2.970]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=2.970]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0279, valid_loss=2.970]        \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=2.970]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0203, train_loss_epoch=0.0203, valid_loss=2.970]        \n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0226, train_loss_epoch=0.0226, valid_loss=2.970]        \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.019, train_loss_epoch=0.019, valid_loss=2.970]          \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0233, train_loss_epoch=0.0233, valid_loss=2.970]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0215, train_loss_epoch=0.0215, valid_loss=2.970]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0201, train_loss_epoch=0.0201, valid_loss=2.970]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0208, train_loss_epoch=0.0208, valid_loss=2.970]        \n",
      "Epoch 337: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.08it/s, v_num=0, train_loss_step=0.0202, train_loss_epoch=0.0202, valid_loss=2.970]\n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0202, train_loss_epoch=0.0202, valid_loss=2.970]        \n",
      "Epoch 339: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.71it/s, v_num=0, train_loss_step=0.0172, train_loss_epoch=0.0202, valid_loss=2.970]\n",
      "Epoch 339: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.58it/s, v_num=0, train_loss_step=0.0172, train_loss_epoch=0.0172, valid_loss=2.970]\n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0172, train_loss_epoch=0.0172, valid_loss=2.970]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0193, train_loss_epoch=0.0193, valid_loss=2.970]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0166, train_loss_epoch=0.0166, valid_loss=2.970]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00877, train_loss_epoch=0.00877, valid_loss=2.970]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=2.970]          \n",
      "Epoch 346: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.29it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=2.970]\n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=2.970]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0186, train_loss_epoch=0.0186, valid_loss=2.970]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0093, train_loss_epoch=0.0093, valid_loss=2.970]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0151, train_loss_epoch=0.0151, valid_loss=2.970]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.016, train_loss_epoch=0.016, valid_loss=2.970]          \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=2.970]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0099, train_loss_epoch=0.0099, valid_loss=2.970]          \n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0168, train_loss_epoch=0.0168, valid_loss=2.970]        \n",
      "Epoch 361: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.62it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=2.970]\n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=2.970]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=2.970]        \n",
      "Epoch 363: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.44it/s, v_num=0, train_loss_step=0.0097, train_loss_epoch=0.0118, valid_loss=2.970]\n",
      "Epoch 363: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.27it/s, v_num=0, train_loss_step=0.0097, train_loss_epoch=0.0097, valid_loss=2.970]\n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0097, train_loss_epoch=0.0097, valid_loss=2.970]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00969, train_loss_epoch=0.00969, valid_loss=2.970]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=2.970]          \n",
      "Epoch 367: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.17it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.00928, valid_loss=2.970] \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=2.970]         \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=2.970]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00848, train_loss_epoch=0.00848, valid_loss=2.970]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0076, train_loss_epoch=0.0076, valid_loss=2.970]          \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=2.970]          \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=2.970]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0093, train_loss_epoch=0.0093, valid_loss=2.970]          \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=2.970]          \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00546, train_loss_epoch=0.00546, valid_loss=2.970]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00696, train_loss_epoch=0.00696, valid_loss=2.970]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00885, train_loss_epoch=0.00885, valid_loss=2.970]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00749, train_loss_epoch=0.00749, valid_loss=2.970]        \n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00567, train_loss_epoch=0.00567, valid_loss=2.970]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00673, train_loss_epoch=0.00673, valid_loss=2.970]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00786, train_loss_epoch=0.00786, valid_loss=2.970]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00672, train_loss_epoch=0.00672, valid_loss=2.970]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00585, train_loss_epoch=0.00585, valid_loss=2.970]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00894, train_loss_epoch=0.00894, valid_loss=2.970]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00592, train_loss_epoch=0.00592, valid_loss=2.970]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00713, train_loss_epoch=0.00713, valid_loss=2.970]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00585, train_loss_epoch=0.00585, valid_loss=2.970]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.00it/s, v_num=0, train_loss_step=0.00689, train_loss_epoch=0.00585, valid_loss=2.970]\n",
      "\u001b[36m(_train_tune pid=43367)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 387.57it/s]\u001b[A\n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00371, train_loss_epoch=0.00371, valid_loss=3.490]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00543, train_loss_epoch=0.00543, valid_loss=3.490]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00488, train_loss_epoch=0.00488, valid_loss=3.490]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00585, train_loss_epoch=0.00585, valid_loss=3.490]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.005, train_loss_epoch=0.005, valid_loss=3.490]            \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00652, train_loss_epoch=0.00652, valid_loss=3.490]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00489, train_loss_epoch=0.00489, valid_loss=3.490]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00536, train_loss_epoch=0.00536, valid_loss=3.490]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00532, train_loss_epoch=0.00532, valid_loss=3.490]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0046, train_loss_epoch=0.0046, valid_loss=3.490]          \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00674, train_loss_epoch=0.00674, valid_loss=3.490]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00672, train_loss_epoch=0.00672, valid_loss=3.490]        \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00448, train_loss_epoch=0.00448, valid_loss=3.490]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00323, train_loss_epoch=0.00323, valid_loss=3.490]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00456, train_loss_epoch=0.00456, valid_loss=3.490]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00392, train_loss_epoch=0.00392, valid_loss=3.490]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00563, train_loss_epoch=0.00563, valid_loss=3.490]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00684, train_loss_epoch=0.00684, valid_loss=3.490]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00779, train_loss_epoch=0.00779, valid_loss=3.490]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00396, train_loss_epoch=0.00396, valid_loss=3.490]        \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00275, train_loss_epoch=0.00275, valid_loss=3.490]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00534, train_loss_epoch=0.00534, valid_loss=3.490]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00284, train_loss_epoch=0.00284, valid_loss=3.490]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00567, train_loss_epoch=0.00567, valid_loss=3.490]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00482, train_loss_epoch=0.00482, valid_loss=3.490]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00285, train_loss_epoch=0.00285, valid_loss=3.490]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0027, train_loss_epoch=0.0027, valid_loss=3.490]          \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00371, train_loss_epoch=0.00371, valid_loss=3.490]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0026, train_loss_epoch=0.0026, valid_loss=3.490]          \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00264, train_loss_epoch=0.00264, valid_loss=3.490]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00356, train_loss_epoch=0.00356, valid_loss=3.490]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00302, train_loss_epoch=0.00302, valid_loss=3.490]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00357, train_loss_epoch=0.00357, valid_loss=3.490]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00312, train_loss_epoch=0.00312, valid_loss=3.490]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0026, train_loss_epoch=0.0026, valid_loss=3.490]          \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00251, train_loss_epoch=0.00251, valid_loss=3.490]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00324, train_loss_epoch=0.00324, valid_loss=3.490]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00294, train_loss_epoch=0.00294, valid_loss=3.490]        \n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0024, train_loss_epoch=0.0024, valid_loss=3.490]          \n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00331, train_loss_epoch=0.00331, valid_loss=3.490]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00327, train_loss_epoch=0.00327, valid_loss=3.490]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00235, train_loss_epoch=0.00235, valid_loss=3.490]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00289, train_loss_epoch=0.00289, valid_loss=3.490]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00302, train_loss_epoch=0.00302, valid_loss=3.490]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00276, train_loss_epoch=0.00276, valid_loss=3.490]        \n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00194, train_loss_epoch=0.00194, valid_loss=3.490]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00191, train_loss_epoch=0.00191, valid_loss=3.490]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00246, train_loss_epoch=0.00246, valid_loss=3.490]        \n",
      "Epoch 489: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.99it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=3.490]\n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=3.490]        \n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00177, train_loss_epoch=0.00177, valid_loss=3.490]        \n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00238, train_loss_epoch=0.00238, valid_loss=3.490]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00238, train_loss_epoch=0.00238, valid_loss=3.490]\n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00242, train_loss_epoch=0.00242, valid_loss=3.490]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00172, train_loss_epoch=0.00172, valid_loss=3.490]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00223, train_loss_epoch=0.00223, valid_loss=3.490]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.50it/s, v_num=0, train_loss_step=0.00179, train_loss_epoch=0.00215, valid_loss=3.490]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=43367)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=43367)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 315.67it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=43367)\u001b[0m \n",
      "Epoch 501: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.40it/s, v_num=0, train_loss_step=0.00213, train_loss_epoch=0.00213, valid_loss=3.540]\n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00213, train_loss_epoch=0.00213, valid_loss=3.540]        \n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00155, train_loss_epoch=0.00155, valid_loss=3.540]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00157, train_loss_epoch=0.00157, valid_loss=3.540]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00199, train_loss_epoch=0.00199, valid_loss=3.540]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00145, train_loss_epoch=0.00145, valid_loss=3.540]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00158, train_loss_epoch=0.00158, valid_loss=3.540]        \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00226, train_loss_epoch=0.00226, valid_loss=3.540]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00212, train_loss_epoch=0.00212, valid_loss=3.540]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00234, train_loss_epoch=0.00234, valid_loss=3.540]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00235, train_loss_epoch=0.00235, valid_loss=3.540]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00173, train_loss_epoch=0.00173, valid_loss=3.540]        \n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00314, train_loss_epoch=0.00314, valid_loss=3.540]        \n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00132, train_loss_epoch=0.00132, valid_loss=3.540]        \n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00188, train_loss_epoch=0.00188, valid_loss=3.540]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00158, train_loss_epoch=0.00158, valid_loss=3.540]        \n",
      "Epoch 526: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.53it/s, v_num=0, train_loss_step=0.00158, train_loss_epoch=0.00158, valid_loss=3.540]\n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00127, valid_loss=3.540]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00162, train_loss_epoch=0.00162, valid_loss=3.540]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00141, train_loss_epoch=0.00141, valid_loss=3.540]        \n",
      "Epoch 531: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.17it/s, v_num=0, train_loss_step=0.00206, train_loss_epoch=0.00206, valid_loss=3.540]\n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00206, train_loss_epoch=0.00206, valid_loss=3.540]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00141, train_loss_epoch=0.00141, valid_loss=3.540]        \n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00182, train_loss_epoch=0.00182, valid_loss=3.540]        \n",
      "Epoch 535: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.55it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=3.540]\n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=3.540]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=3.540]\n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00184, train_loss_epoch=0.00184, valid_loss=3.540]        \n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00138, train_loss_epoch=0.00138, valid_loss=3.540]        \n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00186, train_loss_epoch=0.00186, valid_loss=3.540]        \n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00127, valid_loss=3.540]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=3.540]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00124, train_loss_epoch=0.00124, valid_loss=3.540]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00114, train_loss_epoch=0.00114, valid_loss=3.540]        \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=3.540]        \n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=3.540]\n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00109, train_loss_epoch=0.00109, valid_loss=3.540]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00124, train_loss_epoch=0.00124, valid_loss=3.540]        \n",
      "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00107, train_loss_epoch=0.00107, valid_loss=3.540]        \n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000972, train_loss_epoch=0.000972, valid_loss=3.540]        \n",
      "Epoch 558: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.58it/s, v_num=0, train_loss_step=0.00101, train_loss_epoch=0.00101, valid_loss=3.540]  \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00101, train_loss_epoch=0.00101, valid_loss=3.540]        \n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00107, train_loss_epoch=0.00107, valid_loss=3.540]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00102, train_loss_epoch=0.00102, valid_loss=3.540]        \n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00111, train_loss_epoch=0.00111, valid_loss=3.540]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000987, train_loss_epoch=0.000987, valid_loss=3.540]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=3.540]          \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000958, train_loss_epoch=0.000958, valid_loss=3.540]        \n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000917, train_loss_epoch=0.000917, valid_loss=3.540]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00106, train_loss_epoch=0.00106, valid_loss=3.540]          \n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000941, train_loss_epoch=0.000941, valid_loss=3.540]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000938, train_loss_epoch=0.000938, valid_loss=3.540]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000829, train_loss_epoch=0.000829, valid_loss=3.540]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000852, train_loss_epoch=0.000852, valid_loss=3.540]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000795, train_loss_epoch=0.000795, valid_loss=3.540]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000851, train_loss_epoch=0.000851, valid_loss=3.540]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00152, train_loss_epoch=0.00152, valid_loss=3.540]          \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000782, train_loss_epoch=0.000782, valid_loss=3.540]        \n",
      "Epoch 591: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.39it/s, v_num=0, train_loss_step=0.00105, train_loss_epoch=0.00105, valid_loss=3.540]  \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00105, train_loss_epoch=0.00105, valid_loss=3.540]        \n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000855, train_loss_epoch=0.000855, valid_loss=3.540]        \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00156, train_loss_epoch=0.00156, valid_loss=3.540]          \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000857, train_loss_epoch=0.000857, valid_loss=3.540]        \n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000899, train_loss_epoch=0.000899, valid_loss=3.540]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.94it/s, v_num=0, train_loss_step=0.00101, train_loss_epoch=0.000899, valid_loss=3.540] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 396.55it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00101, train_loss_epoch=0.00101, valid_loss=3.480]         \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000849, train_loss_epoch=0.000849, valid_loss=3.480]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000937, train_loss_epoch=0.000937, valid_loss=3.480]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000856, train_loss_epoch=0.000856, valid_loss=3.480]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000913, train_loss_epoch=0.000913, valid_loss=3.480]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000768, train_loss_epoch=0.000768, valid_loss=3.480]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00127, valid_loss=3.480]          \n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00127, valid_loss=3.480]\n",
      "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000847, train_loss_epoch=0.000847, valid_loss=3.480]        \n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000897, train_loss_epoch=0.000897, valid_loss=3.480]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00105, train_loss_epoch=0.00105, valid_loss=3.480]          \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000922, train_loss_epoch=0.000922, valid_loss=3.480]        \n",
      "Epoch 617: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.57it/s, v_num=0, train_loss_step=0.000874, train_loss_epoch=0.000874, valid_loss=3.480]\n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000874, train_loss_epoch=0.000874, valid_loss=3.480]        \n",
      "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00074, train_loss_epoch=0.00074, valid_loss=3.480]          \n",
      "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000857, train_loss_epoch=0.000857, valid_loss=3.480]        \n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000945, train_loss_epoch=0.000945, valid_loss=3.480]        \n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000837, train_loss_epoch=0.000837, valid_loss=3.480]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000777, train_loss_epoch=0.000777, valid_loss=3.480]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=3.480]          \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000685, train_loss_epoch=0.000685, valid_loss=3.480]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00103, train_loss_epoch=0.00103, valid_loss=3.480]          \n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00084, train_loss_epoch=0.00084, valid_loss=3.480]          \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000777, train_loss_epoch=0.000777, valid_loss=3.480]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000992, train_loss_epoch=0.000992, valid_loss=3.480]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000814, train_loss_epoch=0.000814, valid_loss=3.480]        \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000844, train_loss_epoch=0.000844, valid_loss=3.480]        \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=3.480]            \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000922, train_loss_epoch=0.000922, valid_loss=3.480]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=3.480]          \n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000918, train_loss_epoch=0.000918, valid_loss=3.480]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000991, train_loss_epoch=0.000991, valid_loss=3.480]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000963, train_loss_epoch=0.000963, valid_loss=3.480]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00267, train_loss_epoch=0.00267, valid_loss=3.480]          \n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000915, train_loss_epoch=0.000915, valid_loss=3.480]        \n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00121, train_loss_epoch=0.00121, valid_loss=3.480]          \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=3.480]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00105, train_loss_epoch=0.00105, valid_loss=3.480]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000952, train_loss_epoch=0.000952, valid_loss=3.480]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00117, train_loss_epoch=0.00117, valid_loss=3.480]          \n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000954, train_loss_epoch=0.000954, valid_loss=3.480]        \n",
      "Epoch 668: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.17it/s, v_num=0, train_loss_step=0.000877, train_loss_epoch=0.000877, valid_loss=3.480]\n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000877, train_loss_epoch=0.000877, valid_loss=3.480]        \n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000689, train_loss_epoch=0.000689, valid_loss=3.480]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000645, train_loss_epoch=0.000645, valid_loss=3.480]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000684, train_loss_epoch=0.000684, valid_loss=3.480]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000659, train_loss_epoch=0.000659, valid_loss=3.480]        \n",
      "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000628, train_loss_epoch=0.000628, valid_loss=3.480]        \n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000566, train_loss_epoch=0.000566, valid_loss=3.480]        \n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00078, train_loss_epoch=0.00078, valid_loss=3.480]          \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000572, train_loss_epoch=0.000572, valid_loss=3.480]        \n",
      "Epoch 682: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.18it/s, v_num=0, train_loss_step=0.000621, train_loss_epoch=0.000621, valid_loss=3.480]\n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000621, train_loss_epoch=0.000621, valid_loss=3.480]        \n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000491, train_loss_epoch=0.000491, valid_loss=3.480]        \n",
      "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000523, train_loss_epoch=0.000523, valid_loss=3.480]        \n",
      "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000455, train_loss_epoch=0.000455, valid_loss=3.480]        \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000515, train_loss_epoch=0.000515, valid_loss=3.480]        \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000434, train_loss_epoch=0.000434, valid_loss=3.480]        \n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000997, train_loss_epoch=0.000997, valid_loss=3.480]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000826, train_loss_epoch=0.000826, valid_loss=3.480]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000432, train_loss_epoch=0.000432, valid_loss=3.480]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000955, train_loss_epoch=0.000955, valid_loss=3.480]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.93it/s, v_num=0, train_loss_step=0.00103, train_loss_epoch=0.000955, valid_loss=3.480] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 360.61it/s]\u001b[A\n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00103, train_loss_epoch=0.00103, valid_loss=3.430]         \n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000421, train_loss_epoch=0.000421, valid_loss=3.430]        \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000403, train_loss_epoch=0.000403, valid_loss=3.430]        \n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000371, train_loss_epoch=0.000371, valid_loss=3.430]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000384, train_loss_epoch=0.000384, valid_loss=3.430]        \n",
      "Epoch 709: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.77it/s, v_num=0, train_loss_step=0.00048, train_loss_epoch=0.00048, valid_loss=3.430]  \n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00048, train_loss_epoch=0.00048, valid_loss=3.430]        \n",
      "Epoch 711: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.79it/s, v_num=0, train_loss_step=0.00032, train_loss_epoch=0.00032, valid_loss=3.430]  \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00032, train_loss_epoch=0.00032, valid_loss=3.430]        \n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000356, train_loss_epoch=0.000356, valid_loss=3.430]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000499, train_loss_epoch=0.000499, valid_loss=3.430]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00036, train_loss_epoch=0.00036, valid_loss=3.430]          \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000368, train_loss_epoch=0.000368, valid_loss=3.430]        \n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000329, train_loss_epoch=0.000329, valid_loss=3.430]        \n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000473, train_loss_epoch=0.000473, valid_loss=3.430]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000361, train_loss_epoch=0.000361, valid_loss=3.430]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000313, train_loss_epoch=0.000313, valid_loss=3.430]        \n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000337, train_loss_epoch=0.000337, valid_loss=3.430]        \n",
      "Epoch 727: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.36it/s, v_num=0, train_loss_step=0.000344, train_loss_epoch=0.000344, valid_loss=3.430]\n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000344, train_loss_epoch=0.000344, valid_loss=3.430]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000417, train_loss_epoch=0.000417, valid_loss=3.430]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000304, train_loss_epoch=0.000304, valid_loss=3.430]        \n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000321, train_loss_epoch=0.000321, valid_loss=3.430]        \n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000356, train_loss_epoch=0.000356, valid_loss=3.430]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000289, train_loss_epoch=0.000289, valid_loss=3.430]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00028, train_loss_epoch=0.00028, valid_loss=3.430]          \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000392, train_loss_epoch=0.000392, valid_loss=3.430]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000338, train_loss_epoch=0.000338, valid_loss=3.430]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000314, train_loss_epoch=0.000314, valid_loss=3.430]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000376, train_loss_epoch=0.000376, valid_loss=3.430]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000247, train_loss_epoch=0.000247, valid_loss=3.430]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000307, train_loss_epoch=0.000307, valid_loss=3.430]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00026, train_loss_epoch=0.00026, valid_loss=3.430]          \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00026, train_loss_epoch=0.00026, valid_loss=3.430]\n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000385, train_loss_epoch=0.000385, valid_loss=3.430]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000266, train_loss_epoch=0.000266, valid_loss=3.430]        \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000273, train_loss_epoch=0.000273, valid_loss=3.430]        \n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000288, train_loss_epoch=0.000288, valid_loss=3.430]        \n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000301, train_loss_epoch=0.000301, valid_loss=3.430]        \n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000453, train_loss_epoch=0.000453, valid_loss=3.430]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000293, train_loss_epoch=0.000293, valid_loss=3.430]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000269, train_loss_epoch=0.000269, valid_loss=3.430]        \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000256, train_loss_epoch=0.000256, valid_loss=3.430]        \n",
      "Epoch 766: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.36it/s, v_num=0, train_loss_step=0.000293, train_loss_epoch=0.000293, valid_loss=3.430]\n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000293, train_loss_epoch=0.000293, valid_loss=3.430]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00028, train_loss_epoch=0.00028, valid_loss=3.430]          \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000261, train_loss_epoch=0.000261, valid_loss=3.430]        \n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000263, train_loss_epoch=0.000263, valid_loss=3.430]        \n",
      "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000358, train_loss_epoch=0.000358, valid_loss=3.430]        \n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000258, train_loss_epoch=0.000258, valid_loss=3.430]        \n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000292, train_loss_epoch=0.000292, valid_loss=3.430]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000242, train_loss_epoch=0.000242, valid_loss=3.430]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000282, train_loss_epoch=0.000282, valid_loss=3.430]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00027, train_loss_epoch=0.00027, valid_loss=3.430]          \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000249, train_loss_epoch=0.000249, valid_loss=3.430]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000311, train_loss_epoch=0.000311, valid_loss=3.430]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000256, train_loss_epoch=0.000256, valid_loss=3.430]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000207, train_loss_epoch=0.000207, valid_loss=3.430]        \n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000264, train_loss_epoch=0.000264, valid_loss=3.430]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000326, train_loss_epoch=0.000326, valid_loss=3.430]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000274, train_loss_epoch=0.000274, valid_loss=3.430]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000331, train_loss_epoch=0.000331, valid_loss=3.430]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000308, train_loss_epoch=0.000308, valid_loss=3.430]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.88it/s, v_num=0, train_loss_step=0.000228, train_loss_epoch=0.000222, valid_loss=3.430]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 402.25it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000228, train_loss_epoch=0.000228, valid_loss=3.420]        \n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000304, train_loss_epoch=0.000304, valid_loss=3.420]        \n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000265, train_loss_epoch=0.000265, valid_loss=3.420]        \n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000256, train_loss_epoch=0.000256, valid_loss=3.420]        \n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000232, train_loss_epoch=0.000232, valid_loss=3.420]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000227, train_loss_epoch=0.000227, valid_loss=3.420]        \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000301, train_loss_epoch=0.000301, valid_loss=3.420]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000258, train_loss_epoch=0.000258, valid_loss=3.420]        \n",
      "Epoch 812: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.34it/s, v_num=0, train_loss_step=0.00026, train_loss_epoch=0.000258, valid_loss=3.420] \n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00026, train_loss_epoch=0.00026, valid_loss=3.420]         \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000245, train_loss_epoch=0.000245, valid_loss=3.420]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000244, train_loss_epoch=0.000244, valid_loss=3.420]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000243, train_loss_epoch=0.000243, valid_loss=3.420]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000232, train_loss_epoch=0.000232, valid_loss=3.420]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000199, train_loss_epoch=0.000199, valid_loss=3.420]        \n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000239, train_loss_epoch=0.000239, valid_loss=3.420]        \n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000225, train_loss_epoch=0.000225, valid_loss=3.420]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000225, train_loss_epoch=0.000225, valid_loss=3.420]\n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000225, train_loss_epoch=0.000225, valid_loss=3.420]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000265, train_loss_epoch=0.000265, valid_loss=3.420]        \n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000227, train_loss_epoch=0.000227, valid_loss=3.420]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000212, train_loss_epoch=0.000212, valid_loss=3.420]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000209, train_loss_epoch=0.000209, valid_loss=3.420]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000207, train_loss_epoch=0.000207, valid_loss=3.420]        \n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000233, train_loss_epoch=0.000233, valid_loss=3.420]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000232, train_loss_epoch=0.000232, valid_loss=3.420]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000222, train_loss_epoch=0.000222, valid_loss=3.420]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000214, train_loss_epoch=0.000214, valid_loss=3.420]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000181, train_loss_epoch=0.000181, valid_loss=3.420]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000206, train_loss_epoch=0.000206, valid_loss=3.420]        \n",
      "Epoch 846: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.50it/s, v_num=0, train_loss_step=0.000176, train_loss_epoch=0.000176, valid_loss=3.420]\n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000176, train_loss_epoch=0.000176, valid_loss=3.420]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000215, train_loss_epoch=0.000215, valid_loss=3.420]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000208, train_loss_epoch=0.000208, valid_loss=3.420]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000214, train_loss_epoch=0.000214, valid_loss=3.420]        \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000188, train_loss_epoch=0.000188, valid_loss=3.420]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000148, train_loss_epoch=0.000148, valid_loss=3.420]        \n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000206, train_loss_epoch=0.000206, valid_loss=3.420]        \n",
      "Epoch 857: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.88it/s, v_num=0, train_loss_step=0.000226, train_loss_epoch=0.000206, valid_loss=3.420]\n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000226, train_loss_epoch=0.000226, valid_loss=3.420]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000172, train_loss_epoch=0.000172, valid_loss=3.420]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000173, train_loss_epoch=0.000173, valid_loss=3.420]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000176, train_loss_epoch=0.000176, valid_loss=3.420]        \n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000176, train_loss_epoch=0.000176, valid_loss=3.420]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00017, train_loss_epoch=0.00017, valid_loss=3.420]          \n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000174, train_loss_epoch=0.000174, valid_loss=3.420]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000176, train_loss_epoch=0.000176, valid_loss=3.420]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000165, train_loss_epoch=0.000165, valid_loss=3.420]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000158, train_loss_epoch=0.000158, valid_loss=3.420]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000141, train_loss_epoch=0.000141, valid_loss=3.420]        \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000182, train_loss_epoch=0.000182, valid_loss=3.420]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000189, train_loss_epoch=0.000189, valid_loss=3.420]        \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000164, train_loss_epoch=0.000164, valid_loss=3.420]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00018, train_loss_epoch=0.00018, valid_loss=3.420]          \n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000169, train_loss_epoch=0.000169, valid_loss=3.420]        \n",
      "Epoch 885: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.78it/s, v_num=0, train_loss_step=0.000169, train_loss_epoch=0.000169, valid_loss=3.420]\n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000169, train_loss_epoch=0.000169, valid_loss=3.420]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000152, train_loss_epoch=0.000152, valid_loss=3.420]        \n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000174, train_loss_epoch=0.000174, valid_loss=3.420]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000167, train_loss_epoch=0.000167, valid_loss=3.420]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000148, train_loss_epoch=0.000148, valid_loss=3.420]        \n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000162, train_loss_epoch=0.000162, valid_loss=3.420]        \n",
      "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000183, train_loss_epoch=0.000183, valid_loss=3.420]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000146, train_loss_epoch=0.000146, valid_loss=3.420]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.74it/s, v_num=0, train_loss_step=0.000171, train_loss_epoch=0.000173, valid_loss=3.420]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 342.81it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=43367)\u001b[0m \n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000167, train_loss_epoch=0.000167, valid_loss=3.410]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000148, train_loss_epoch=0.000148, valid_loss=3.410]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000167, train_loss_epoch=0.000167, valid_loss=3.410]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00014, train_loss_epoch=0.00014, valid_loss=3.410]          \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000171, train_loss_epoch=0.000171, valid_loss=3.410]        \n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000151, train_loss_epoch=0.000151, valid_loss=3.410]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000156, train_loss_epoch=0.000156, valid_loss=3.410]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000161, train_loss_epoch=0.000161, valid_loss=3.410]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000143, train_loss_epoch=0.000143, valid_loss=3.410]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000146, train_loss_epoch=0.000146, valid_loss=3.410]        \n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000137, train_loss_epoch=0.000137, valid_loss=3.410]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000134, train_loss_epoch=0.000134, valid_loss=3.410]        \n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000137, train_loss_epoch=0.000137, valid_loss=3.410]        \n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000159, train_loss_epoch=0.000159, valid_loss=3.410]        \n",
      "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000131, train_loss_epoch=0.000131, valid_loss=3.410]        \n",
      "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000139, train_loss_epoch=0.000139, valid_loss=3.410]        \n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000134, train_loss_epoch=0.000134, valid_loss=3.410]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000136, train_loss_epoch=0.000136, valid_loss=3.410]        \n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000136, train_loss_epoch=0.000136, valid_loss=3.410]\n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000137, train_loss_epoch=0.000137, valid_loss=3.410]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000126, train_loss_epoch=0.000126, valid_loss=3.410]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000148, train_loss_epoch=0.000148, valid_loss=3.410]        \n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000131, train_loss_epoch=0.000131, valid_loss=3.410]        \n",
      "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000138, train_loss_epoch=0.000138, valid_loss=3.410]        \n",
      "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000149, train_loss_epoch=0.000149, valid_loss=3.410]        \n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000129, train_loss_epoch=0.000129, valid_loss=3.410]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000146, train_loss_epoch=0.000146, valid_loss=3.410]        \n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000142, train_loss_epoch=0.000142, valid_loss=3.410]        \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00013, train_loss_epoch=0.00013, valid_loss=3.410]          \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000139, train_loss_epoch=0.000139, valid_loss=3.410]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000132, train_loss_epoch=0.000132, valid_loss=3.410]        \n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000129, train_loss_epoch=0.000129, valid_loss=3.410]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000112, train_loss_epoch=0.000112, valid_loss=3.410]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000136, train_loss_epoch=0.000136, valid_loss=3.410]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000119, train_loss_epoch=0.000119, valid_loss=3.410]        \n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000138, train_loss_epoch=0.000138, valid_loss=3.410]        \n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000125, train_loss_epoch=0.000125, valid_loss=3.410]        \n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000135, train_loss_epoch=0.000135, valid_loss=3.410]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000118, train_loss_epoch=0.000118, valid_loss=3.410]        \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000102, train_loss_epoch=0.000102, valid_loss=3.410]        \n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000106, train_loss_epoch=0.000106, valid_loss=3.410]        \n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000114, train_loss_epoch=0.000114, valid_loss=3.410]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000109, train_loss_epoch=0.000109, valid_loss=3.410]        \n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000134, train_loss_epoch=0.000134, valid_loss=3.410]        \n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000116, train_loss_epoch=0.000116, valid_loss=3.410]        \n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000117, train_loss_epoch=0.000117, valid_loss=3.410]        \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000112, train_loss_epoch=0.000112, valid_loss=3.410]        \n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000115, train_loss_epoch=0.000115, valid_loss=3.410]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000101, train_loss_epoch=0.000101, valid_loss=3.410]        \n",
      "Epoch 983: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.39it/s, v_num=0, train_loss_step=0.000116, train_loss_epoch=0.000113, valid_loss=3.410]\n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000116, train_loss_epoch=0.000116, valid_loss=3.410]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.92e-5, train_loss_epoch=8.92e-5, valid_loss=3.410]          \n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000114, train_loss_epoch=0.000114, valid_loss=3.410]        \n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000107, train_loss_epoch=0.000107, valid_loss=3.410]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000101, train_loss_epoch=0.000101, valid_loss=3.410]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000117, train_loss_epoch=0.000117, valid_loss=3.410]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.82e-5, train_loss_epoch=8.82e-5, valid_loss=3.410]          \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000105, train_loss_epoch=0.000105, valid_loss=3.410]        \n",
      "Epoch 996: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.67it/s, v_num=0, train_loss_step=9.04e-5, train_loss_epoch=0.000105, valid_loss=3.410] \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.04e-5, train_loss_epoch=9.04e-5, valid_loss=3.410]         \n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00012, train_loss_epoch=0.00012, valid_loss=3.410]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.90it/s, v_num=0, train_loss_step=0.000116, train_loss_epoch=8.55e-5, valid_loss=3.410]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 354.13it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=43367)\u001b[0m \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.40it/s, v_num=0, train_loss_step=0.000116, train_loss_epoch=0.000116, valid_loss=3.400]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=43367)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=43367)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[36m(_train_tune pid=43916)\u001b[0m Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 91.31it/s]\n",
      "                                                                           \n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.220, train_loss_epoch=3.220]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150]       \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=3.130]        \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.060, train_loss_epoch=3.060]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940]        \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=3.160]        \n",
      "Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.40it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]\n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.060, train_loss_epoch=3.060]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970]        \n",
      "Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.48it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=3.160]\n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=3.160]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890]        \n",
      "Epoch 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.40it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.850]\n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010]        \n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880]        \n",
      "Epoch 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.66it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.880]\n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090]        \n",
      "Epoch 79: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.59it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920]\n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920]        \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980]        \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970]        \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840]        \n",
      "Epoch 92: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 24.06it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930]\n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.68it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.820]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 412.74it/s]\u001b[A\n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.591]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=0.591]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890, valid_loss=0.591]        \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.591]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=0.591]        \n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.591]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.591]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.591]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.591]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.591]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.591]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.591]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.591]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890, valid_loss=0.591]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=0.591]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.591]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890, valid_loss=0.591]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.591]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890, valid_loss=0.591]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.591]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.591]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.591]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.591]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.591]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.591]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.591]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.591]        \n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.591]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.591]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.591]        \n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.591]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.591]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.591]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.591]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.591]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.591]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.591]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.591]        \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.591]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.591]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.591]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.591]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.591]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.591]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.591]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.591]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.591]        \n",
      "Epoch 196: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.24it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.591]\n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.591]        \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.591]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.62it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.550, valid_loss=0.591]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 407.13it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=1.410]        \n",
      "Epoch 200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.90it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=1.410]\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=1.410]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=1.410]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=1.410]        \n",
      "Epoch 204: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.57it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.600, valid_loss=1.410]\n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=1.410]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=1.410]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=1.410]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=1.410]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=1.410]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=1.410]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=1.410]        \n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=1.410]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=1.410]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=1.410]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=1.410]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=1.410]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=1.410]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=1.410]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=1.410]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=1.410]        \n",
      "Epoch 238: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.67it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.430, valid_loss=1.410]\n",
      "Epoch 238: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.27it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=1.410]\n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=1.410]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=1.410]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=1.410]        \n",
      "Epoch 244: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.45it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.440, valid_loss=1.410]\n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=1.410]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=1.410]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=1.410]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=1.410]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=1.410]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=1.410]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=1.410]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=1.410]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=1.410]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=1.410]        \n",
      "Epoch 262: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.77it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=1.410]\n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=1.410]        \n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=1.410]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=1.410]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=1.410]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=1.410]        \n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=1.410]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=1.410]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=1.410]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=1.410]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=1.410]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=1.410]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=1.410]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=1.410]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=1.410]        \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=1.410]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=1.410]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=1.410]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=1.410]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=1.410]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=1.410]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.23it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.150, valid_loss=1.410]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 353.86it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=1.190]        \n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=1.190]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=1.190]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=1.190]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=1.190]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=1.190]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=1.190]        \n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=1.190]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=1.190]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=1.190]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=1.190]\n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=1.190]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=1.190]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=1.190]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=1.190]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=1.190]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=1.190]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=1.190]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=1.190]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=1.190]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=1.190]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=1.190]        \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=1.190]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=1.190]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=1.190]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=1.190]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=1.190]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=1.190]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=1.190]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=1.190]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=1.190]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=1.190]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=1.190]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=1.190]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=1.190]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=1.190]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=1.190]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=1.190]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=1.190]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=1.190]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=1.190]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=1.190]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=1.190]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=1.190]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=1.190]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=1.190]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=1.190]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=1.190]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=1.190]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=1.190]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=1.190]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=1.190]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.80it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.120, valid_loss=1.190]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=43916)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 323.11it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=43916)\u001b[0m \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=1.280]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=1.280]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=1.280]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=1.280]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=1.280]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=1.280]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=1.280]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=1.280]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=1.280]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=1.280]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=1.280]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=1.280]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=1.280]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=1.280]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=1.280]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=1.280]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=1.280]\n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=1.280]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=1.280]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=1.280]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=1.280]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=1.280]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=1.280]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=1.280]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=1.280]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=1.280]        \n",
      "Epoch 449: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.41it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=1.280]\n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=1.280]        \n",
      "Epoch 451: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.09it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=1.280]\n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=1.280]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=1.280]        \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=1.280]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=1.280]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=1.280]        \n",
      "Epoch 460: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.19it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=2.060, valid_loss=1.280]\n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=1.280]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=1.280]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=1.280]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=1.280]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=1.280]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=1.280]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=1.280]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=1.280]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=1.280]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=1.280]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=1.280]        \n",
      "Epoch 480: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.78it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.950, valid_loss=1.280]\n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=1.280]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=1.280]        \n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=1.280]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=1.280]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=1.280]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=1.280]        \n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=1.280]        \n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=1.280]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=1.280]        \n",
      "Epoch 497: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.50it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=1.280]\n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=1.280]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.87it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.930, valid_loss=1.280]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 365.52it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=43916)\u001b[0m \n",
      "                                                                       \u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=1.060]        \n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=1.060]        \n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=1.060]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=1.060]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=1.060]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=1.060]        \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=1.060]        \n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=1.060]        \n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=1.060]        \n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=1.060]        \n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=1.060]        \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=1.060]        \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=1.060]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=1.060]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=1.060]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=1.060]        \n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=1.060]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=1.060]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=1.060]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=1.060]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=1.060]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=1.060]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=1.060]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=1.060]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=1.060]        \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=1.060]        \n",
      "Epoch 549: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.18it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=1.060]\n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=1.060]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=1.060]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=1.060]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=1.060]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=1.060]        \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=1.060]        \n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=1.060]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=1.060]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=1.060]        \n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=1.060]        \n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=1.060]        \n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=1.060]        \n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=1.060]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=1.060]        \n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=1.060]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=1.060]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=1.060]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=1.060]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=1.060]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=1.060]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=1.060]        \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=1.060]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=1.060]        \n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=1.060]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=1.060]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=1.060]        \n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=1.060]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.17it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.860, valid_loss=1.060]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 352.82it/s]\u001b[A\n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.809]        \n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.809]        \n",
      "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.809]        \n",
      "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.809]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.809]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.809]        \n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.809]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.809]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.809]        \n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.809]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.809]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.809]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.809]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.809]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.809]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.809]        \n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.809]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.809]        \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.809]        \n",
      "Epoch 635: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.97it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.770, valid_loss=0.809]\n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.809]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.809]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.809]        \n",
      "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.809]        \n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.809]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.809]        \n",
      "Epoch 645: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.24it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.809]\n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.809]        \n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.809]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.809]        \n",
      "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.809]        \n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.809]        \n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.809]        \n",
      "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.809]        \n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.809]        \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.809]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.809]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.809]        \n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.809]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.809]\n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.809]        \n",
      "Epoch 668: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.58it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.809]\n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.809]        \n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.809]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.809]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.809]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.809]        \n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.809]        \n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.809]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.809]        \n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.809]        \n",
      "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.809]        \n",
      "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.809]        \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.809]        \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.809]        \n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.809]        \n",
      "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.809]        \n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.809]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.82it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.620, valid_loss=0.809]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 333.01it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=43916)\u001b[0m \n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.897]        \n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.897]        \n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.897]        \n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.897]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.897]        \n",
      "Epoch 708: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.58it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.897]\n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.897]        \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.897]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.897]        \n",
      "Epoch 712: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.20it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.897]\n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.897]        \n",
      "Epoch 714: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.67it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.897]\n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.897]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.897]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.897]        \n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.897]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.897]        \n",
      "Epoch 724: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.89it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.897]\n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.897]        \n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.897]        \n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.897]        \n",
      "Epoch 728: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.94it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.897]\n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.897]        \n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.897]        \n",
      "Epoch 730: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.83it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.640, valid_loss=0.897]\n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.897]        \n",
      "Epoch 732: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.50it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.897]\n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.897]        \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.897]        \n",
      "Epoch 734: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.86it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.897]\n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.897]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.897]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.897]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.897]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.897]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.897]        \n",
      "Epoch 745: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.24it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.630, valid_loss=0.897]\n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.897]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.897]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.897]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.897]        \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.897]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.897]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.897]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.897]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.897]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.897]        \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.897]        \n",
      "Epoch 765: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.82it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.570, valid_loss=0.897]\n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.897]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.897]        \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.897]        \n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.897]        \n",
      "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.897]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.897]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.897]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.897]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.897]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.897]        \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.897]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.897]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.897]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.897]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.897]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.897]        \n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.897]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.897]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.897]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.56it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.610, valid_loss=0.897]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 329.40it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=43916)\u001b[0m \n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.832]        \n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.832]        \n",
      "Epoch 801: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.80it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.832]\n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.832]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.832]        \n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.832]        \n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.832]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.832]        \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.832]        \n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.832]        \n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.832]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.832]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.832]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.832]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.832]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.832]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.832]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.832]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.832]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.832]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.832]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.832]        \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.832]        \n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.832]        \n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.832]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.832]        \n",
      "Epoch 841: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.07it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.832]\n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.832]        \n",
      "Epoch 843: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.14it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.832]\n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.832]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.832]        \n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.832]        \n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.832]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.832]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.832]        \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.832]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.832]        \n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.832]        \n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.832]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.832]        \n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.832]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.832]        \n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.832]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.832]        \n",
      "Epoch 871: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.52it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.832]\n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.832]        \n",
      "Epoch 873: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.47it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.832]\n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.832]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.832]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.832]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.832]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.832]        \n",
      "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.832]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.832]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.832]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.832]        \n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.832]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.832]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.832]        \n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.832]        \n",
      "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.832]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.832]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.20it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.540, valid_loss=0.832]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 372.76it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=43916)\u001b[0m \n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.805]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.805]        \n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.805]        \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.805]        \n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.805]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.805]        \n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.805]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.805]        \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.805]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.805]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.805]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=0.805]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.805]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.805]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.805]        \n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.805]        \n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.805]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.805]        \n",
      "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.805]        \n",
      "Epoch 935: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.85it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.805]\n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.805]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.805]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.805]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.805]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.805]        \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.805]        \n",
      "Epoch 947: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.27it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.805]\n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.805]        \n",
      "Epoch 949: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.64it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.805]\n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.805]        \n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.805]        \n",
      "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.805]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.805]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.805]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.805]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.805]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.805]        \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.805]        \n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.805]        \n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.805]        \n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.805]        \n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.805]        \n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.805]        \n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.805]        \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.805]        \n",
      "Epoch 979: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.05it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.805]\n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.805]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.805]        \n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.805]        \n",
      "Epoch 983: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.03it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.805]\n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.805]        \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.805]        \n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.805]        \n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.805]        \n",
      "Epoch 990: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.61it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.530, valid_loss=0.805]\n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.805]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.805]        \n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.805]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.805]        \n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.805]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.36it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.620, valid_loss=0.805]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 385.51it/s]\u001b[A\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.17it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.716]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=43916)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=43916)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[36m(_train_tune pid=44446)\u001b[0m Seed set to 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030]        \n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.21it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=3.030]\n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=3.250]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830]       \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140]        \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020]        \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980]        \n",
      "Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.99it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920]\n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880]        \n",
      "Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.58it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860]\n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740]        \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750]        \n",
      "Epoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.24it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.750]\n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760]        \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580]\n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450]        \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410]        \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.68it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.240]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 400.33it/s]\u001b[A\n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.785]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.785]        \n",
      "Epoch 105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.07it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.785]\n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.785]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.785]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.785]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.785]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.785]        \n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.785]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.785]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.785]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.785]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.785]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.785]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.785]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.785]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.785]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.785]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=0.785]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.785]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.785]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.785]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.785]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.785]        \n",
      "Epoch 149: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.15it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.785]\n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.785]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.785]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.785]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.785]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.785]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.785]        \n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.785]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.785]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.785]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.785]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.785]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=0.785]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.785]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.785]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=0.785]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=0.785]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.785]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.785]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=0.785]        \n",
      "Epoch 186: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.59it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.785]\n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.785]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=0.785]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=0.785]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=0.785]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=0.785]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=0.785]        \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=0.785]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.45it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.330, valid_loss=0.785]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 387.72it/s]\u001b[A\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=1.980]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=1.980]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=1.980]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=1.980]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=1.980]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=1.980]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=1.980]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=1.980]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.980]        \n",
      "Epoch 219: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.40it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.060, valid_loss=1.980]\n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.980]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.980]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=1.980]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=1.980]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=1.980]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=1.980]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=1.980]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=1.980]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=1.980]        \n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=1.980]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=1.980]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.980]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=1.980]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=1.980]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=1.980]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=1.980]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910, valid_loss=1.980]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=1.980]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=1.980]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=0.932, valid_loss=1.980]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.826, train_loss_epoch=0.826, valid_loss=1.980]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871, valid_loss=1.980]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=0.827, valid_loss=1.980]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796, valid_loss=1.980]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=1.980]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=0.878, valid_loss=1.980]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.828, train_loss_epoch=0.828, valid_loss=1.980]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.787, train_loss_epoch=0.787, valid_loss=1.980]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.764, train_loss_epoch=0.764, valid_loss=1.980]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=0.799, valid_loss=1.980]        \n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.773, train_loss_epoch=0.773, valid_loss=1.980]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.789, train_loss_epoch=0.789, valid_loss=1.980]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.800, train_loss_epoch=0.800, valid_loss=1.980]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759, valid_loss=1.980]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=1.980]        \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.800, train_loss_epoch=0.800, valid_loss=1.980]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817, valid_loss=1.980]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.738, train_loss_epoch=0.738, valid_loss=1.980]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.710, train_loss_epoch=0.710, valid_loss=1.980]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=1.980]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.80it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.657, valid_loss=1.980]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 390.64it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=3.060]        \n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=3.060]        \n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=3.060]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=3.060]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.728, train_loss_epoch=0.728, valid_loss=3.060]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.722, train_loss_epoch=0.722, valid_loss=3.060]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.679, train_loss_epoch=0.679, valid_loss=3.060]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.646, train_loss_epoch=0.646, valid_loss=3.060]        \n",
      "Epoch 315: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.03it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=3.060]\n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=3.060]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.679, train_loss_epoch=0.679, valid_loss=3.060]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.773, train_loss_epoch=0.773, valid_loss=3.060]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=3.060]        \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=3.060]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.716, valid_loss=3.060]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=3.060]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.636, train_loss_epoch=0.636, valid_loss=3.060]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=3.060]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=3.060]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=3.060]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=3.060]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=3.060]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=3.060]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=3.060]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=3.060]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=3.060]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=3.060]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=3.060]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=3.060]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=3.060]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=3.060]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=3.060]        \n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=3.060]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=3.060]        \n",
      "Epoch 363: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.68it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.060]\n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.060]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=3.060]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=3.060]        \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.060]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=3.060]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.060]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=3.060]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.060]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.060]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.060]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.060]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.060]        \n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.060]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.060]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.060]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=3.060]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.060]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.060]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.060]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.55it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.290, valid_loss=3.060]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 390.06it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=44446)\u001b[0m \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.350]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=3.350]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=3.350]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=3.350]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=3.350]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=3.350]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=3.350]        \n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.350]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=3.350]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=3.350]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=3.350]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=3.350]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=3.350]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=3.350]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.350]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.350]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=3.350]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=3.350]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=3.350]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=3.350]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=3.350]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=3.350]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=3.350]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=3.350]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=3.350]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=3.350]\n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=3.350]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=3.350]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=3.350]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=3.350]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=3.350]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=3.350]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=3.350]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=3.350]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=3.350]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=3.350]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=3.350]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=3.350]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=3.350]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=3.350]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=3.350]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=3.350]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=3.350]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=3.350]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=3.350]        \n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=3.350]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=3.350]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.350]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=3.350]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=3.350]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=3.350]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=3.350]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=3.350]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.38it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.243, valid_loss=3.350]\n",
      "\u001b[36m(_train_tune pid=44446)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 383.74it/s]\u001b[A\n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=3.210]        \n",
      "Epoch 501: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.65it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=3.210]\n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=3.210]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=3.210]        \n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=3.210]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.210]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=3.210]        \n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=3.210]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=3.210]        \n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=3.210]        \n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.210]        \n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.210]        \n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.210]        \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=3.210]        \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=3.210]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=3.210]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=3.210]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.210]        \n",
      "Epoch 531: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.64it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=3.210]\n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=3.210]        \n",
      "Epoch 533: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.67it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=3.210]\n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=3.210]        \n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=3.210]        \n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=3.210]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=3.210]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=3.210]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.210]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.210]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=3.210]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=3.210]        \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=3.210]        \n",
      "Epoch 549: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.33it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.188, valid_loss=3.210]\n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.210]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=3.210]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=3.210]        \n",
      "Epoch 553: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.57it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=3.210]\n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=3.210]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.210]        \n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.210]        \n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.210]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=3.210]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.210]        \n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=3.210]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=3.210]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.210]        \n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=3.210]        \n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.210]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.210]        \n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=3.210]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=3.210]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=3.210]        \n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=3.210]        \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.210]        \n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=3.210]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=3.210]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=3.210]        \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.210]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=3.210]        \n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=3.210]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=3.210]        \n",
      "Epoch 597: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.10it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=3.210]\n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=3.210]        \n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=3.210]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.78it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.191, valid_loss=3.210]\n",
      "\u001b[36m(_train_tune pid=44446)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 393.20it/s]\u001b[A\n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=3.230]        \n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=3.230]        \n",
      "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=3.230]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=3.230]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=3.230]        \n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=3.230]        \n",
      "Epoch 610: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.03it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=3.230]\n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=3.230]        \n",
      "Epoch 612: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.71it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=3.230]\n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=3.230]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=3.230]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=3.230]        \n",
      "Epoch 618: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.56it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=3.230]\n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=3.230]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=3.230]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=3.230]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=3.230]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=3.230]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=3.230]        \n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=3.230]        \n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=3.230]        \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=3.230]        \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=3.230]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=3.230]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=3.230]        \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=3.230]        \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=3.230]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=3.230]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=3.230]        \n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=3.230]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=3.230]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=3.230]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=3.230]        \n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=3.230]        \n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=3.230]        \n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=3.230]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=3.230]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=3.230]        \n",
      "Epoch 665: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.63it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.133, valid_loss=3.230]\n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141, valid_loss=3.230]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=3.230]        \n",
      "Epoch 667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.81it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=3.230]\n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123, valid_loss=3.230]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=3.230]        \n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=3.230]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=3.230]\n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119, valid_loss=3.230]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=3.230]        \n",
      "Epoch 675: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.85it/s, v_num=0, train_loss_step=0.0989, train_loss_epoch=0.0989, valid_loss=3.230]\n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0989, train_loss_epoch=0.0989, valid_loss=3.230]        \n",
      "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=3.230]          \n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0969, train_loss_epoch=0.0969, valid_loss=3.230]        \n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=3.230]          \n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=3.230]          \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.088, train_loss_epoch=0.088, valid_loss=3.230]        \n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=3.230]          \n",
      "Epoch 688: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.98it/s, v_num=0, train_loss_step=0.094, train_loss_epoch=0.0904, valid_loss=3.230] \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.094, train_loss_epoch=0.094, valid_loss=3.230]         \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0984, train_loss_epoch=0.0984, valid_loss=3.230]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.087, train_loss_epoch=0.087, valid_loss=3.230]          \n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0864, train_loss_epoch=0.0864, valid_loss=3.230]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0892, train_loss_epoch=0.0892, valid_loss=3.230]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.095, train_loss_epoch=0.095, valid_loss=3.230]          \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0949, train_loss_epoch=0.0949, valid_loss=3.230]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.74it/s, v_num=0, train_loss_step=0.0948, train_loss_epoch=0.0949, valid_loss=3.230]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 384.90it/s]\u001b[A\n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0948, train_loss_epoch=0.0948, valid_loss=2.850]        \n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0987, train_loss_epoch=0.0987, valid_loss=2.850]        \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0833, train_loss_epoch=0.0833, valid_loss=2.850]        \n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0862, train_loss_epoch=0.0862, valid_loss=2.850]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.084, train_loss_epoch=0.084, valid_loss=2.850]          \n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0782, train_loss_epoch=0.0782, valid_loss=2.850]        \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0821, train_loss_epoch=0.0821, valid_loss=2.850]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0816, train_loss_epoch=0.0816, valid_loss=2.850]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0814, train_loss_epoch=0.0814, valid_loss=2.850]        \n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0823, train_loss_epoch=0.0823, valid_loss=2.850]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0887, train_loss_epoch=0.0887, valid_loss=2.850]        \n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0871, train_loss_epoch=0.0871, valid_loss=2.850]        \n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0731, train_loss_epoch=0.0731, valid_loss=2.850]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0929, train_loss_epoch=0.0929, valid_loss=2.850]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0795, train_loss_epoch=0.0795, valid_loss=2.850]        \n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0853, train_loss_epoch=0.0853, valid_loss=2.850]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0859, train_loss_epoch=0.0859, valid_loss=2.850]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0746, train_loss_epoch=0.0746, valid_loss=2.850]        \n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.074, train_loss_epoch=0.074, valid_loss=2.850]          \n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0839, train_loss_epoch=0.0839, valid_loss=2.850]        \n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0746, train_loss_epoch=0.0746, valid_loss=2.850]        \n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0714, train_loss_epoch=0.0714, valid_loss=2.850]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0723, train_loss_epoch=0.0723, valid_loss=2.850]        \n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0717, train_loss_epoch=0.0717, valid_loss=2.850]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0814, train_loss_epoch=0.0814, valid_loss=2.850]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0747, train_loss_epoch=0.0747, valid_loss=2.850]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0876, train_loss_epoch=0.0876, valid_loss=2.850]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0738, train_loss_epoch=0.0738, valid_loss=2.850]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.069, train_loss_epoch=0.069, valid_loss=2.850]          \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0788, train_loss_epoch=0.0788, valid_loss=2.850]        \n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=2.850]        \n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0618, train_loss_epoch=0.0618, valid_loss=2.850]        \n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0757, train_loss_epoch=0.0757, valid_loss=2.850]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0758, train_loss_epoch=0.0758, valid_loss=2.850]        \n",
      "Epoch 762: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.43it/s, v_num=0, train_loss_step=0.0727, train_loss_epoch=0.0727, valid_loss=2.850]\n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0741, train_loss_epoch=0.0741, valid_loss=2.850]        \n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=2.850]        \n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0688, train_loss_epoch=0.0688, valid_loss=2.850]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0852, train_loss_epoch=0.0852, valid_loss=2.850]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=2.850]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0625, train_loss_epoch=0.0625, valid_loss=2.850]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0665, train_loss_epoch=0.0665, valid_loss=2.850]        \n",
      "Epoch 775: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.62it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=2.850]\n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=2.850]        \n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0635, train_loss_epoch=0.0635, valid_loss=2.850]        \n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.071, train_loss_epoch=0.071, valid_loss=2.850]          \n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0801, train_loss_epoch=0.0801, valid_loss=2.850]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0766, train_loss_epoch=0.0766, valid_loss=2.850]        \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0642, train_loss_epoch=0.0642, valid_loss=2.850]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0719, train_loss_epoch=0.0719, valid_loss=2.850]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0714, train_loss_epoch=0.0714, valid_loss=2.850]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0788, train_loss_epoch=0.0788, valid_loss=2.850]        \n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0616, train_loss_epoch=0.0616, valid_loss=2.850]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0728, train_loss_epoch=0.0728, valid_loss=2.850]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0708, train_loss_epoch=0.0708, valid_loss=2.850]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0555, train_loss_epoch=0.0555, valid_loss=2.850]        \n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0593, train_loss_epoch=0.0593, valid_loss=2.850]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.62it/s, v_num=0, train_loss_step=0.0491, train_loss_epoch=0.0593, valid_loss=2.850]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 392.61it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0491, train_loss_epoch=0.0491, valid_loss=2.980]        \n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0795, train_loss_epoch=0.0795, valid_loss=2.980]        \n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0702, train_loss_epoch=0.0702, valid_loss=2.980]        \n",
      "Epoch 802: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.19it/s, v_num=0, train_loss_step=0.0657, train_loss_epoch=0.0702, valid_loss=2.980]\n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0657, train_loss_epoch=0.0657, valid_loss=2.980]        \n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0672, train_loss_epoch=0.0672, valid_loss=2.980]        \n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0653, train_loss_epoch=0.0653, valid_loss=2.980]        \n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0622, train_loss_epoch=0.0622, valid_loss=2.980]        \n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0652, train_loss_epoch=0.0652, valid_loss=2.980]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=2.980]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0619, train_loss_epoch=0.0619, valid_loss=2.980]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0641, train_loss_epoch=0.0641, valid_loss=2.980]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0581, train_loss_epoch=0.0581, valid_loss=2.980]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0626, train_loss_epoch=0.0626, valid_loss=2.980]        \n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0535, train_loss_epoch=0.0535, valid_loss=2.980]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0717, train_loss_epoch=0.0717, valid_loss=2.980]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0665, train_loss_epoch=0.0665, valid_loss=2.980]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0572, train_loss_epoch=0.0572, valid_loss=2.980]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0574, train_loss_epoch=0.0574, valid_loss=2.980]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0528, train_loss_epoch=0.0528, valid_loss=2.980]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0662, train_loss_epoch=0.0662, valid_loss=2.980]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.056, train_loss_epoch=0.056, valid_loss=2.980]          \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0592, train_loss_epoch=0.0592, valid_loss=2.980]        \n",
      "Epoch 837: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.37it/s, v_num=0, train_loss_step=0.0702, train_loss_epoch=0.0702, valid_loss=2.980]\n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0702, train_loss_epoch=0.0702, valid_loss=2.980]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.075, train_loss_epoch=0.075, valid_loss=2.980]          \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.067, train_loss_epoch=0.067, valid_loss=2.980]          \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0665, train_loss_epoch=0.0665, valid_loss=2.980]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0743, train_loss_epoch=0.0743, valid_loss=2.980]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0631, train_loss_epoch=0.0631, valid_loss=2.980]        \n",
      "Epoch 846: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.30it/s, v_num=0, train_loss_step=0.0635, train_loss_epoch=0.0631, valid_loss=2.980]\n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0635, train_loss_epoch=0.0635, valid_loss=2.980]        \n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0614, train_loss_epoch=0.0614, valid_loss=2.980]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0525, train_loss_epoch=0.0525, valid_loss=2.980]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0595, train_loss_epoch=0.0595, valid_loss=2.980]        \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0593, train_loss_epoch=0.0593, valid_loss=2.980]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0599, train_loss_epoch=0.0599, valid_loss=2.980]        \n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0637, train_loss_epoch=0.0637, valid_loss=2.980]        \n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0629, train_loss_epoch=0.0629, valid_loss=2.980]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0542, train_loss_epoch=0.0542, valid_loss=2.980]        \n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0601, train_loss_epoch=0.0601, valid_loss=2.980]        \n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0487, train_loss_epoch=0.0487, valid_loss=2.980]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0553, train_loss_epoch=0.0553, valid_loss=2.980]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0676, train_loss_epoch=0.0676, valid_loss=2.980]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0697, train_loss_epoch=0.0697, valid_loss=2.980]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0498, train_loss_epoch=0.0498, valid_loss=2.980]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0527, train_loss_epoch=0.0527, valid_loss=2.980]        \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0552, train_loss_epoch=0.0552, valid_loss=2.980]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0504, train_loss_epoch=0.0504, valid_loss=2.980]        \n",
      "Epoch 880: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.05it/s, v_num=0, train_loss_step=0.0608, train_loss_epoch=0.0608, valid_loss=2.980]\n",
      "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0608, train_loss_epoch=0.0608, valid_loss=2.980]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0564, train_loss_epoch=0.0564, valid_loss=2.980]        \n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0574, train_loss_epoch=0.0574, valid_loss=2.980]        \n",
      "Epoch 884: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.91it/s, v_num=0, train_loss_step=0.0624, train_loss_epoch=0.0574, valid_loss=2.980]\n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0624, train_loss_epoch=0.0624, valid_loss=2.980]        \n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0601, train_loss_epoch=0.0601, valid_loss=2.980]        \n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=2.980]        \n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0636, train_loss_epoch=0.0636, valid_loss=2.980]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0619, train_loss_epoch=0.0619, valid_loss=2.980]        \n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0546, train_loss_epoch=0.0546, valid_loss=2.980]        \n",
      "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0598, train_loss_epoch=0.0598, valid_loss=2.980]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=2.980]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.68it/s, v_num=0, train_loss_step=0.0616, train_loss_epoch=0.0535, valid_loss=2.980]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 389.26it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0616, train_loss_epoch=0.0616, valid_loss=2.920]        \n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0522, train_loss_epoch=0.0522, valid_loss=2.920]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0573, train_loss_epoch=0.0573, valid_loss=2.920]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0524, train_loss_epoch=0.0524, valid_loss=2.920]        \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0539, train_loss_epoch=0.0539, valid_loss=2.920]        \n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0471, train_loss_epoch=0.0471, valid_loss=2.920]        \n",
      "Epoch 909: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.17it/s, v_num=0, train_loss_step=0.0563, train_loss_epoch=0.0471, valid_loss=2.920]\n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0563, train_loss_epoch=0.0563, valid_loss=2.920]        \n",
      "Epoch 911: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.45it/s, v_num=0, train_loss_step=0.0632, train_loss_epoch=0.0658, valid_loss=2.920]\n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0632, train_loss_epoch=0.0632, valid_loss=2.920]        \n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0507, train_loss_epoch=0.0507, valid_loss=2.920]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0486, train_loss_epoch=0.0486, valid_loss=2.920]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0518, train_loss_epoch=0.0518, valid_loss=2.920]        \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0672, train_loss_epoch=0.0672, valid_loss=2.920]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.062, train_loss_epoch=0.062, valid_loss=2.920]          \n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.049, train_loss_epoch=0.049, valid_loss=2.920]          \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0563, train_loss_epoch=0.0563, valid_loss=2.920]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0583, train_loss_epoch=0.0583, valid_loss=2.920]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0593, train_loss_epoch=0.0593, valid_loss=2.920]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0588, train_loss_epoch=0.0588, valid_loss=2.920]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0518, train_loss_epoch=0.0518, valid_loss=2.920]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0549, train_loss_epoch=0.0549, valid_loss=2.920]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0605, train_loss_epoch=0.0605, valid_loss=2.920]        \n",
      "Epoch 933: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.05it/s, v_num=0, train_loss_step=0.051, train_loss_epoch=0.051, valid_loss=2.920]  \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.051, train_loss_epoch=0.051, valid_loss=2.920]        \n",
      "Epoch 935: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.53it/s, v_num=0, train_loss_step=0.0538, train_loss_epoch=0.0538, valid_loss=2.920]\n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0538, train_loss_epoch=0.0538, valid_loss=2.920]        \n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0539, train_loss_epoch=0.0539, valid_loss=2.920]        \n",
      "Epoch 937: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.15it/s, v_num=0, train_loss_step=0.0632, train_loss_epoch=0.0539, valid_loss=2.920]\n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0632, train_loss_epoch=0.0632, valid_loss=2.920]        \n",
      "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0475, train_loss_epoch=0.0475, valid_loss=2.920]        \n",
      "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0619, train_loss_epoch=0.0619, valid_loss=2.920]        \n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0544, train_loss_epoch=0.0544, valid_loss=2.920]        \n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0563, train_loss_epoch=0.0563, valid_loss=2.920]        \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0522, train_loss_epoch=0.0522, valid_loss=2.920]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0607, train_loss_epoch=0.0607, valid_loss=2.920]        \n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0471, train_loss_epoch=0.0471, valid_loss=2.920]        \n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0562, train_loss_epoch=0.0562, valid_loss=2.920]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0506, train_loss_epoch=0.0506, valid_loss=2.920]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0575, train_loss_epoch=0.0575, valid_loss=2.920]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0547, train_loss_epoch=0.0547, valid_loss=2.920]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.044, train_loss_epoch=0.044, valid_loss=2.920]          \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0489, train_loss_epoch=0.0489, valid_loss=2.920]        \n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0563, train_loss_epoch=0.0563, valid_loss=2.920]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0492, train_loss_epoch=0.0492, valid_loss=2.920]        \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0383, train_loss_epoch=0.0383, valid_loss=2.920]        \n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.050, train_loss_epoch=0.050, valid_loss=2.920]          \n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0504, train_loss_epoch=0.0504, valid_loss=2.920]        \n",
      "Epoch 971: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.59it/s, v_num=0, train_loss_step=0.054, train_loss_epoch=0.054, valid_loss=2.920]  \n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.054, train_loss_epoch=0.054, valid_loss=2.920]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0519, train_loss_epoch=0.0519, valid_loss=2.920]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0567, train_loss_epoch=0.0567, valid_loss=2.920]        \n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0495, train_loss_epoch=0.0495, valid_loss=2.920]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.043, train_loss_epoch=0.043, valid_loss=2.920]          \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0512, train_loss_epoch=0.0512, valid_loss=2.920]        \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0424, train_loss_epoch=0.0424, valid_loss=2.920]        \n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.044, train_loss_epoch=0.044, valid_loss=2.920]          \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0571, train_loss_epoch=0.0571, valid_loss=2.920]        \n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0533, train_loss_epoch=0.0533, valid_loss=2.920]        \n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0399, train_loss_epoch=0.0399, valid_loss=2.920]        \n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0605, train_loss_epoch=0.0605, valid_loss=2.920]        \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0421, train_loss_epoch=0.0421, valid_loss=2.920]        \n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477, valid_loss=2.920]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.060, train_loss_epoch=0.060, valid_loss=2.920]          \n",
      "Epoch 997: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.71it/s, v_num=0, train_loss_step=0.0611, train_loss_epoch=0.0611, valid_loss=2.920]\n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0611, train_loss_epoch=0.0611, valid_loss=2.920]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.59it/s, v_num=0, train_loss_step=0.0489, train_loss_epoch=0.0525, valid_loss=2.920]\n",
      "\u001b[36m(_train_tune pid=44446)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=44446)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 352.85it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=44446)\u001b[0m \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.16it/s, v_num=0, train_loss_step=0.0489, train_loss_epoch=0.0489, valid_loss=2.940]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=44446)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=44446)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[36m(_train_tune pid=44961)\u001b[0m Seed set to 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830]        \n",
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.59it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.940]\n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800]        \n",
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.69it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.800]\n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930]        \n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920]        \n",
      "Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.66it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930]\n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]        \n",
      "Epoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.55it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]\n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690]        \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710]        \n",
      "Epoch 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.30it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.710]\n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710]        \n",
      "Epoch 81: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.91it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650]\n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650]        \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600]        \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680]        \n",
      "Epoch 89: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.46it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620]\n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620]        \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480]        \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.81it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.470]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 374.96it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=2.090]       \n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=2.090]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=2.090]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=2.090]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=2.090]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=2.090]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=2.090]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=2.090]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=2.090]        \n",
      "Epoch 115: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.32it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=2.090]\n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=2.090]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=2.090]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=2.090]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=2.090]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=2.090]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=2.090]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=2.090]        \n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.090]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=2.090]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=2.090]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=2.090]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=2.090]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=2.090]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=2.090]        \n",
      "Epoch 138: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.67it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=2.090]\n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=2.090]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=2.090]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=2.090]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=2.090]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=2.090]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=2.090]\n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.090]        \n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=2.090]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=2.090]        \n",
      "Epoch 152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.17it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.160, valid_loss=2.090]\n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=2.090]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=2.090]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=2.090]        \n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=2.090]        \n",
      "Epoch 157: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.67it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=2.090]\n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=2.090]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=2.090]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=2.090]        \n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=2.090]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=2.090]        \n",
      "Epoch 164: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.75it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.110, valid_loss=2.090]\n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=2.090]        \n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=2.090]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=2.090]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=2.090]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=2.090]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=2.090]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=2.090]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=2.090]        \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=2.090]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=2.090]        \n",
      "Epoch 181: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.77it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.080, valid_loss=2.090]\n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=2.090]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=2.090]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=2.090]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=2.090]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=2.090]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=2.090]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=2.090]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=2.090]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=2.090]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=0.932, valid_loss=2.090]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=2.090]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=2.090]        \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.924, train_loss_epoch=0.924, valid_loss=2.090]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.71it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.924, valid_loss=2.090]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 360.86it/s]\u001b[A\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=1.860]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=1.860]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=0.921, valid_loss=1.860]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942, valid_loss=1.860]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.903, train_loss_epoch=0.903, valid_loss=1.860]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=1.860]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=1.860]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=1.860]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905, valid_loss=1.860]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922, valid_loss=1.860]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=1.860]        \n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905, valid_loss=1.860]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.830, valid_loss=1.860]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=1.860]        \n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.935, train_loss_epoch=0.935, valid_loss=1.860]        \n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.908, valid_loss=1.860]        \n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=1.860]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887, valid_loss=1.860]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=1.860]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=0.848, valid_loss=1.860]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.877, valid_loss=1.860]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.869, train_loss_epoch=0.869, valid_loss=1.860]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.851, train_loss_epoch=0.851, valid_loss=1.860]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=1.860]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.828, train_loss_epoch=0.828, valid_loss=1.860]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860, valid_loss=1.860]        \n",
      "Epoch 245: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.93it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=1.860]\n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=1.860]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=0.879, valid_loss=1.860]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=1.860]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.756, train_loss_epoch=0.756, valid_loss=1.860]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.786, train_loss_epoch=0.786, valid_loss=1.860]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806, valid_loss=1.860]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=1.860]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.886, train_loss_epoch=0.886, valid_loss=1.860]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=1.860]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.812, valid_loss=1.860]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=0.799, valid_loss=1.860]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.783, valid_loss=1.860]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=1.860]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=1.860]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.774, train_loss_epoch=0.774, valid_loss=1.860]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841, valid_loss=1.860]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.771, train_loss_epoch=0.771, valid_loss=1.860]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.738, train_loss_epoch=0.738, valid_loss=1.860]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.750, train_loss_epoch=0.750, valid_loss=1.860]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=1.860]        \n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.723, train_loss_epoch=0.723, valid_loss=1.860]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.705, train_loss_epoch=0.705, valid_loss=1.860]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=1.860]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.727, train_loss_epoch=0.727, valid_loss=1.860]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719, valid_loss=1.860]        \n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.728, train_loss_epoch=0.728, valid_loss=1.860]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.752, train_loss_epoch=0.752, valid_loss=1.860]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.721, train_loss_epoch=0.721, valid_loss=1.860]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.713, train_loss_epoch=0.713, valid_loss=1.860]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714, valid_loss=1.860]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.705, train_loss_epoch=0.705, valid_loss=1.860]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=1.860]        \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.713, train_loss_epoch=0.713, valid_loss=1.860]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.739, train_loss_epoch=0.739, valid_loss=1.860]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=0.748, valid_loss=1.860]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.882, train_loss_epoch=0.882, valid_loss=1.860]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.727, train_loss_epoch=0.727, valid_loss=1.860]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=1.860]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.800, train_loss_epoch=0.800, valid_loss=1.860]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.39it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.800, valid_loss=1.860]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 281.46it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724, valid_loss=2.790]        \n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.739, train_loss_epoch=0.739, valid_loss=2.790]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.818, train_loss_epoch=0.818, valid_loss=2.790]        \n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=2.790]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=2.790]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.720, train_loss_epoch=0.720, valid_loss=2.790]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741, valid_loss=2.790]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=2.790]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=2.790]        \n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.687, valid_loss=2.790]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718, valid_loss=2.790]        \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.726, train_loss_epoch=0.726, valid_loss=2.790]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=2.790]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.698, valid_loss=2.790]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=2.790]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694, valid_loss=2.790]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.712, valid_loss=2.790]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=2.790]        \n",
      "Epoch 326: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.75it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=2.790]\n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=2.790]        \n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=2.790]        \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741, valid_loss=2.790]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.671, train_loss_epoch=0.671, valid_loss=2.790]        \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=2.790]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.640, train_loss_epoch=0.640, valid_loss=2.790]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.703, train_loss_epoch=0.703, valid_loss=2.790]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=2.790]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.643, train_loss_epoch=0.643, valid_loss=2.790]        \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=2.790]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=2.790]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=2.790]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=2.790]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=2.790]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=2.790]        \n",
      "Epoch 351: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.28it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=2.790]\n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=2.790]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=2.790]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=2.790]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.612, train_loss_epoch=0.612, valid_loss=2.790]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=2.790]        \n",
      "Epoch 359: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.68it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=2.790]\n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=2.790]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=2.790]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=2.790]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=2.790]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=2.790]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=2.790]        \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597, valid_loss=2.790]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597, valid_loss=2.790]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.593, train_loss_epoch=0.593, valid_loss=2.790]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=2.790]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=2.790]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=2.790]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=2.790]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=2.790]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=2.790]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=2.790]        \n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=2.790]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=2.790]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=2.790]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=2.790]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=2.790]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=2.790]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=2.790]\n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=2.790]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=2.790]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.13it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.550, valid_loss=2.790]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=44961)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 314.56it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=44961)\u001b[0m \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.49it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=3.040]\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=3.040]        \n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=3.040]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=3.040]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=3.040]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=3.040]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=3.040]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=3.040]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=3.040]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=3.040]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=3.040]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=3.040]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=3.040]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=3.040]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=3.040]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=3.040]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=3.040]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=3.040]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=3.040]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=3.040]        \n",
      "Epoch 431: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.19it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=3.040]\n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=3.040]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=3.040]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=3.040]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=3.040]        \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=3.040]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=3.040]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=3.040]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=3.040]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=3.040]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=3.040]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=3.040]        \n",
      "Epoch 452: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.30it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.554, valid_loss=3.040]\n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=3.040]        \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=3.040]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=3.040]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=3.040]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=3.040]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=3.040]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=3.040]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=3.040]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=3.040]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=3.040]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=3.040]        \n",
      "Epoch 469: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.99it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=3.040]\n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=3.040]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=3.040]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=3.040]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=3.040]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=3.040]        \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=3.040]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=3.040]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=3.040]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=3.040]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=3.040]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=3.040]        \n",
      "Epoch 490: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.00it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.525, valid_loss=3.040]\n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=3.040]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=3.040]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=3.040]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=3.040]        \n",
      "Epoch 497: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.63it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=3.040]\n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=3.040]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=3.040]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.72it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.513, valid_loss=3.040]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 373.42it/s]\u001b[A\n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=3.300]        \n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=3.300]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=3.300]        \n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=3.300]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=3.300]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=3.300]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=3.300]        \n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=3.300]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=3.300]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=3.300]        \n",
      "Epoch 516: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.09it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.485, valid_loss=3.300]\n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=3.300]        \n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=3.300]        \n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=3.300]        \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=3.300]        \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=3.300]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=3.300]        \n",
      "Epoch 527: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.51it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=3.300]\n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=3.300]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=3.300]        \n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=3.300]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=3.300]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=3.300]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=3.300]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=3.300]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=3.300]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=3.300]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=3.300]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=3.300]        \n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=3.300]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=3.300]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=3.300]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=3.300]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=3.300]        \n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=3.300]        \n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=3.300]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=3.300]        \n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=3.300]        \n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=3.300]        \n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=3.300]        \n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=3.300]        \n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=3.300]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=3.300]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=3.300]        \n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=3.300]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=3.300]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=3.300]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=3.300]        \n",
      "Epoch 580: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.22it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=3.300]\n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=3.300]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=3.300]        \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=3.300]        \n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=3.300]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=3.300]        \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=3.300]        \n",
      "Epoch 590: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.07it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=3.300]\n",
      "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=3.300]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=3.300]        \n",
      "Epoch 592: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.14it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.469, valid_loss=3.300]\n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=3.300]        \n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=3.300]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=3.300]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=3.300]        \n",
      "Epoch 597: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.51it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=3.300]\n",
      "Epoch 597: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.42it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.499, valid_loss=3.300]\n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=3.300]        \n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=3.300]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.54it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.482, valid_loss=3.300]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 313.19it/s]\u001b[A\n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=3.060]        \n",
      "Epoch 602: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.70it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.456, valid_loss=3.060]\n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=3.060]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=3.060]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=3.060]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=3.060]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=3.060]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=3.060]        \n",
      "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=3.060]        \n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=3.060]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=3.060]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=3.060]        \n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=3.060]        \n",
      "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=3.060]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=3.060]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=3.060]        \n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=3.060]        \n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=3.060]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=3.060]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=3.060]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=3.060]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=3.060]        \n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=3.060]        \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=3.060]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=3.060]        \n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=3.060]        \n",
      "Epoch 640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.23it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=3.060]\n",
      "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=3.060]        \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=3.060]        \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=3.060]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=3.060]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=3.060]        \n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=3.060]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=3.060]        \n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=3.060]        \n",
      "Epoch 653: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.18it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=3.060]\n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=3.060]        \n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=3.060]        \n",
      "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=3.060]        \n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=3.060]        \n",
      "Epoch 658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.00it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=3.060]\n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=3.060]        \n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=3.060]        \n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=3.060]        \n",
      "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=3.060]        \n",
      "Epoch 666: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.59it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=3.060]\n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=3.060]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=3.060]        \n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=3.060]        \n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=3.060]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=3.060]        \n",
      "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=3.060]        \n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=3.060]        \n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=3.060]        \n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=3.060]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=3.060]        \n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=3.060]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=3.060]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=3.060]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=3.060]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=3.060]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=3.060]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=3.060]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.96it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.379, valid_loss=3.060]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 361.80it/s]\u001b[A\n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=3.410]        \n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=3.410]        \n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=3.410]        \n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=3.410]        \n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417, valid_loss=3.410]        \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=3.410]        \n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417, valid_loss=3.410]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=3.410]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=3.410]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=3.410]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=3.410]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=3.410]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=3.410]        \n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=3.410]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=3.410]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=3.410]        \n",
      "Epoch 732: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.50it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=3.410]\n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=3.410]        \n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=3.410]        \n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.410]        \n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=3.410]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=3.410]        \n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=3.410]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=3.410]        \n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=3.410]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=3.410]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=3.410]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.410]        \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=3.410]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=3.410]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=3.410]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=3.410]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=3.410]        \n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=3.410]        \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=3.410]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=3.410]        \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=3.410]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=3.410]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=3.410]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=3.410]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=3.410]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.410]        \n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.410]        \n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=3.410]        \n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=3.410]        \n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=3.410]        \n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=3.410]        \n",
      "Epoch 788: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.61it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.374, valid_loss=3.410]\n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=3.410]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=3.410]        \n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=3.410]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=3.410]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=3.410]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=3.410]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=3.410]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.91it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.362, valid_loss=3.410]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 375.63it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=3.380]        \n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=3.380]        \n",
      "Epoch 801: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.21it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.374, valid_loss=3.380]\n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=3.380]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=3.380]        \n",
      "Epoch 805: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.84it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.384, valid_loss=3.380]\n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.380]        \n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=3.380]        \n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=3.380]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=3.380]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=3.380]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=3.380]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.380]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=3.380]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.380]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.380]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.380]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=3.380]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=3.380]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.380]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=3.380]        \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=3.380]        \n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=3.380]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.380]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=3.380]        \n",
      "Epoch 841: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.49it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.359, valid_loss=3.380]\n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=3.380]        \n",
      "Epoch 843: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.50it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.353, valid_loss=3.380]\n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=3.380]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=3.380]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=3.380]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.380]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=3.380]        \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.380]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=3.380]        \n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=3.380]        \n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=3.380]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.380]        \n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.380]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=3.380]        \n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=3.380]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=3.380]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.380]        \n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=3.380]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=3.380]        \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=3.380]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.380]        \n",
      "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.380]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=3.380]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=3.380]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.380]        \n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.380]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=3.380]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.380]        \n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.380]        \n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=3.380]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.380]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.38it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.350, valid_loss=3.380]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 381.37it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.470]        \n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=3.470]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.470]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.470]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.470]        \n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=3.470]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.470]        \n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=3.470]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.470]        \n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.470]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=3.470]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=3.470]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=3.470]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=3.470]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.470]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.470]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.470]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=3.470]        \n",
      "Epoch 933: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.52it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.470]\n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.470]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.470]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.470]        \n",
      "Epoch 939: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.02it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.335, valid_loss=3.470]\n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.470]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.470]        \n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.470]        \n",
      "Epoch 943: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.37it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.470]\n",
      "Epoch 943: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.30it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.343, valid_loss=3.470]\n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.470]        \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=3.470]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=3.470]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=3.470]        \n",
      "Epoch 951: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.90it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.321, valid_loss=3.470]\n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=3.470]        \n",
      "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=3.470]        \n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.470]        \n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.470]        \n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=3.470]        \n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.470]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.470]        \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=3.470]        \n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.470]        \n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.470]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.470]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.470]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.470]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=3.470]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.470]        \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=3.470]        \n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.470]        \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.470]        \n",
      "Epoch 986: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.48it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.470]\n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.470]        \n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.470]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.470]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=3.470]        \n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=3.470]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=3.470]\n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=3.470]        \n",
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.470]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.76it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.339, valid_loss=3.470]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 381.79it/s]\u001b[A\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.54it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.400]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=44961)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=44961)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[36m(_train_tune pid=45541)\u001b[0m Seed set to 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.50it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=2.310]\n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850]       \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920]        \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910]        \n",
      "Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.23it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.820]\n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860]        \n",
      "Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.94it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790]\n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790]\n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770]        \n",
      "Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.23it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790]\n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610]        \n",
      "Epoch 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.94it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.520]\n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480]        \n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470]        \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250]        \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.44it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.120]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 391.70it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.570]       \n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=1.570]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=1.570]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.570]        \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=1.570]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=1.570]        \n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=1.570]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=1.570]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=1.570]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=1.570]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=1.570]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=1.570]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=1.570]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=0.968, valid_loss=1.570]        \n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=1.570]        \n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.864, train_loss_epoch=0.864, valid_loss=1.570]        \n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.898, train_loss_epoch=0.898, valid_loss=1.570]        \n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=1.570]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=1.570]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.849, valid_loss=1.570]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=1.570]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.790, train_loss_epoch=0.790, valid_loss=1.570]        \n",
      "Epoch 143: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.97it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=0.827, valid_loss=1.570]\n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=0.827, valid_loss=1.570]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.820, train_loss_epoch=0.820, valid_loss=1.570]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.790, train_loss_epoch=0.790, valid_loss=1.570]        \n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.798, train_loss_epoch=0.798, valid_loss=1.570]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.773, train_loss_epoch=0.773, valid_loss=1.570]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=1.570]        \n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.770, train_loss_epoch=0.770, valid_loss=1.570]        \n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.744, train_loss_epoch=0.744, valid_loss=1.570]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746, valid_loss=1.570]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.705, train_loss_epoch=0.705, valid_loss=1.570]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.702, train_loss_epoch=0.702, valid_loss=1.570]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.740, train_loss_epoch=0.740, valid_loss=1.570]        \n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.766, valid_loss=1.570]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759, valid_loss=1.570]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=1.570]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.729, train_loss_epoch=0.729, valid_loss=1.570]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.666, train_loss_epoch=0.666, valid_loss=1.570]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=1.570]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=1.570]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=1.570]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=1.570]        \n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660, valid_loss=1.570]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.764, train_loss_epoch=0.764, valid_loss=1.570]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678, valid_loss=1.570]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=1.570]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=1.570]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=1.570]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=1.570]        \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=1.570]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.66it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.613, valid_loss=1.570]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 353.98it/s]\u001b[A\n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=2.110]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=2.110]        \n",
      "Epoch 205: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.32it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.604, valid_loss=2.110]\n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=2.110]        \n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=2.110]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=2.110]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=2.110]        \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=2.110]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=2.110]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=2.110]        \n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=2.110]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=2.110]        \n",
      "Epoch 222: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.01it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=2.110]\n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=2.110]        \n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=2.110]        \n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=2.110]        \n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=2.110]        \n",
      "Epoch 230: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.49it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=2.110]\n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=2.110]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=2.110]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=2.110]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=2.110]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=2.110]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=2.110]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=2.110]        \n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=2.110]        \n",
      "Epoch 245: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.03it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=2.110]\n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=2.110]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=2.110]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=2.110]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=2.110]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=2.110]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=2.110]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=2.110]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=2.110]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464, valid_loss=2.110]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=2.110]        \n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=2.110]        \n",
      "Epoch 267: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.40it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=2.110]\n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=2.110]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=2.110]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=2.110]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=2.110]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=2.110]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=2.110]        \n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=2.110]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=2.110]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=2.110]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=2.110]        \n",
      "Epoch 286: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.55it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=2.110]\n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427, valid_loss=2.110]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=2.110]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=2.110]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=2.110]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=2.110]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=2.110]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=2.110]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.07it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.459, valid_loss=2.110]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 364.56it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=1.800]        \n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=1.800]        \n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=1.800]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=1.800]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=1.800]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=1.800]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=1.800]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=1.800]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=1.800]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=1.800]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=1.800]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=1.800]        \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=1.800]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=1.800]        \n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=1.800]        \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=1.800]        \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=1.800]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=1.800]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=1.800]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=1.800]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=1.800]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=1.800]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=1.800]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=1.800]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=1.800]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=1.800]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=1.800]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=1.800]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=1.800]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=1.800]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=1.800]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=1.800]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=1.800]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=1.800]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=1.800]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=1.800]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=1.800]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=1.800]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=1.800]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=1.800]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=1.800]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=1.800]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=1.800]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=1.800]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=1.800]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=1.800]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=1.800]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=1.800]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=1.800]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=1.800]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=1.800]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.30it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.347, valid_loss=1.800]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 370.78it/s]\u001b[A\n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=1.870]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=1.870]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=1.870]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=1.870]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=1.870]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=1.870]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=1.870]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=1.870]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=1.870]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=1.870]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=1.870]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=1.870]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=1.870]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=1.870]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=1.870]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=1.870]        \n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=1.870]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=1.870]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=1.870]        \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=1.870]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=1.870]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=1.870]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=1.870]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=1.870]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=1.870]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=1.870]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=1.870]        \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=1.870]        \n",
      "Epoch 457: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.07it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=1.870]\n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=1.870]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=1.870]        \n",
      "Epoch 461: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.60it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=1.870]\n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=1.870]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=1.870]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=1.870]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=1.870]\n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=1.870]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=1.870]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=1.870]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=1.870]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=1.870]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=1.870]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=1.870]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=1.870]        \n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=1.870]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=1.870]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=1.870]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=1.870]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=1.870]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=1.870]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=1.870]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=1.870]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=1.870]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.33it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.311, valid_loss=1.870]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 365.07it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=1.560]        \n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=1.560]        \n",
      "Epoch 501: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.45it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.346, valid_loss=1.560]\n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=1.560]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=1.560]        \n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=1.560]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=1.560]        \n",
      "Epoch 506: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.34it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=1.560]\n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=1.560]        \n",
      "Epoch 508: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.41it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=1.560]\n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=1.560]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=1.560]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=1.560]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=1.560]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=1.560]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=1.560]        \n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=1.560]        \n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=1.560]        \n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=1.560]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=1.560]        \n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=1.560]        \n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=1.560]        \n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=1.560]        \n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=1.560]        \n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=1.560]        \n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=1.560]        \n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=1.560]        \n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=1.560]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=1.560]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=1.560]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=1.560]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=1.560]        \n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=1.560]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=1.560]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=1.560]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=1.560]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=1.560]        \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=1.560]        \n",
      "Epoch 561: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.22it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=1.560]\n",
      "Epoch 561: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.12it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.302, valid_loss=1.560]\n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=1.560]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=1.560]        \n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=1.560]        \n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=1.560]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=1.560]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=1.560]        \n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=1.560]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=1.560]        \n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=1.560]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=1.560]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=1.560]        \n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=1.560]        \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=1.560]        \n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=1.560]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=1.560]        \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=1.560]        \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=1.560]        \n",
      "Epoch 590: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.08it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=1.560]\n",
      "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=1.560]        \n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=1.560]        \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=1.560]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=1.560]        \n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=1.560]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.20it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.307, valid_loss=1.560]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 333.23it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=1.470]        \n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=1.470]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=1.470]        \n",
      "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=1.470]        \n",
      "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=1.470]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=1.470]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=1.470]        \n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=1.470]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=1.470]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=1.470]        \n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=1.470]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=1.470]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=1.470]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=1.470]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=1.470]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=1.470]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=1.470]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=1.470]        \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=1.470]        \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=1.470]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=1.470]        \n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=1.470]        \n",
      "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=1.470]        \n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=1.470]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=1.470]        \n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=1.470]        \n",
      "Epoch 649: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.06it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.305, valid_loss=1.470]\n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=1.470]        \n",
      "Epoch 651: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.41it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.310, valid_loss=1.470]\n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=1.470]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=1.470]        \n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=1.470]        \n",
      "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=1.470]        \n",
      "Epoch 659: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.71it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=1.470]\n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=1.470]        \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=1.470]        \n",
      "Epoch 661: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.46it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=1.470]\n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=1.470]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=1.470]        \n",
      "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=1.470]        \n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=1.470]        \n",
      "Epoch 667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.06it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=1.470]\n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=1.470]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=1.470]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=1.470]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=1.470]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=1.470]        \n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=1.470]        \n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=1.470]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=1.470]        \n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=1.470]        \n",
      "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=1.470]        \n",
      "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=1.470]        \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=1.470]        \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=1.470]        \n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=1.470]        \n",
      "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=1.470]        \n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=1.470]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.58it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.281, valid_loss=1.470]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 389.99it/s]\u001b[A\n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=1.710]        \n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=1.710]        \n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=1.710]        \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=1.710]        \n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=1.710]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=1.710]        \n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=1.710]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=1.710]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=1.710]        \n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=1.710]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=1.710]        \n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=1.710]        \n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=1.710]        \n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=1.710]        \n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=1.710]        \n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=1.710]        \n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=1.710]        \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=1.710]        \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=1.710]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=1.710]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=1.710]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=1.710]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=1.710]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=1.710]        \n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=1.710]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=1.710]        \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=1.710]        \n",
      "Epoch 749: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.26it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=1.710]\n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=1.710]        \n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=1.710]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=1.710]        \n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=1.710]        \n",
      "Epoch 756: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.21it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=1.710]\n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=1.710]        \n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=1.710]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=1.710]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=1.710]        \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=1.710]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=1.710]        \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=1.710]        \n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=1.710]        \n",
      "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=1.710]        \n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=1.710]        \n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=1.710]        \n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=1.710]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=1.710]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=1.710]        \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=1.710]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=1.710]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=1.710]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=1.710]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=1.710]        \n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=1.710]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=1.710]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=1.710]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.28it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.270, valid_loss=1.710]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 321.03it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=45541)\u001b[0m \n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=1.730]        \n",
      "Epoch 801: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.89it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=1.730]\n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=1.730]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=1.730]        \n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=1.730]        \n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=1.730]        \n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=1.730]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=1.730]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=1.730]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=1.730]        \n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=1.730]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=1.730]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=1.730]        \n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=1.730]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=1.730]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=1.730]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=1.730]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=1.730]        \n",
      "Epoch 829: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.63it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=1.730]\n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=1.730]        \n",
      "Epoch 831: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.80it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=1.730]\n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=1.730]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=1.730]        \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=1.730]        \n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=1.730]        \n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=1.730]        \n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=1.730]        \n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=1.730]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=1.730]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=1.730]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=1.730]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=1.730]        \n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=1.730]        \n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=1.730]        \n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=1.730]        \n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=1.730]        \n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=1.730]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=1.730]        \n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=1.730]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=1.730]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=1.730]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=1.730]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=1.730]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=1.730]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=1.730]        \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=1.730]        \n",
      "Epoch 877: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.07it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=1.730]\n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=1.730]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=1.730]        \n",
      "Epoch 879: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.73it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=1.730]\n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=1.730]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=1.730]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=1.730]        \n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=1.730]        \n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=1.730]        \n",
      "Epoch 889: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.35it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=1.730]\n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=1.730]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=1.730]        \n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=1.730]        \n",
      "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=1.730]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=1.730]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=1.730]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.85it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=1.730]\n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.75it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.291, valid_loss=1.730]\n",
      "\u001b[36m(_train_tune pid=45541)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 356.99it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=45541)\u001b[0m \n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=1.760]        \n",
      "Epoch 901: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.20it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=1.760]\n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=1.760]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=1.760]        \n",
      "Epoch 903: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.60it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.295, valid_loss=1.760]\n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=1.760]        \n",
      "Epoch 905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.07it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.275, valid_loss=1.760]\n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=1.760]        \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=1.760]        \n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=1.760]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=1.760]        \n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=1.760]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=1.760]        \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=1.760]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=1.760]        \n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=1.760]        \n",
      "Epoch 922: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.34it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=1.760]\n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=1.760]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=1.760]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=1.760]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=1.760]        \n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=1.760]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=1.760]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=1.760]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=1.760]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=1.760]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=1.760]        \n",
      "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=1.760]        \n",
      "Epoch 939: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.14it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=1.760]\n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=1.760]        \n",
      "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=1.760]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=1.760]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=1.760]        \n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=1.760]        \n",
      "Epoch 945: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.96it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.279, valid_loss=1.760]\n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=1.760]        \n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=1.760]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=1.760]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=1.760]        \n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=1.760]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=1.760]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=1.760]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=1.760]        \n",
      "Epoch 958: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.19it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=1.760]\n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=1.760]        \n",
      "Epoch 960: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.81it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=1.760]\n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=1.760]        \n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=1.760]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=1.760]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=1.760]        \n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=1.760]        \n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=1.760]        \n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=1.760]        \n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=1.760]        \n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=1.760]        \n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=1.760]        \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=1.760]        \n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=1.760]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=1.760]        \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=1.760]        \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=1.760]        \n",
      "Epoch 985: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.20it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=1.760]\n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=1.760]        \n",
      "Epoch 987: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.14it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=1.760]\n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=1.760]        \n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=1.760]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=1.760]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=1.760]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=1.760]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=1.760]        \n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=1.760]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.69it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.271, valid_loss=1.760]\n",
      "\u001b[36m(_train_tune pid=45541)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=45541)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 328.50it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=45541)\u001b[0m \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.24it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.271, valid_loss=1.800]\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.88it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=1.800]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=45541)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=45541)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[36m(_train_tune pid=46058)\u001b[0m Seed set to 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920]       \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100]        \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070]        \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770]\n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070]        \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710]        \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780]        \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750]        \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870]        \n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710]        \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460]        \n",
      "Epoch 78: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.64it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.460]\n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410]        \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270]        \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.38it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.180]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 394.31it/s]\u001b[A\n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.529]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.529]        \n",
      "Epoch 103: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.40it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.529]\n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.529]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.529]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.529]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.529]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.529]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.529]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.529]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.529]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.529]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.529]        \n",
      "Epoch 123: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.77it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.529]\n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.529]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.529]        \n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.529]        \n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.529]        \n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.529]        \n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.529]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.529]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.529]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.529]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=0.529]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=0.529]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.529]        \n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.529]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=0.529]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.529]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.529]\n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.529]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.529]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.529]        \n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.529]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.529]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.529]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.529]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.529]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.529]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.529]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.529]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.529]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.529]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.529]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.529]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.529]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.529]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.529]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.529]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.529]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.529]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.84it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.570, valid_loss=0.529]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 399.38it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=3.170]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=3.170]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=3.170]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.170]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.170]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.170]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.170]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.170]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.170]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.170]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.170]        \n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.170]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.170]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.170]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.170]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.170]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.170]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.170]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.170]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.170]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.170]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.170]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=3.170]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=3.170]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.170]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=3.170]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.170]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=3.170]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.170]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.170]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.170]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=3.170]        \n",
      "Epoch 260: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.33it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.170]\n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.170]        \n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=3.170]        \n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.170]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.170]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.170]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.170]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.170]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.170]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.170]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.170]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.170]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.170]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.170]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.170]        \n",
      "Epoch 289: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.07it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.170]\n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.170]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.170]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.170]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.170]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.170]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.99it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=0.974, valid_loss=3.170]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 391.11it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=2.150]        \n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=2.150]        \n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=2.150]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=2.150]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=2.150]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=2.150]        \n",
      "Epoch 312: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.68it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=1.010, valid_loss=2.150]\n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974, valid_loss=2.150]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=2.150]        \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=2.150]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=2.150]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=2.150]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=2.150]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=2.150]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=2.150]        \n",
      "Epoch 327: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.87it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953, valid_loss=2.150]\n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953, valid_loss=2.150]        \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=2.150]        \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=2.150]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942, valid_loss=2.150]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=0.894, valid_loss=2.150]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841, valid_loss=2.150]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.826, train_loss_epoch=0.826, valid_loss=2.150]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.844, train_loss_epoch=0.844, valid_loss=2.150]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.815, train_loss_epoch=0.815, valid_loss=2.150]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=2.150]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.749, valid_loss=2.150]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.812, valid_loss=2.150]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.726, train_loss_epoch=0.726, valid_loss=2.150]        \n",
      "Epoch 352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.55it/s, v_num=0, train_loss_step=0.765, train_loss_epoch=0.726, valid_loss=2.150]\n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.765, train_loss_epoch=0.765, valid_loss=2.150]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.710, train_loss_epoch=0.710, valid_loss=2.150]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.755, train_loss_epoch=0.755, valid_loss=2.150]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.710, train_loss_epoch=0.710, valid_loss=2.150]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.738, train_loss_epoch=0.738, valid_loss=2.150]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=0.748, valid_loss=2.150]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.726, train_loss_epoch=0.726, valid_loss=2.150]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.715, valid_loss=2.150]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.680, valid_loss=2.150]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=2.150]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.733, train_loss_epoch=0.733, valid_loss=2.150]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.678, train_loss_epoch=0.678, valid_loss=2.150]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=2.150]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=2.150]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=2.150]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670, valid_loss=2.150]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.671, train_loss_epoch=0.671, valid_loss=2.150]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=2.150]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=2.150]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=2.150]        \n",
      "Epoch 391: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.34it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=2.150]\n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=2.150]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=2.150]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=2.150]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=2.150]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=2.150]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.27it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.635, valid_loss=2.150]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 372.99it/s]\u001b[A\n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.35it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.635, valid_loss=2.430]\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=2.430]        \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=2.430]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=2.430]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=2.430]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=2.430]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=2.430]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=2.430]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=2.430]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.647, train_loss_epoch=0.647, valid_loss=2.430]        \n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.647, train_loss_epoch=0.647, valid_loss=2.430]\n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=2.430]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=2.430]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=2.430]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=2.430]        \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=2.430]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=2.430]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=2.430]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=2.430]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=2.430]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=2.430]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=2.430]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=2.430]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=2.430]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=2.430]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=2.430]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=2.430]        \n",
      "Epoch 446: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.95it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=2.430]\n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=2.430]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=2.430]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=2.430]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=2.430]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=2.430]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=2.430]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=2.430]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=2.430]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=2.430]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=2.430]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=2.430]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=2.430]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=2.430]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=2.430]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=2.430]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=2.430]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=2.430]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=2.430]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=2.430]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=2.430]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=2.430]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=2.430]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=2.430]        \n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=2.430]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=2.430]        \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=2.430]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=2.430]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.03it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.536, valid_loss=2.430]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 391.99it/s]\u001b[A\n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=2.820]        \n",
      "Epoch 502: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.52it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=2.820]\n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=2.820]        \n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=2.820]        \n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=2.820]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=2.820]        \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=2.820]        \n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=2.820]        \n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=2.820]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=2.820]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=2.820]        \n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=2.820]        \n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=2.820]        \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=2.820]\n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=2.820]        \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=2.820]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=2.820]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=2.820]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=2.820]        \n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=2.820]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=2.820]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=2.820]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=2.820]        \n",
      "Epoch 538: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.29it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.483, valid_loss=2.820]\n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=2.820]        \n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=2.820]        \n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=2.820]        \n",
      "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=2.820]        \n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=2.820]        \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=2.820]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=2.820]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=2.820]        \n",
      "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=2.820]        \n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=2.820]        \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=2.820]        \n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=2.820]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=2.820]        \n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=2.820]        \n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=2.820]        \n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=2.820]        \n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=2.820]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=2.820]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=2.820]        \n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=2.820]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=2.820]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=2.820]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=2.820]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=2.820]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=2.820]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=2.820]        \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=2.820]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=2.820]        \n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=2.820]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=2.820]        \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=2.820]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.28it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.490, valid_loss=2.820]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 325.24it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=2.760]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=2.760]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=2.760]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=2.760]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=2.760]        \n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=2.760]        \n",
      "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=2.760]        \n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=2.760]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=2.760]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=2.760]        \n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=2.760]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=2.760]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=2.760]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=2.760]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=2.760]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=2.760]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=2.760]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=2.760]        \n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=2.760]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=2.760]        \n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=2.760]        \n",
      "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=2.760]        \n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=2.760]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=2.760]        \n",
      "Epoch 646: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.86it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.365, valid_loss=2.760]\n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=2.760]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=2.760]        \n",
      "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417, valid_loss=2.760]        \n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=2.760]        \n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=2.760]        \n",
      "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=2.760]        \n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=2.760]        \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=2.760]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=2.760]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=2.760]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=2.760]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=2.760]        \n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=2.760]        \n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=2.760]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=2.760]        \n",
      "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=2.760]        \n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=2.760]        \n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=2.760]        \n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=2.760]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=2.760]        \n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=2.760]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=2.760]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=2.760]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=2.760]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=2.760]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=2.760]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=2.760]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.75it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.291, valid_loss=2.760]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 370.10it/s]\u001b[A\n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=2.830]        \n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=2.830]        \n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=2.830]        \n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=2.830]        \n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=2.830]        \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=2.830]        \n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=2.830]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=2.830]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=2.830]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=2.830]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=2.830]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=2.830]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=2.830]        \n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=2.830]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=2.830]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=2.830]        \n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=2.830]        \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=2.830]        \n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=2.830]\n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=2.830]        \n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=2.830]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=2.830]        \n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=2.830]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=2.830]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=2.830]        \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=2.830]        \n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=2.830]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=2.830]        \n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=2.830]        \n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=2.830]        \n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=2.830]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=2.830]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=2.830]        \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=2.830]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=2.830]        \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=2.830]        \n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=2.830]        \n",
      "Epoch 773: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.92it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.262, valid_loss=2.830]\n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=2.830]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=2.830]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=2.830]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=2.830]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=2.830]        \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=2.830]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=2.830]        \n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=2.830]        \n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=2.830]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=2.830]        \n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=2.830]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=2.830]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=2.830]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.38it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.243, valid_loss=2.830]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 368.60it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=2.690]        \n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=2.690]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=2.690]        \n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=2.690]        \n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=2.690]        \n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248, valid_loss=2.690]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=2.690]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=2.690]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=2.690]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=2.690]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=2.690]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=2.690]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=2.690]        \n",
      "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=2.690]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=2.690]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=2.690]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=2.690]        \n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=2.690]        \n",
      "Epoch 831: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.90it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=2.690]\n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=2.690]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=2.690]        \n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=2.690]        \n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=2.690]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=2.690]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=2.690]        \n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=2.690]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=2.690]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=2.690]        \n",
      "Epoch 845: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.18it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=2.690]\n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=2.690]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=2.690]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=2.690]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=2.690]        \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=2.690]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=2.690]        \n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=2.690]        \n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=2.690]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=2.690]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=2.690]        \n",
      "Epoch 863: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.13it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=2.690]\n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=2.690]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=2.690]        \n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=2.690]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=2.690]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=2.690]        \n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=2.690]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=2.690]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=2.690]        \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=2.690]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=2.690]        \n",
      "Epoch 883: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.01it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.240, valid_loss=2.690]\n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=2.690]        \n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=2.690]        \n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=2.690]        \n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=2.690]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=2.690]        \n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=2.690]        \n",
      "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=2.690]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=2.690]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.11it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.219, valid_loss=2.690]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 377.25it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=46058)\u001b[0m \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.65it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=2.810]\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=2.810]        \n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=2.810]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=2.810]        \n",
      "Epoch 903: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.54it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=2.810]\n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=2.810]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=2.810]        \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=2.810]        \n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=2.810]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=2.810]        \n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=2.810]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=2.810]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=2.810]        \n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=2.810]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=2.810]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=2.810]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=2.810]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=2.810]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=2.810]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=2.810]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=2.810]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=2.810]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=2.810]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=2.810]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=2.810]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=2.810]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=2.810]        \n",
      "Epoch 945: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.67it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=2.810]\n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=2.810]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=2.810]        \n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=2.810]        \n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=2.810]        \n",
      "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=2.810]        \n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=2.810]        \n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=2.810]        \n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=2.810]        \n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=2.810]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=2.810]        \n",
      "Epoch 965: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.30it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=2.810]\n",
      "Epoch 965: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.23it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.214, valid_loss=2.810]\n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=2.810]        \n",
      "Epoch 967: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.26it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=2.810]\n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=2.810]        \n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=2.810]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=2.810]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=2.810]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=2.810]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=2.810]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=2.810]        \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=2.810]        \n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=2.810]        \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=2.810]        \n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=2.810]        \n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=2.810]        \n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=2.810]        \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=2.810]        \n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=2.810]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=2.810]        \n",
      "Epoch 997: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.06it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=2.810]\n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=2.810]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.24it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.196, valid_loss=2.810]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 340.14it/s]\u001b[A\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.91it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=2.880]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=46058)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=46058)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[36m(_train_tune pid=46574)\u001b[0m Seed set to 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240]        \n",
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.72it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]\n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]        \n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.02it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]\n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.67it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.150]\n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190]        \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.966]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.882, train_loss_epoch=0.882]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=0.885]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=0.846]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=0.848]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.825, train_loss_epoch=0.825]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=0.879]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=0.803]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.793, train_loss_epoch=0.793]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=0.762]        \n",
      "Epoch 81: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.47it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=0.801]\n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=0.801]        \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.756, train_loss_epoch=0.756]        \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.716]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.775, train_loss_epoch=0.775]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.727, train_loss_epoch=0.727]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.720, train_loss_epoch=0.720]        \n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.707, train_loss_epoch=0.707]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.42it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.717]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 395.58it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=46574)\u001b[0m \n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.716, valid_loss=2.410]        \n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661, valid_loss=2.410]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=2.410]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=2.410]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=2.410]        \n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=2.410]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=2.410]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=2.410]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=2.410]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=2.410]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=2.410]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=2.410]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=2.410]        \n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=2.410]        \n",
      "Epoch 130: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.54it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.548, valid_loss=2.410]\n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=2.410]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=2.410]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=2.410]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=2.410]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=2.410]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=2.410]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=2.410]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=2.410]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=2.410]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=2.410]        \n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=2.410]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=2.410]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=2.410]        \n",
      "Epoch 153: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.94it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=2.410]\n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=2.410]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=2.410]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=2.410]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=2.410]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=2.410]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=2.410]        \n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=2.410]        \n",
      "Epoch 168: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.78it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=2.410]\n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=2.410]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=2.410]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=2.410]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=2.410]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=2.410]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=2.410]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=2.410]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=2.410]        \n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=2.410]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=2.410]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=2.410]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=2.410]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=2.410]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=2.410]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=2.410]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.08it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.385, valid_loss=2.410]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 377.80it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=46574)\u001b[0m \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=3.600]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=3.600]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=3.600]        \n",
      "Epoch 205: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.16it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=3.600]\n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=3.600]        \n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=3.600]        \n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=3.600]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=3.600]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=3.600]        \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=3.600]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=3.600]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=3.600]        \n",
      "Epoch 219: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.02it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.600]\n",
      "Epoch 219: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.91it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.361, valid_loss=3.600]\n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=3.600]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=3.600]        \n",
      "Epoch 224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.61it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=3.600]\n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.600]        \n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=3.600]        \n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=3.600]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=3.600]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=3.600]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.391, valid_loss=3.600]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=3.600]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.600]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=3.600]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.600]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=3.600]        \n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=3.600]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=3.600]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=3.600]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.600]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=3.600]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.600]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=3.600]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.600]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.600]        \n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.600]        \n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=3.600]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=3.600]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=3.600]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=3.600]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=3.600]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.600]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=3.600]        \n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.600]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=3.600]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.600]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.600]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.600]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=3.600]        \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.600]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.600]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=3.600]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=3.600]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=3.600]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.15it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.288, valid_loss=3.600]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 387.75it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=46574)\u001b[0m \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.33it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=3.950]\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=3.950]        \n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=3.950]        \n",
      "Epoch 301: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.13it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=3.950]\n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=3.950]        \n",
      "Epoch 303: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.21it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=3.950]\n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=3.950]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=3.950]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=3.950]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=3.950]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=3.950]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.950]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=3.950]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=3.950]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=3.950]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=3.950]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=3.950]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=3.950]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=3.950]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=3.950]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=3.950]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=3.950]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=3.950]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=3.950]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=3.950]        \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=3.950]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=3.950]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=3.950]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=3.950]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=3.950]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=3.950]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=3.950]        \n",
      "Epoch 351: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.15it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=3.950]\n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=3.950]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=3.950]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=3.950]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=3.950]        \n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=3.950]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=3.950]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=3.950]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=3.950]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=3.950]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=3.950]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=3.950]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=3.950]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=3.950]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=3.950]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=3.950]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=3.950]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=3.950]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=3.950]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=3.950]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=3.950]        \n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=3.950]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.950]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=3.950]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.950]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=3.950]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.950]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=3.950]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.27it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.213, valid_loss=3.950]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 352.85it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=3.750]        \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=3.750]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=3.750]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=3.750]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=3.750]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.750]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=3.750]        \n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=3.750]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=3.750]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=3.750]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=3.750]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=3.750]        \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=3.750]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=3.750]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.750]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=3.750]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=3.750]        \n",
      "Epoch 432: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.95it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=3.750]\n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=3.750]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=3.750]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=3.750]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=3.750]        \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.750]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=3.750]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.750]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=3.750]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.750]        \n",
      "Epoch 449: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.80it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=3.750]\n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.750]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=3.750]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=3.750]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=3.750]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=3.750]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=3.750]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=3.750]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=3.750]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=3.750]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.750]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.750]        \n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=3.750]        \n",
      "Epoch 473: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.99it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=3.750]\n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=3.750]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.750]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=3.750]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=3.750]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=3.750]        \n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.750]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=3.750]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=3.750]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=3.750]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=3.750]        \n",
      "Epoch 492: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.86it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=3.750]\n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=3.750]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=3.750]        \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.750]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.750]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.750]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.22it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.208, valid_loss=3.750]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 384.45it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.900]        \n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=3.900]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=3.900]        \n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=3.900]        \n",
      "Epoch 506: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.56it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.900]\n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.900]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=3.900]        \n",
      "Epoch 510: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.02it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.200, valid_loss=3.900]\n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.900]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.900]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=3.900]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=3.900]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.900]        \n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=3.900]        \n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.900]        \n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=3.900]        \n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=3.900]        \n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=3.900]        \n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=3.900]        \n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=3.900]        \n",
      "Epoch 533: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.06it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.900]\n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.900]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.900]        \n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=3.900]        \n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=3.900]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=3.900]        \n",
      "Epoch 541: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.01it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.900]\n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.900]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=3.900]        \n",
      "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=3.900]        \n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=3.900]        \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.900]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.900]        \n",
      "Epoch 553: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.36it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=3.900]\n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=3.900]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.900]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=3.900]        \n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.900]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=3.900]        \n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=3.900]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=3.900]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=3.900]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=3.900]        \n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=3.900]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.900]        \n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.900]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=3.900]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=3.900]        \n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=3.900]        \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.900]        \n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=3.900]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.900]        \n",
      "Epoch 587: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.72it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.900]\n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.900]        \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.900]        \n",
      "Epoch 589: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.81it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=3.900]\n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=3.900]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=3.900]        \n",
      "Epoch 593: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.47it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.179, valid_loss=3.900]\n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.900]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.900]        \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=3.900]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.38it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.186, valid_loss=3.900]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 377.63it/s]\u001b[A\n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.67it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.186, valid_loss=4.000]\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=4.000]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=4.000]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=4.000]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=4.000]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=4.000]        \n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=4.000]        \n",
      "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=4.000]        \n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=4.000]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=4.000]        \n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=4.000]        \n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=4.000]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=4.000]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=4.000]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=4.000]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=4.000]        \n",
      "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=4.000]        \n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=4.000]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=4.000]        \n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=4.000]        \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=4.000]        \n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=4.000]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=4.000]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=4.000]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=4.000]        \n",
      "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=4.000]        \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=4.000]        \n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=4.000]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=4.000]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=4.000]        \n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=4.000]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=4.000]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=4.000]        \n",
      "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=4.000]        \n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=4.000]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=4.000]        \n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=4.000]        \n",
      "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=4.000]        \n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=4.000]        \n",
      "Epoch 658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.90it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=4.000]\n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=4.000]        \n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=4.000]        \n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=4.000]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=4.000]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=4.000]        \n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=4.000]        \n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=4.000]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=4.000]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=4.000]        \n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=4.000]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=4.000]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=4.000]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=4.000]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=4.000]        \n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=4.000]        \n",
      "Epoch 679: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.78it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=4.000]\n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=4.000]        \n",
      "Epoch 681: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.46it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=4.000]\n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=4.000]        \n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=4.000]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=4.000]        \n",
      "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=4.000]        \n",
      "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=4.000]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=4.000]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=4.000]        \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=4.000]        \n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=4.000]        \n",
      "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=4.000]        \n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=4.000]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=4.000]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.99it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.188, valid_loss=4.000]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 342.48it/s]\u001b[A\n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=3.740]        \n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=3.740]        \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.740]        \n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=3.740]        \n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=3.740]        \n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=3.740]        \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=3.740]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.740]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=3.740]        \n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=3.740]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=3.740]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=3.740]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=3.740]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=3.740]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.740]        \n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=3.740]        \n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.740]        \n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.740]        \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=3.740]        \n",
      "Epoch 733: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.97it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=3.740]\n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=3.740]        \n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.740]        \n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=3.740]        \n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=3.740]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=3.740]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=3.740]        \n",
      "Epoch 742: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.22it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.169, valid_loss=3.740]\n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=3.740]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=3.740]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=3.740]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=3.740]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=3.740]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=3.740]        \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=3.740]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.740]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=3.740]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.740]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=3.740]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=3.740]        \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.740]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.740]        \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=3.740]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=3.740]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=3.740]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=3.740]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.740]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=3.740]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=3.740]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=3.740]        \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=3.740]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=3.740]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.740]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=3.740]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=3.740]        \n",
      "Epoch 793: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.07it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.740]\n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.740]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=3.740]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=3.740]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=3.740]        \n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=3.740]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.63it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.168, valid_loss=3.740]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 361.24it/s]\u001b[A\n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=3.750]        \n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=3.750]        \n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.750]        \n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=3.750]        \n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=3.750]        \n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=3.750]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=3.750]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=3.750]        \n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=3.750]        \n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=3.750]        \n",
      "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=3.750]        \n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=3.750]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=3.750]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=3.750]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=3.750]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=3.750]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=3.750]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.750]        \n",
      "Epoch 833: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.99it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=3.750]\n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=3.750]        \n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.750]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=3.750]        \n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=3.750]        \n",
      "Epoch 838: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.77it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=3.750]\n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=3.750]        \n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=3.750]        \n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.750]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=3.750]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=3.750]        \n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=3.750]        \n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=3.750]        \n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=3.750]        \n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.750]        \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=3.750]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=3.750]        \n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=3.750]        \n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.750]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=3.750]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=3.750]        \n",
      "Epoch 863: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.11it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=3.750]\n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=3.750]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=3.750]        \n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=3.750]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.750]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=3.750]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.750]        \n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=3.750]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=3.750]        \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=3.750]        \n",
      "Epoch 877: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.69it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=3.750]\n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=3.750]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.750]        \n",
      "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=3.750]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=3.750]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=3.750]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=3.750]        \n",
      "Epoch 888: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.34it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=3.750]\n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=3.750]        \n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=3.750]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.750]        \n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=3.750]        \n",
      "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=3.750]        \n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=3.750]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=3.750]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.00it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.159, valid_loss=3.750]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 353.74it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=3.730]        \n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=3.730]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=3.730]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=3.730]        \n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=3.730]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=3.730]        \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=3.730]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=3.730]        \n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=3.730]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=3.730]        \n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=3.730]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=3.730]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=3.730]        \n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=3.730]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=3.730]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=3.730]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=3.730]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=3.730]        \n",
      "Epoch 927: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.01it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=3.730]\n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=3.730]        \n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.730]        \n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.730]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=3.730]        \n",
      "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=3.730]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=3.730]        \n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=3.730]        \n",
      "Epoch 937: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.76it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=3.730]\n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=3.730]        \n",
      "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=3.730]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=3.730]        \n",
      "Epoch 940: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.54it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=3.730]\n",
      "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=3.730]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=3.730]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=3.730]        \n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=3.730]        \n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=3.730]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.730]        \n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=3.730]        \n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=3.730]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=3.730]        \n",
      "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=3.730]        \n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=3.730]        \n",
      "Epoch 957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.46it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=3.730]\n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=3.730]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=3.730]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=3.730]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=3.730]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=3.730]        \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=3.730]        \n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=3.730]        \n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=3.730]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=3.730]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=3.730]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=3.730]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=3.730]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=3.730]        \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=3.730]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=3.730]        \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=3.730]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=3.730]        \n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=3.730]        \n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=3.730]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=3.730]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=3.730]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=3.730]        \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=3.730]        \n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=3.730]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.16it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.161, valid_loss=3.730]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 355.00it/s]\u001b[A\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.56it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=3.740]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=46574)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=46574)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[36m(_train_tune pid=47121)\u001b[0m Seed set to 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]       \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]        \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]        \n",
      "Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.92it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]\n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]        \n",
      "Epoch 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.68it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]\n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=0.968]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=0.923]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.934, train_loss_epoch=0.934]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.942, train_loss_epoch=0.942]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.910, train_loss_epoch=0.910]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.862, train_loss_epoch=0.862]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.858, train_loss_epoch=0.858]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.877]        \n",
      "Epoch 89: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.98it/s, v_num=0, train_loss_step=0.840, train_loss_epoch=0.863]\n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.840, train_loss_epoch=0.840]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.845, train_loss_epoch=0.845]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.868, train_loss_epoch=0.868]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860]        \n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=0.799]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.88it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=0.821]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 392.28it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=0.751, valid_loss=0.420]       \n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.787, train_loss_epoch=0.787, valid_loss=0.420]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.768, train_loss_epoch=0.768, valid_loss=0.420]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=0.420]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.733, train_loss_epoch=0.733, valid_loss=0.420]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.785, train_loss_epoch=0.785, valid_loss=0.420]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.736, train_loss_epoch=0.736, valid_loss=0.420]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.740, train_loss_epoch=0.740, valid_loss=0.420]        \n",
      "Epoch 114: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.62it/s, v_num=0, train_loss_step=0.740, train_loss_epoch=0.740, valid_loss=0.420]\n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.740, train_loss_epoch=0.740, valid_loss=0.420]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.775, train_loss_epoch=0.775, valid_loss=0.420]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.740, train_loss_epoch=0.740, valid_loss=0.420]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.715, valid_loss=0.420]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=0.420]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.705, train_loss_epoch=0.705, valid_loss=0.420]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673, valid_loss=0.420]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=0.420]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.702, train_loss_epoch=0.702, valid_loss=0.420]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.420]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=0.420]        \n",
      "Epoch 133: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.63it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=0.420]\n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=0.420]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=0.420]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=0.420]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.667, train_loss_epoch=0.667, valid_loss=0.420]        \n",
      "Epoch 139: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.61it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665, valid_loss=0.420]\n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665, valid_loss=0.420]        \n",
      "Epoch 141: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.49it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.420]\n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=0.420]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.636, train_loss_epoch=0.636, valid_loss=0.420]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.420]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.420]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=0.420]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.420]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.420]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=0.420]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.420]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.420]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=0.420]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.420]        \n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.420]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.420]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.420]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.420]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.420]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.420]        \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=0.420]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=0.420]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.420]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=0.420]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.420]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.420]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.420]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.420]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.420]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=0.420]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.420]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.90it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.502, valid_loss=0.420]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 364.53it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=2.030]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=2.030]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=2.030]        \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=2.030]        \n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=2.030]        \n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=2.030]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=2.030]        \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=2.030]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=2.030]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=2.030]        \n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=2.030]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=2.030]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=2.030]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=2.030]        \n",
      "Epoch 228: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.40it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=2.030]\n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=2.030]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=2.030]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=2.030]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=2.030]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=2.030]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=2.030]        \n",
      "Epoch 237: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.88it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=2.030]\n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=2.030]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=2.030]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=2.030]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=2.030]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=2.030]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=2.030]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=2.030]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=2.030]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=2.030]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=2.030]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=2.030]        \n",
      "Epoch 258: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.33it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=2.030]\n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=2.030]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=2.030]        \n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=2.030]        \n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=2.030]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=2.030]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=2.030]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=2.030]        \n",
      "Epoch 272: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.38it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=2.030]\n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=2.030]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=2.030]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=2.030]        \n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=2.030]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=2.030]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=2.030]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=2.030]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=2.030]        \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=2.030]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=2.030]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=2.030]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=2.030]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=2.030]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.55it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.375, valid_loss=2.030]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 397.64it/s]\u001b[A\n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=2.280]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=2.280]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=2.280]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=2.280]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=2.280]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=2.280]        \n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=2.280]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=2.280]        \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=2.280]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=2.280]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=2.280]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=2.280]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=2.280]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=2.280]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=2.280]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=2.280]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=2.280]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=2.280]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=2.280]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=2.280]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=2.280]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=2.280]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=2.280]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=2.280]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=2.280]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=2.280]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=2.280]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=2.280]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=2.280]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=2.280]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=2.280]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=2.280]        \n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=2.280]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=2.280]        \n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=2.280]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=2.280]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=2.280]        \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=2.280]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=2.280]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=2.280]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=2.280]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=2.280]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=2.280]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=2.280]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=2.280]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=2.280]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=2.280]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=2.280]        \n",
      "Epoch 390: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.80it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=2.280]\n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=2.280]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=2.280]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=2.280]        \n",
      "Epoch 396: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.16it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=2.280]\n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=2.280]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=2.280]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.85it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.311, valid_loss=2.280]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 376.95it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=1.770]        \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=1.770]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=1.770]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=1.770]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=1.770]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=1.770]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=1.770]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=1.770]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=1.770]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=1.770]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=1.770]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=1.770]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=1.770]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=1.770]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=1.770]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=1.770]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=1.770]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=1.770]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=1.770]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=1.770]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=1.770]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=1.770]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=1.770]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=1.770]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=1.770]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=1.770]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=1.770]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=1.770]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=1.770]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=1.770]        \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=1.770]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=1.770]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=1.770]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=1.770]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=1.770]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=1.770]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=1.770]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=1.770]        \n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=1.770]        \n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=1.770]        \n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=1.770]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=1.770]        \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=1.770]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=1.770]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=1.770]        \n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=1.770]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=1.770]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=1.770]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=1.770]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=1.770]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=1.770]        \n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=1.770]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=1.770]        \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=1.770]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=1.770]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.19it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.263, valid_loss=1.770]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 378.79it/s]\u001b[A\n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=1.860]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=1.860]        \n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=1.860]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=1.860]        \n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=1.860]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=1.860]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=1.860]        \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=1.860]        \n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=1.860]        \n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=1.860]        \n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=1.860]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=1.860]        \n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=1.860]        \n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=1.860]        \n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=1.860]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=1.860]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=1.860]        \n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=1.860]\n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=1.860]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=1.860]        \n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=1.860]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=1.860]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=1.860]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=1.860]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=1.860]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=1.860]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=1.860]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=1.860]        \n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=1.860]        \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=1.860]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=1.860]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=1.860]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=1.860]        \n",
      "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=1.860]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=1.860]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=1.860]        \n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=1.860]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=1.860]        \n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=1.860]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=1.860]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=1.860]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=1.860]        \n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=1.860]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=1.860]        \n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=1.860]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=1.860]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=1.860]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=1.860]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=1.860]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=1.860]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=1.860]        \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=1.860]        \n",
      "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=1.860]        \n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=1.860]        \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=1.860]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=1.860]        \n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=1.860]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.56it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.238, valid_loss=1.860]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 382.69it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=1.280]        \n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=1.280]        \n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=1.280]        \n",
      "Epoch 604: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.45it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=1.280]\n",
      "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=1.280]        \n",
      "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=1.280]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=1.280]        \n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=1.280]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=1.280]        \n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=1.280]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=1.280]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=1.280]        \n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=1.280]        \n",
      "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=1.280]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=1.280]\n",
      "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=1.280]        \n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=1.280]        \n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=1.280]        \n",
      "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=1.280]        \n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=1.280]        \n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=1.280]        \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=1.280]        \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=1.280]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=1.280]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=1.280]        \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=1.280]        \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=1.280]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=1.280]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=1.280]        \n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=1.280]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=1.280]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=1.280]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=1.280]        \n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=1.280]        \n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=1.280]        \n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=1.280]        \n",
      "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=1.280]        \n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=1.280]        \n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=1.280]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=1.280]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=1.280]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=1.280]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=1.280]        \n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=1.280]        \n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=1.280]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=1.280]        \n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=1.280]        \n",
      "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=1.280]        \n",
      "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=1.280]        \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=1.280]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=1.280]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=1.280]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=1.280]        \n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=1.280]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.93it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.220, valid_loss=1.280]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 379.51it/s]\u001b[A\n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=1.190]        \n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=1.190]        \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=1.190]        \n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=1.190]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=1.190]        \n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=1.190]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=1.190]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=1.190]        \n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=1.190]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=1.190]        \n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=1.190]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=1.190]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=1.190]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=1.190]        \n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=1.190]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=1.190]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=1.190]        \n",
      "Epoch 732: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.69it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.231, valid_loss=1.190]\n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=1.190]        \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=1.190]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=1.190]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=1.190]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=1.190]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=1.190]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=1.190]        \n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=1.190]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=1.190]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=1.190]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=1.190]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=1.190]        \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=1.190]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=1.190]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=1.190]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=1.190]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=1.190]        \n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=1.190]        \n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=1.190]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=1.190]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=1.190]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=1.190]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=1.190]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=1.190]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=1.190]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=1.190]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=1.190]        \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=1.190]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=1.190]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=1.190]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=1.190]        \n",
      "Epoch 791: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.43it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=1.190]\n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=1.190]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=1.190]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=1.190]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=1.190]        \n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=1.190]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.56it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.199, valid_loss=1.190]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 329.07it/s]\u001b[A\n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=1.250]        \n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=1.250]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=1.250]        \n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=1.250]        \n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=1.250]        \n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=1.250]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=1.250]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=1.250]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=1.250]        \n",
      "Epoch 816: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.54it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=1.250]\n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=1.250]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=1.250]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=1.250]        \n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=1.250]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=1.250]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=1.250]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=1.250]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=1.250]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=1.250]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=1.250]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=1.250]        \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=1.250]        \n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=1.250]        \n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=1.250]        \n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=1.250]        \n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=1.250]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=1.250]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=1.250]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=1.250]        \n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=1.250]        \n",
      "Epoch 851: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.97it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.215, valid_loss=1.250]\n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=1.250]        \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=1.250]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=1.250]        \n",
      "Epoch 857: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.50it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.208, valid_loss=1.250]\n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=1.250]        \n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=1.250]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=1.250]        \n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=1.250]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=1.250]        \n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=1.250]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=1.250]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=1.250]        \n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=1.250]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=1.250]        \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=1.250]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=1.250]        \n",
      "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=1.250]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=1.250]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=1.250]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=1.250]        \n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=1.250]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=1.250]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=1.250]        \n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=1.250]        \n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=1.250]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=1.250]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.25it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.206, valid_loss=1.250]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 369.41it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=1.210]        \n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=1.210]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=1.210]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=1.210]        \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=1.210]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=1.210]        \n",
      "Epoch 908: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.05it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=1.210]\n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=1.210]        \n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=1.210]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=1.210]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=1.210]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=1.210]        \n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=1.210]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=1.210]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=1.210]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=1.210]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=1.210]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=1.210]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=1.210]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=1.210]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=1.210]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=1.210]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=1.210]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=1.210]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=1.210]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=1.210]        \n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=1.210]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=1.210]        \n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=1.210]        \n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=1.210]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=1.210]        \n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=1.210]        \n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=1.210]        \n",
      "Epoch 952: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.43it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=1.210]\n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=1.210]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=1.210]        \n",
      "Epoch 956: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.50it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.193, valid_loss=1.210]\n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=1.210]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=1.210]        \n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=1.210]        \n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=1.210]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=1.210]        \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=1.210]        \n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=1.210]        \n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=1.210]        \n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=1.210]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=1.210]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=1.210]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=1.210]        \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=1.210]        \n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=1.210]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=1.210]        \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=1.210]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=1.210]        \n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=1.210]        \n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=1.210]        \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=1.210]        \n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=1.210]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=1.210]        \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=1.210]        \n",
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=1.210]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.59it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.198, valid_loss=1.210]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 377.19it/s]\u001b[A\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.41it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=1.220]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=47121)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=47121)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[36m(_train_tune pid=47667)\u001b[0m Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.470, train_loss_epoch=3.470]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=3.130]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.060, train_loss_epoch=3.060]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]        \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150]        \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=3.130]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120]        \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=3.130]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980]        \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820]        \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880]        \n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870]        \n",
      "Epoch 67: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.38it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.810]\n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000]        \n",
      "Epoch 71: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.16it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=3.000]\n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.89it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.630]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 410.04it/s]\u001b[A\n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.939]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.939]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.939]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.939]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.939]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.939]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.939]        \n",
      "Epoch 116: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.62it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.939]\n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.939]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.939]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.939]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.939]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.939]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.939]        \n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.939]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.939]        \n",
      "Epoch 130: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.31it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.939]\n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.939]        \n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.939]        \n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.939]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.939]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.939]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.939]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.939]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.939]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.939]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.939]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.939]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.939]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.939]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.939]        \n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.939]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.939]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.939]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.939]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.939]        \n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.939]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.939]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.939]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.939]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.939]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.939]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.939]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=0.939]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.939]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.939]        \n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.939]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.939]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.939]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=0.939]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.939]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.939]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.939]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.939]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.57it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=2.010, valid_loss=0.939]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 388.07it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=3.110]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=3.110]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=3.110]        \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=3.110]        \n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=3.110]        \n",
      "Epoch 210: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.47it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=3.110]\n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=3.110]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=3.110]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=3.110]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=3.110]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=3.110]        \n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=3.110]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=3.110]        \n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=3.110]        \n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=3.110]        \n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=3.110]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=3.110]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=3.110]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=3.110]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=3.110]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=3.110]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=3.110]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=3.110]        \n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=3.110]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=3.110]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=3.110]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=3.110]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=3.110]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=3.110]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=3.110]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=3.110]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=3.110]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=3.110]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=3.110]        \n",
      "Epoch 264: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.02it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.540, valid_loss=3.110]\n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=3.110]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=3.110]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=3.110]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=3.110]        \n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.110]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=3.110]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=3.110]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=3.110]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=3.110]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=3.110]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=3.110]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.110]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.110]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.110]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.110]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=3.110]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=3.110]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.110]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.10it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.300, valid_loss=3.110]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 381.51it/s]\u001b[A\n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.670]        \n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=3.670]        \n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.670]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.670]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=3.670]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.670]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=3.670]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.670]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.670]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.670]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=3.670]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.670]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.670]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=3.670]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=3.670]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=3.670]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.670]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.670]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.670]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.670]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.670]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.670]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.670]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.670]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=3.670]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969, valid_loss=3.670]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.670]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=0.921, valid_loss=3.670]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=3.670]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=0.968, valid_loss=3.670]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=3.670]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922, valid_loss=3.670]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=3.670]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=3.670]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.867, valid_loss=3.670]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.880, train_loss_epoch=0.880, valid_loss=3.670]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=0.822, valid_loss=3.670]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=0.899, valid_loss=3.670]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=3.670]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=3.670]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=3.670]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=3.670]        \n",
      "Epoch 382: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.49it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.837, valid_loss=3.670]\n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861, valid_loss=3.670]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.818, train_loss_epoch=0.818, valid_loss=3.670]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.792, train_loss_epoch=0.792, valid_loss=3.670]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=3.670]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.771, train_loss_epoch=0.771, valid_loss=3.670]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.867, valid_loss=3.670]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=3.670]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.772, train_loss_epoch=0.772, valid_loss=3.670]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.787, train_loss_epoch=0.787, valid_loss=3.670]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.19it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.787, valid_loss=3.670]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 367.89it/s]\u001b[A\n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=4.320]        \n",
      "Epoch 402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.46it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=4.320]\n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=4.320]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776, valid_loss=4.320]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=0.761, valid_loss=4.320]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=4.320]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780, valid_loss=4.320]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.765, train_loss_epoch=0.765, valid_loss=4.320]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.738, train_loss_epoch=0.738, valid_loss=4.320]        \n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.767, train_loss_epoch=0.767, valid_loss=4.320]        \n",
      "Epoch 415: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.94it/s, v_num=0, train_loss_step=0.743, train_loss_epoch=0.743, valid_loss=4.320]\n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.732, train_loss_epoch=0.732, valid_loss=4.320]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.766, valid_loss=4.320]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.717, train_loss_epoch=0.717, valid_loss=4.320]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=4.320]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746, valid_loss=4.320]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.728, train_loss_epoch=0.728, valid_loss=4.320]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.710, train_loss_epoch=0.710, valid_loss=4.320]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.682, train_loss_epoch=0.682, valid_loss=4.320]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.747, valid_loss=4.320]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.734, train_loss_epoch=0.734, valid_loss=4.320]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.723, train_loss_epoch=0.723, valid_loss=4.320]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.723, train_loss_epoch=0.723, valid_loss=4.320]\n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.717, train_loss_epoch=0.717, valid_loss=4.320]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=4.320]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.736, train_loss_epoch=0.736, valid_loss=4.320]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.702, train_loss_epoch=0.702, valid_loss=4.320]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694, valid_loss=4.320]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.716, valid_loss=4.320]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.753, train_loss_epoch=0.753, valid_loss=4.320]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.723, train_loss_epoch=0.723, valid_loss=4.320]        \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=4.320]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670, valid_loss=4.320]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693, valid_loss=4.320]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.721, train_loss_epoch=0.721, valid_loss=4.320]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=4.320]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.728, train_loss_epoch=0.728, valid_loss=4.320]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=4.320]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=4.320]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=4.320]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693, valid_loss=4.320]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=4.320]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=4.320]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=4.320]        \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=4.320]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665, valid_loss=4.320]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=4.320]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=4.320]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=4.320]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=4.320]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=4.320]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=4.320]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.608, train_loss_epoch=0.608, valid_loss=4.320]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602, valid_loss=4.320]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=4.320]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.42it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.604, valid_loss=4.320]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=47667)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 351.58it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=47667)\u001b[0m \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.56it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=4.860]\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=4.860]        \n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=4.860]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=4.860]        \n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=4.860]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=4.860]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=4.860]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=4.860]        \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=4.860]        \n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=4.860]        \n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=4.860]        \n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=4.860]        \n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=4.860]        \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=4.860]        \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=4.860]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=4.860]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=4.860]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=4.860]        \n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=4.860]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=4.860]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=4.860]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=4.860]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=4.860]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=4.860]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=4.860]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=4.860]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=4.860]        \n",
      "Epoch 550: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.24it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=4.860]\n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=4.860]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=4.860]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=4.860]        \n",
      "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=4.860]        \n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=4.860]        \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=4.860]        \n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=4.860]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=4.860]        \n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=4.860]        \n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=4.860]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=4.860]        \n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=4.860]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=4.860]        \n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=4.860]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=4.860]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=4.860]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=4.860]        \n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=4.860]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=4.860]        \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=4.860]        \n",
      "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=4.860]        \n",
      "Epoch 591: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.33it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.539, valid_loss=4.860]\n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=4.860]        \n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=4.860]        \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=4.860]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=4.860]        \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=4.860]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.57it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.516, valid_loss=4.860]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 332.54it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=4.510]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=4.510]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=4.510]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=4.510]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=4.510]        \n",
      "Epoch 609: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.32it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.437, valid_loss=4.510]\n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=4.510]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=4.510]        \n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=4.510]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=4.510]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=4.510]        \n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=4.510]        \n",
      "Epoch 618: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.58it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=4.510]\n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=4.510]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=4.510]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=4.510]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=4.510]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=4.510]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=4.510]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=4.510]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=4.510]        \n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=4.510]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=4.510]        \n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=4.510]        \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=4.510]        \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=4.510]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=4.510]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=4.510]        \n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=4.510]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=4.510]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=4.510]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=4.510]        \n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=4.510]        \n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=4.510]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=4.510]        \n",
      "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=4.510]        \n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=4.510]        \n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=4.510]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=4.510]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=4.510]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=4.510]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=4.510]        \n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=4.510]        \n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=4.510]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=4.510]        \n",
      "Epoch 682: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.95it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=4.510]\n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=4.510]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=4.510]        \n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=4.510]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=4.510]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=4.510]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=4.510]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=4.510]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=4.510]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.90it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.292, valid_loss=4.510]\n",
      "\u001b[36m(_train_tune pid=47667)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 357.11it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=47667)\u001b[0m \n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=3.960]        \n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.960]        \n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.960]        \n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=3.960]        \n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.960]        \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=3.960]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=3.960]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.960]        \n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.960]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=3.960]        \n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=3.960]        \n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=3.960]        \n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=3.960]        \n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=3.960]        \n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=3.960]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=3.960]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=3.960]        \n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=3.960]        \n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=3.960]        \n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.960]        \n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.960]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=3.960]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=3.960]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.960]        \n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.960]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=3.960]        \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=3.960]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=3.960]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=3.960]        \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=3.960]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=3.960]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.960]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.960]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=3.960]        \n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=3.960]        \n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=3.960]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=3.960]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=3.960]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=3.960]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=3.960]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=3.960]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=3.960]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=3.960]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=3.960]        \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=3.960]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=3.960]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.960]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=3.960]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=3.960]        \n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=3.960]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=3.960]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=3.960]        \n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=3.960]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.85it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.318, valid_loss=3.960]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 383.57it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=3.580]        \n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=3.580]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=3.580]        \n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=3.580]        \n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.580]        \n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=3.580]        \n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=3.580]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=3.580]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=3.580]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=3.580]        \n",
      "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=3.580]        \n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=3.580]        \n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.580]        \n",
      "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=3.580]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=3.580]        \n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=3.580]        \n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=3.580]        \n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=3.580]        \n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=3.580]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=3.580]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=3.580]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=3.580]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=3.580]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=3.580]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=3.580]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=3.580]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.580]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=3.580]        \n",
      "Epoch 854: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.86it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=3.580]\n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=3.580]        \n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=3.580]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=3.580]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=3.580]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=3.580]        \n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=3.580]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=3.580]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=3.580]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.580]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.580]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=3.580]        \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=3.580]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=3.580]        \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=3.580]        \n",
      "Epoch 880: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.05it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=3.580]\n",
      "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=3.580]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=3.580]        \n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=3.580]        \n",
      "Epoch 884: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.39it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=3.580]\n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=3.580]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=3.580]        \n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=3.580]        \n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=3.580]\n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=3.580]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=3.580]        \n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=3.580]        \n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.580]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=3.580]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.06it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.251, valid_loss=3.580]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 381.72it/s]\u001b[A\n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=3.510]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=3.510]        \n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=3.510]        \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=3.510]        \n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=3.510]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=3.510]        \n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=3.510]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=3.510]        \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=3.510]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=3.510]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=3.510]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=3.510]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=3.510]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=3.510]        \n",
      "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=3.510]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.510]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=3.510]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=3.510]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=3.510]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=3.510]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=3.510]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=3.510]        \n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=3.510]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=3.510]        \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=3.510]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=3.510]        \n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=3.510]        \n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=3.510]        \n",
      "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248, valid_loss=3.510]        \n",
      "Epoch 954: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.36it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=3.510]\n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=3.510]        \n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.510]        \n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=3.510]        \n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=3.510]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=3.510]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=3.510]        \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=3.510]        \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=3.510]        \n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=3.510]        \n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=3.510]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=3.510]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=3.510]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=3.510]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=3.510]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=3.510]        \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=3.510]        \n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=3.510]        \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=3.510]        \n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=3.510]        \n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=3.510]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=3.510]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=3.510]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=3.510]        \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=3.510]        \n",
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=3.510]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.26it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.244, valid_loss=3.510]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 382.10it/s]\u001b[A\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.22it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=3.380]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=47667)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=47667)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[36m(_train_tune pid=48180)\u001b[0m Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.00, train_loss_epoch=35.00]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.220, train_loss_epoch=3.220]        \n",
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.14it/s, v_num=0, train_loss_step=3.220, train_loss_epoch=3.220]\n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.220, train_loss_epoch=3.220]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090]        \n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.600, train_loss_epoch=3.600]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830]        \n",
      "Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.72it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=2.830]\n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=3.160]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=3.130]        \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070]        \n",
      "Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.19it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870]\n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170]        \n",
      "Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.45it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920]\n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080]        \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810]        \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830]        \n",
      "Epoch 54: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.87it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=2.820]\n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910]        \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890]        \n",
      "Epoch 61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.76it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830]\n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710]        \n",
      "Epoch 81: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.55it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980]\n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980]        \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860]        \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790]        \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.43it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.790]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 383.11it/s]\u001b[A\n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.723]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040, valid_loss=0.723]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.723]        \n",
      "Epoch 105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.37it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.880, valid_loss=0.723]\n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.723]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.723]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=0.723]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.723]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.723]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.723]        \n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.723]        \n",
      "Epoch 116: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.10it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.723]\n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.723]        \n",
      "Epoch 118: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.14it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.810, valid_loss=0.723]\n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.723]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.723]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.723]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.723]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.723]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.723]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.723]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.723]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.723]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.723]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.723]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.723]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.723]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.723]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.723]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.723]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.723]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.723]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.723]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.723]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.723]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.723]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.723]\n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.723]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.723]        \n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.723]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.723]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.723]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.723]        \n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.723]        \n",
      "Epoch 173: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.23it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.723]\n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.723]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.723]        \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.723]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.723]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.723]        \n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.723]        \n",
      "Epoch 187: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.17it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.520, valid_loss=0.723]\n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.723]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.723]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.723]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.723]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.723]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.723]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.24it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.360, valid_loss=0.723]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 349.29it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=2.080]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=2.080]        \n",
      "Epoch 202: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.19it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=2.080]\n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=2.080]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=2.080]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=2.080]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=2.080]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=2.080]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=2.080]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=2.080]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=2.080]        \n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=2.080]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=2.080]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=2.080]        \n",
      "Epoch 226: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.63it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=2.080]\n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=2.080]        \n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=2.080]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=2.080]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=2.080]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=2.080]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=2.080]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=2.080]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=2.080]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=2.080]        \n",
      "Epoch 244: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.38it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=2.080]\n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=2.080]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=2.080]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=2.080]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=2.080]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=2.080]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=2.080]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=2.080]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=2.080]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=2.080]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=2.080]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=2.080]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=2.080]        \n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=2.080]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=2.080]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=2.080]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=2.080]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=2.080]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=2.080]        \n",
      "Epoch 274: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.07it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=2.080]\n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=2.080]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=2.080]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=2.080]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=2.080]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=2.080]        \n",
      "Epoch 283: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.66it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=2.080]\n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=2.080]        \n",
      "Epoch 285: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.24it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.230, valid_loss=2.080]\n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=2.080]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=2.080]        \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=2.080]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=2.080]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=2.080]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=2.080]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=2.080]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=2.080]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.32it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=1.970, valid_loss=2.080]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 378.96it/s]\u001b[A\n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=1.970]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=1.970]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=1.970]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=1.970]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=1.970]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=1.970]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=1.970]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=1.970]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=1.970]        \n",
      "Epoch 320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.94it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=1.970]\n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=1.970]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=1.970]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=1.970]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=1.970]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=1.970]        \n",
      "Epoch 331: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.45it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=1.970]\n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=1.970]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=1.970]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=1.970]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=1.970]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=1.970]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=1.970]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=1.970]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=1.970]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=1.970]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=1.970]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=1.970]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=1.970]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=1.970]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=1.970]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=1.970]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=1.970]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=1.970]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=1.970]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=1.970]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=1.970]        \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=1.970]        \n",
      "Epoch 370: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.02it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=1.970]\n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=1.970]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=1.970]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=1.970]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=1.970]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=1.970]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=1.970]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=1.970]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=1.970]        \n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=1.970]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=1.970]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=1.970]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=1.970]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=1.970]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=1.970]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.52it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.490, valid_loss=1.970]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 381.13it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=1.040]        \n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=1.040]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=1.040]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=1.040]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=1.040]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=1.040]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=1.040]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=1.040]        \n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=1.040]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=1.040]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=1.040]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=1.040]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=1.040]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=1.040]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=1.040]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=1.040]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=1.040]        \n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=1.040]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=1.040]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=1.040]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=1.040]        \n",
      "Epoch 437: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.42it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=1.040]\n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=1.040]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=1.040]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=1.040]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=1.040]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=1.040]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=1.040]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=1.040]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=1.040]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=1.040]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=1.040]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=1.040]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=1.040]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=1.040]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=1.040]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=1.040]        \n",
      "Epoch 467: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.18it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=1.040]\n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=1.040]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=1.040]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=1.040]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=1.040]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=1.040]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=1.040]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=1.040]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=1.040]        \n",
      "Epoch 484: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.53it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=1.040]\n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=1.040]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=1.040]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=1.040]        \n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=1.040]        \n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=1.040]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=1.040]        \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=1.040]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=1.040]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.05it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.230, valid_loss=1.040]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 390.46it/s]\u001b[A\n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=1.890]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=1.890]        \n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=1.890]        \n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=1.890]        \n",
      "Epoch 507: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.92it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=1.890]\n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=1.890]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=1.890]        \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=1.890]        \n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=1.890]        \n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=1.890]        \n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=1.890]        \n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=1.890]        \n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=1.890]        \n",
      "Epoch 524: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.45it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=1.890]\n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=1.890]        \n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=1.890]        \n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=1.890]        \n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=1.890]        \n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=1.890]        \n",
      "Epoch 533: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.63it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=1.890]\n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=1.890]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=1.890]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=1.890]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=1.890]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=1.890]        \n",
      "Epoch 544: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.18it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=1.890]\n",
      "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=1.890]        \n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=1.890]        \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=1.890]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=1.890]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=1.890]        \n",
      "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=1.890]        \n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=1.890]        \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=1.890]        \n",
      "Epoch 561: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.13it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=1.890]\n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=1.890]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=1.890]\n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=1.890]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=1.890]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=1.890]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=1.890]        \n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=1.890]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=1.890]        \n",
      "Epoch 574: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.88it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=1.890]\n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=1.890]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=1.890]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.890]        \n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=1.890]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=1.890]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.890]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=1.890]        \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=1.890]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=1.890]        \n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=1.890]        \n",
      "Epoch 593: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.72it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=1.890]\n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=1.890]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=1.890]        \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=1.890]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.01it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.890]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 362.20it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=48180)\u001b[0m \n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.830]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=1.830]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.830]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=1.830]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.830]        \n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.830]        \n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.830]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.830]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=1.830]        \n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=1.830]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=1.830]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=1.830]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=1.830]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=1.830]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=1.830]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=1.830]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=1.830]        \n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.830]        \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=1.830]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=1.830]        \n",
      "Epoch 638: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.53it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.090, valid_loss=1.830]\n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=1.830]        \n",
      "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=1.830]        \n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=1.830]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=1.830]        \n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=1.830]        \n",
      "Epoch 649: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.88it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.130, valid_loss=1.830]\n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=1.830]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=1.830]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=1.830]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.830]        \n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=1.830]        \n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.981, train_loss_epoch=0.981, valid_loss=1.830]        \n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=1.830]        \n",
      "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=1.830]        \n",
      "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=1.830]        \n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=1.830]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.925, train_loss_epoch=0.925, valid_loss=1.830]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=1.830]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=1.830]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=1.830]        \n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.903, train_loss_epoch=0.903, valid_loss=1.830]        \n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951, valid_loss=1.830]        \n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=1.830]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=1.830]        \n",
      "Epoch 682: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.22it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=0.895, valid_loss=1.830]\n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.895, train_loss_epoch=0.895, valid_loss=1.830]        \n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.892, train_loss_epoch=0.892, valid_loss=1.830]        \n",
      "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=0.918, valid_loss=1.830]        \n",
      "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=1.830]        \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922, valid_loss=1.830]        \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.903, train_loss_epoch=0.903, valid_loss=1.830]        \n",
      "Epoch 693: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.50it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=1.830]\n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.908, valid_loss=1.830]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=1.830]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=1.830]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.28it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=0.804, valid_loss=1.830]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 384.02it/s]\u001b[A\n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.880, train_loss_epoch=0.880, valid_loss=2.060]        \n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854, valid_loss=2.060]        \n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.875, train_loss_epoch=0.875, valid_loss=2.060]        \n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.826, train_loss_epoch=0.826, valid_loss=2.060]        \n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.898, train_loss_epoch=0.898, valid_loss=2.060]        \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.826, train_loss_epoch=0.826, valid_loss=2.060]        \n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=0.799, valid_loss=2.060]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870, valid_loss=2.060]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=2.060]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806, valid_loss=2.060]        \n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=2.060]        \n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854, valid_loss=2.060]        \n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.844, train_loss_epoch=0.844, valid_loss=2.060]        \n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806, valid_loss=2.060]        \n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=2.060]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.867, valid_loss=2.060]        \n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.824, valid_loss=2.060]        \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.772, train_loss_epoch=0.772, valid_loss=2.060]        \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.815, train_loss_epoch=0.815, valid_loss=2.060]        \n",
      "Epoch 736: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.32it/s, v_num=0, train_loss_step=0.833, train_loss_epoch=0.833, valid_loss=2.060]\n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.833, train_loss_epoch=0.833, valid_loss=2.060]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854, valid_loss=2.060]        \n",
      "Epoch 738: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.60it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.854, valid_loss=2.060]\n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871, valid_loss=2.060]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=0.799, valid_loss=2.060]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.786, train_loss_epoch=0.786, valid_loss=2.060]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=0.885, valid_loss=2.060]        \n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.856, valid_loss=2.060]        \n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.815, train_loss_epoch=0.815, valid_loss=2.060]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.865, train_loss_epoch=0.865, valid_loss=2.060]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.833, train_loss_epoch=0.833, valid_loss=2.060]        \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=0.848, valid_loss=2.060]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.855, train_loss_epoch=0.855, valid_loss=2.060]        \n",
      "Epoch 756: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.13it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=2.060]\n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=2.060]        \n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796, valid_loss=2.060]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.815, train_loss_epoch=0.815, valid_loss=2.060]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.835, train_loss_epoch=0.835, valid_loss=2.060]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.826, train_loss_epoch=0.826, valid_loss=2.060]        \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806, valid_loss=2.060]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.849, valid_loss=2.060]        \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.778, train_loss_epoch=0.778, valid_loss=2.060]        \n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=0.822, valid_loss=2.060]        \n",
      "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=2.060]        \n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.789, train_loss_epoch=0.789, valid_loss=2.060]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.800, train_loss_epoch=0.800, valid_loss=2.060]        \n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.792, train_loss_epoch=0.792, valid_loss=2.060]        \n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.855, train_loss_epoch=0.855, valid_loss=2.060]        \n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.795, train_loss_epoch=0.795, valid_loss=2.060]        \n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.792, train_loss_epoch=0.792, valid_loss=2.060]        \n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=2.060]        \n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.788, train_loss_epoch=0.788, valid_loss=2.060]        \n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.785, train_loss_epoch=0.785, valid_loss=2.060]        \n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.787, train_loss_epoch=0.787, valid_loss=2.060]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=0.803, valid_loss=2.060]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=0.803, valid_loss=2.060]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.779, train_loss_epoch=0.779, valid_loss=2.060]        \n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.798, train_loss_epoch=0.798, valid_loss=2.060]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.24it/s, v_num=0, train_loss_step=0.773, train_loss_epoch=0.798, valid_loss=2.060]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 380.68it/s]\u001b[A\n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.798, train_loss_epoch=0.798, valid_loss=2.410]        \n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=2.410]        \n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=0.801, valid_loss=2.410]        \n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.794, train_loss_epoch=0.794, valid_loss=2.410]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.782, train_loss_epoch=0.782, valid_loss=2.410]        \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.836, valid_loss=2.410]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=2.410]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=2.410]        \n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.820, train_loss_epoch=0.820, valid_loss=2.410]        \n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=0.799, valid_loss=2.410]        \n",
      "Epoch 819: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.12it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=2.410]\n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=2.410]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=0.762, valid_loss=2.410]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=0.799, valid_loss=2.410]        \n",
      "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719, valid_loss=2.410]        \n",
      "Epoch 827: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.26it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=2.410]\n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=2.410]        \n",
      "Epoch 829: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.89it/s, v_num=0, train_loss_step=0.795, train_loss_epoch=0.795, valid_loss=2.410]\n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.795, train_loss_epoch=0.795, valid_loss=2.410]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=2.410]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.786, train_loss_epoch=0.786, valid_loss=2.410]        \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.770, train_loss_epoch=0.770, valid_loss=2.410]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=2.410]        \n",
      "Epoch 837: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.11it/s, v_num=0, train_loss_step=0.814, train_loss_epoch=0.807, valid_loss=2.410]\n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.814, train_loss_epoch=0.814, valid_loss=2.410]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=2.410]        \n",
      "Epoch 839: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.73it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.791, valid_loss=2.410]\n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=2.410]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796, valid_loss=2.410]        \n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.766, valid_loss=2.410]        \n",
      "Epoch 843: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.63it/s, v_num=0, train_loss_step=0.774, train_loss_epoch=0.774, valid_loss=2.410]\n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.774, train_loss_epoch=0.774, valid_loss=2.410]        \n",
      "Epoch 845: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.34it/s, v_num=0, train_loss_step=0.790, train_loss_epoch=0.771, valid_loss=2.410]\n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.790, train_loss_epoch=0.790, valid_loss=2.410]        \n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.792, train_loss_epoch=0.792, valid_loss=2.410]        \n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.782, train_loss_epoch=0.782, valid_loss=2.410]        \n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.732, train_loss_epoch=0.732, valid_loss=2.410]        \n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.771, train_loss_epoch=0.771, valid_loss=2.410]        \n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.783, valid_loss=2.410]        \n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.800, train_loss_epoch=0.800, valid_loss=2.410]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.778, train_loss_epoch=0.778, valid_loss=2.410]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.766, valid_loss=2.410]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.778, train_loss_epoch=0.778, valid_loss=2.410]        \n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.793, train_loss_epoch=0.793, valid_loss=2.410]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.779, train_loss_epoch=0.779, valid_loss=2.410]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=0.748, valid_loss=2.410]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776, valid_loss=2.410]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.749, valid_loss=2.410]        \n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.773, train_loss_epoch=0.773, valid_loss=2.410]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.749, valid_loss=2.410]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.769, valid_loss=2.410]        \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.815, train_loss_epoch=0.815, valid_loss=2.410]        \n",
      "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.774, train_loss_epoch=0.774, valid_loss=2.410]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.729, train_loss_epoch=0.729, valid_loss=2.410]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.769, valid_loss=2.410]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.773, train_loss_epoch=0.773, valid_loss=2.410]        \n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.767, train_loss_epoch=0.767, valid_loss=2.410]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796, valid_loss=2.410]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.738, train_loss_epoch=0.738, valid_loss=2.410]        \n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780, valid_loss=2.410]        \n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.764, train_loss_epoch=0.764, valid_loss=2.410]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719, valid_loss=2.410]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.36it/s, v_num=0, train_loss_step=0.760, train_loss_epoch=0.719, valid_loss=2.410]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 363.08it/s]\u001b[A\n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.747, valid_loss=2.480]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.749, valid_loss=2.480]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.738, train_loss_epoch=0.738, valid_loss=2.480]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.721, train_loss_epoch=0.721, valid_loss=2.480]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=0.761, valid_loss=2.480]        \n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.783, valid_loss=2.480]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.739, train_loss_epoch=0.739, valid_loss=2.480]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.777, train_loss_epoch=0.777, valid_loss=2.480]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.743, train_loss_epoch=0.743, valid_loss=2.480]        \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=0.758, valid_loss=2.480]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.772, train_loss_epoch=0.772, valid_loss=2.480]        \n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.764, train_loss_epoch=0.764, valid_loss=2.480]        \n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.750, train_loss_epoch=0.750, valid_loss=2.480]        \n",
      "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.770, train_loss_epoch=0.770, valid_loss=2.480]        \n",
      "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.722, train_loss_epoch=0.722, valid_loss=2.480]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.747, valid_loss=2.480]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737, valid_loss=2.480]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.716, train_loss_epoch=0.716, valid_loss=2.480]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.743, train_loss_epoch=0.743, valid_loss=2.480]        \n",
      "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.733, train_loss_epoch=0.733, valid_loss=2.480]        \n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.729, train_loss_epoch=0.729, valid_loss=2.480]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.726, train_loss_epoch=0.726, valid_loss=2.480]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.753, train_loss_epoch=0.753, valid_loss=2.480]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.729, train_loss_epoch=0.729, valid_loss=2.480]        \n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.705, train_loss_epoch=0.705, valid_loss=2.480]        \n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=0.751, valid_loss=2.480]        \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=2.480]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.728, train_loss_epoch=0.728, valid_loss=2.480]        \n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=2.480]        \n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.749, valid_loss=2.480]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741, valid_loss=2.480]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.729, train_loss_epoch=0.729, valid_loss=2.480]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.765, train_loss_epoch=0.765, valid_loss=2.480]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719, valid_loss=2.480]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718, valid_loss=2.480]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.711, train_loss_epoch=0.711, valid_loss=2.480]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718, valid_loss=2.480]        \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=2.480]        \n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.757, train_loss_epoch=0.757, valid_loss=2.480]        \n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.752, train_loss_epoch=0.752, valid_loss=2.480]        \n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759, valid_loss=2.480]        \n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=2.480]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.764, train_loss_epoch=0.764, valid_loss=2.480]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.731, train_loss_epoch=0.731, valid_loss=2.480]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.715, valid_loss=2.480]        \n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.777, train_loss_epoch=0.777, valid_loss=2.480]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=2.480]        \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.728, train_loss_epoch=0.728, valid_loss=2.480]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704, valid_loss=2.480]        \n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.725, train_loss_epoch=0.725, valid_loss=2.480]        \n",
      "Epoch 989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.31it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719, valid_loss=2.480]\n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719, valid_loss=2.480]        \n",
      "Epoch 991: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.34it/s, v_num=0, train_loss_step=0.730, train_loss_epoch=0.730, valid_loss=2.480]\n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.753, train_loss_epoch=0.753, valid_loss=2.480]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718, valid_loss=2.480]        \n",
      "Epoch 993: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.02it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718, valid_loss=2.480]\n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.745, train_loss_epoch=0.745, valid_loss=2.480]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.722, train_loss_epoch=0.722, valid_loss=2.480]        \n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.745, train_loss_epoch=0.745, valid_loss=2.480]        \n",
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.739, train_loss_epoch=0.739, valid_loss=2.480]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.26it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.739, valid_loss=2.480]\n",
      "\u001b[36m(_train_tune pid=48180)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=48180)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 356.51it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=48180)\u001b[0m \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.94it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737, valid_loss=2.570]\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.68it/s, v_num=0, train_loss_step=0.737, train_loss_epoch=0.737, valid_loss=2.570]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=48180)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=48180)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[36m(_train_tune pid=48708)\u001b[0m Seed set to 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000]\n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930]       \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120]        \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080]        \n",
      "Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.69it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110]\n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960]        \n",
      "Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.33it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800]\n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870]        \n",
      "Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.77it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.870]\n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720]        \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730]        \n",
      "Epoch 68: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.67it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.680]\n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520]        \n",
      "Epoch 85: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.81it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540]\n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460]        \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.60it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160]\n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.44it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.160]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=48708)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 405.52it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=48708)\u001b[0m \n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=1.150]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=1.150]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=1.150]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=1.150]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=1.150]        \n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=1.150]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=1.150]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=1.150]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=1.150]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=1.150]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=1.150]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=1.150]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=1.150]        \n",
      "Epoch 126: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.97it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=1.150]\n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=1.150]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=1.150]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=1.150]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=1.150]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=1.150]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=1.150]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=1.150]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=1.150]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=1.150]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=1.150]        \n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=1.150]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=1.150]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=1.150]        \n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=1.150]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=1.150]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=1.150]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=1.150]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=1.150]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=1.150]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=1.150]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=1.150]        \n",
      "Epoch 173: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.32it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=1.150]\n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=1.150]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=1.150]        \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=1.150]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=1.150]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=1.150]        \n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=1.150]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=1.150]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=1.150]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=1.150]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=1.150]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=1.150]        \n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=1.150]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.69it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.450, valid_loss=1.150]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 405.68it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=3.360]        \n",
      "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=3.360]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.360]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=3.360]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.360]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=3.360]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=3.360]        \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=3.360]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=3.360]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=3.360]        \n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.360]        \n",
      "Epoch 220: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.61it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.270, valid_loss=3.360]\n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.360]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.360]        \n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.360]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=3.360]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=3.360]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.360]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=3.360]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.360]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=3.360]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.360]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.360]        \n",
      "Epoch 239: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.72it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.180, valid_loss=3.360]\n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.360]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.360]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.360]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.360]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.360]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.360]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.360]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.360]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.360]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.360]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.360]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.360]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.360]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.360]        \n",
      "Epoch 268: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.64it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.360]\n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.360]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.360]        \n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953, valid_loss=3.360]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.360]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.360]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.360]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.360]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=0.963, valid_loss=3.360]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=3.360]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=3.360]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=3.360]        \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=3.360]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=3.360]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=3.360]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.360]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947, valid_loss=3.360]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.837, train_loss_epoch=0.837, valid_loss=3.360]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.28it/s, v_num=0, train_loss_step=0.898, train_loss_epoch=0.837, valid_loss=3.360]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 397.30it/s]\u001b[A\n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940, valid_loss=3.770]        \n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893, valid_loss=3.770]        \n",
      "Epoch 303: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.52it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=3.770]\n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=3.770]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=0.918, valid_loss=3.770]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.975, train_loss_epoch=0.975, valid_loss=3.770]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=3.770]        \n",
      "Epoch 311: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.13it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=3.770]\n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=0.923, valid_loss=3.770]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.953, train_loss_epoch=0.953, valid_loss=3.770]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=3.770]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861, valid_loss=3.770]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854, valid_loss=3.770]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860, valid_loss=3.770]        \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.941, train_loss_epoch=0.941, valid_loss=3.770]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926, valid_loss=3.770]        \n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.828, train_loss_epoch=0.828, valid_loss=3.770]        \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.856, valid_loss=3.770]        \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=3.770]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=3.770]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776, valid_loss=3.770]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=3.770]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.766, valid_loss=3.770]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.773, train_loss_epoch=0.773, valid_loss=3.770]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.735, train_loss_epoch=0.735, valid_loss=3.770]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.765, train_loss_epoch=0.765, valid_loss=3.770]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.710, train_loss_epoch=0.710, valid_loss=3.770]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=0.761, valid_loss=3.770]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.722, train_loss_epoch=0.722, valid_loss=3.770]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.732, train_loss_epoch=0.732, valid_loss=3.770]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=3.770]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.756, train_loss_epoch=0.756, valid_loss=3.770]        \n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.760, train_loss_epoch=0.760, valid_loss=3.770]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.738, train_loss_epoch=0.738, valid_loss=3.770]        \n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=3.770]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693, valid_loss=3.770]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=3.770]        \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714, valid_loss=3.770]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.702, train_loss_epoch=0.702, valid_loss=3.770]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=3.770]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694, valid_loss=3.770]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=3.770]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=3.770]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685, valid_loss=3.770]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.680, valid_loss=3.770]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=3.770]        \n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661, valid_loss=3.770]        \n",
      "Epoch 389: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.76it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.666, valid_loss=3.770]\n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714, valid_loss=3.770]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=3.770]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.683, train_loss_epoch=0.683, valid_loss=3.770]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.639, train_loss_epoch=0.639, valid_loss=3.770]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=3.770]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.675, train_loss_epoch=0.675, valid_loss=3.770]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.44it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.675, valid_loss=3.770]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 391.37it/s]\u001b[A\n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=3.680]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.679, train_loss_epoch=0.679, valid_loss=3.680]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=3.680]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=3.680]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=3.680]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=3.680]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=3.680]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=3.680]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=3.680]        \n",
      "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=3.680]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=3.680]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.608, train_loss_epoch=0.608, valid_loss=3.680]        \n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=3.680]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=3.680]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=3.680]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=3.680]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.640, train_loss_epoch=0.640, valid_loss=3.680]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.666, train_loss_epoch=0.666, valid_loss=3.680]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=3.680]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=3.680]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.640, train_loss_epoch=0.640, valid_loss=3.680]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=3.680]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=3.680]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=3.680]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=3.680]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=3.680]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=3.680]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=3.680]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=3.680]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=3.680]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622, valid_loss=3.680]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=3.680]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.612, train_loss_epoch=0.612, valid_loss=3.680]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622, valid_loss=3.680]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=3.680]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=3.680]        \n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602, valid_loss=3.680]        \n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=3.680]        \n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=3.680]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.667, train_loss_epoch=0.667, valid_loss=3.680]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=3.680]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=3.680]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=3.680]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=3.680]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=3.680]        \n",
      "Epoch 486: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.15it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.625, valid_loss=3.680]\n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=3.680]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=3.680]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=3.680]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.633, train_loss_epoch=0.633, valid_loss=3.680]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.643, train_loss_epoch=0.643, valid_loss=3.680]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622, valid_loss=3.680]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=3.680]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.45it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.655, valid_loss=3.680]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 325.95it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=3.290]        \n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=3.290]        \n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=3.290]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.646, train_loss_epoch=0.646, valid_loss=3.290]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=3.290]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=3.290]        \n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=3.290]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=3.290]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=3.290]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=3.290]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=3.290]        \n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=3.290]        \n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.616, train_loss_epoch=0.616, valid_loss=3.290]        \n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=3.290]        \n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=3.290]        \n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=3.290]        \n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=3.290]        \n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622, valid_loss=3.290]        \n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=3.290]        \n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=3.290]        \n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=3.290]        \n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=3.290]        \n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=3.290]        \n",
      "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=3.290]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=3.290]        \n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=3.290]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=3.290]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=3.290]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=3.290]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=3.290]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=3.290]        \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=3.290]\n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=3.290]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=3.290]        \n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=3.290]        \n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=3.290]        \n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=3.290]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=3.290]        \n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=3.290]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=3.290]        \n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=3.290]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=3.290]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=3.290]        \n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=3.290]        \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=3.290]        \n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=3.290]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=3.290]        \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=3.290]        \n",
      "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=3.290]        \n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=3.290]        \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=3.290]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=3.290]        \n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=3.290]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.86it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.600, valid_loss=3.290]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 352.58it/s]\u001b[A\n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=2.860]        \n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=2.860]        \n",
      "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=2.860]        \n",
      "Epoch 606: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.09it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=2.860]\n",
      "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=2.860]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=2.860]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=2.860]        \n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=2.860]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=2.860]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=2.860]        \n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=2.860]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=2.860]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=2.860]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=2.860]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=2.860]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=2.860]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=2.860]        \n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=2.860]        \n",
      "Epoch 632: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.47it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=2.860]\n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=2.860]        \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=2.860]        \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=2.860]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=2.860]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=2.860]        \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=2.860]        \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=2.860]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=2.860]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=2.860]        \n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=2.860]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=2.860]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=2.860]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=2.860]        \n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=2.860]        \n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=2.860]        \n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=2.860]        \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=2.860]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=2.860]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=2.860]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=2.860]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=2.860]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=2.860]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=2.860]        \n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=2.860]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=2.860]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=2.860]        \n",
      "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=2.860]        \n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=2.860]        \n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=2.860]        \n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=2.860]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=2.860]        \n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=2.860]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=2.860]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=2.860]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=2.860]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=2.860]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=2.860]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=2.860]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.60it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.537, valid_loss=2.860]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 389.26it/s]\u001b[A\n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=2.770]        \n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=2.770]        \n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=2.770]        \n",
      "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=2.770]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=2.770]        \n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=2.770]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=2.770]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=2.770]        \n",
      "Epoch 714: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.34it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.536, valid_loss=2.770]\n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=2.770]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=2.770]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=2.770]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=2.770]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=2.770]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=2.770]        \n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=2.770]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=2.770]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=2.770]        \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=2.770]        \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=2.770]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=2.770]        \n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=2.770]        \n",
      "Epoch 737: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.12it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.509, valid_loss=2.770]\n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=2.770]        \n",
      "Epoch 739: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.03it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=2.770]\n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=2.770]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=2.770]        \n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=2.770]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=2.770]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=2.770]        \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=2.770]        \n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=2.770]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=2.770]        \n",
      "Epoch 754: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.42it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=2.770]\n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=2.770]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=2.770]        \n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=2.770]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=2.770]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=2.770]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=2.770]        \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=2.770]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=2.770]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=2.770]        \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=2.770]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=2.770]        \n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=2.770]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=2.770]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=2.770]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=2.770]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=2.770]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=2.770]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=2.770]        \n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=2.770]        \n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=2.770]        \n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=2.770]        \n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=2.770]        \n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=2.770]        \n",
      "Epoch 792: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.76it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=2.770]\n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=2.770]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=2.770]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=2.770]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=2.770]\n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=2.770]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.28it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.524, valid_loss=2.770]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 367.92it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=2.770]        \n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=2.770]        \n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=2.770]        \n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=2.770]        \n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=2.770]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=2.770]        \n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.500, train_loss_epoch=0.500, valid_loss=2.770]        \n",
      "Epoch 810: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.93it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=2.770]\n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=2.770]        \n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=2.770]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=2.770]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=2.770]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=2.770]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=2.770]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=2.770]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=2.770]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=2.770]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=2.770]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=2.770]        \n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=2.770]        \n",
      "Epoch 831: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.57it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.509, valid_loss=2.770]\n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=2.770]        \n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=2.770]        \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=2.770]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=2.770]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=2.770]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=2.770]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=2.770]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=2.770]        \n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=2.770]        \n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=2.770]        \n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=2.770]        \n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=2.770]        \n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=2.770]        \n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=2.770]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=2.770]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=2.770]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=2.770]        \n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=2.770]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=2.770]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=2.770]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=2.770]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=2.770]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=2.770]        \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=2.770]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=2.770]        \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=2.770]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=2.770]        \n",
      "Epoch 883: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.31it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=2.770]\n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=2.770]        \n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=2.770]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=2.770]        \n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=2.770]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=2.770]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=2.770]        \n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=2.770]        \n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=2.770]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=2.770]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.09it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.491, valid_loss=2.770]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 351.84it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=2.810]        \n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=2.810]        \n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=2.810]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=2.810]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=2.810]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=2.810]        \n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=2.810]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=2.810]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=2.810]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=2.810]        \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=2.810]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=2.810]        \n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=2.810]        \n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=2.810]        \n",
      "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=2.810]        \n",
      "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=2.810]        \n",
      "Epoch 928: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.12it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=2.810]\n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=2.810]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=2.810]        \n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=2.810]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=2.810]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=2.810]        \n",
      "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=2.810]        \n",
      "Epoch 936: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.34it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=2.810]\n",
      "Epoch 936: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.26it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.540, valid_loss=2.810]\n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=2.810]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=2.810]        \n",
      "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=2.810]        \n",
      "Epoch 939: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.18it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=2.810]\n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=2.810]        \n",
      "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=2.810]        \n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=2.810]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=2.810]        \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=2.810]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=2.810]        \n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=2.810]        \n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=2.810]        \n",
      "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=2.810]        \n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=2.810]        \n",
      "Epoch 957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.78it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=2.810]\n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=2.810]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=2.810]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=2.810]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=2.810]        \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=2.810]        \n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=2.810]        \n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=2.810]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=2.810]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=2.810]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=2.810]        \n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=2.810]        \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=2.810]        \n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=2.810]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=2.810]        \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=2.810]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=2.810]        \n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=2.810]        \n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=2.810]        \n",
      "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557, valid_loss=2.810]        \n",
      "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=2.810]        \n",
      "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=2.810]        \n",
      "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=2.810]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.04it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.530, valid_loss=2.810]\n",
      "\u001b[36m(_train_tune pid=48708)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=48708)\u001b[0m \n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 344.11it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=48708)\u001b[0m \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.40it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=2.820]\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.07it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=2.820]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=48708)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=48708)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[36m(_train_tune pid=49235)\u001b[0m Seed set to 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840]        \n",
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.60it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850]\n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850]       \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840]        \n",
      "Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.05it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900]\n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810]        \n",
      "Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.37it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790]\n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810]        \n",
      "Epoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.69it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.790]\n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740]        \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770]        \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710]        \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560]        \n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570]        \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.22it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.390]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 394.02it/s]\u001b[A\n",
      "Epoch 100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.67it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=2.940]\n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=2.940]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=2.940]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=2.940]        \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=2.940]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=2.940]        \n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=2.940]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=2.940]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=2.940]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=2.940]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=2.940]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=2.940]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=2.940]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=2.940]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=2.940]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=2.940]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=2.940]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=2.940]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=2.940]        \n",
      "Epoch 135: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.73it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=2.940]\n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=2.940]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=2.940]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=2.940]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=2.940]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=2.940]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972, valid_loss=2.940]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=2.940]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.897, train_loss_epoch=0.897, valid_loss=2.940]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=2.940]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.986, train_loss_epoch=0.986, valid_loss=2.940]        \n",
      "Epoch 156: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.00it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.922, valid_loss=2.940]\n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=2.940]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956, valid_loss=2.940]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=0.819, valid_loss=2.940]        \n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=2.940]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=2.940]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.812, valid_loss=2.940]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.880, train_loss_epoch=0.880, valid_loss=2.940]        \n",
      "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806, valid_loss=2.940]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.886, train_loss_epoch=0.886, valid_loss=2.940]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=0.822, valid_loss=2.940]        \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=0.803, valid_loss=2.940]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=0.819, valid_loss=2.940]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=2.940]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.839, train_loss_epoch=0.839, valid_loss=2.940]        \n",
      "Epoch 186: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.71it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=2.940]\n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=2.940]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=2.940]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=2.940]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.738, train_loss_epoch=0.738, valid_loss=2.940]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.929, train_loss_epoch=0.929, valid_loss=2.940]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.833, train_loss_epoch=0.833, valid_loss=2.940]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.56it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.828, valid_loss=2.940]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 401.25it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746, valid_loss=3.580]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.739, train_loss_epoch=0.739, valid_loss=3.580]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.710, train_loss_epoch=0.710, valid_loss=3.580]        \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.798, train_loss_epoch=0.798, valid_loss=3.580]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.729, train_loss_epoch=0.729, valid_loss=3.580]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.774, train_loss_epoch=0.774, valid_loss=3.580]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.728, train_loss_epoch=0.728, valid_loss=3.580]        \n",
      "Epoch 215: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.51it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718, valid_loss=3.580]\n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718, valid_loss=3.580]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.777, train_loss_epoch=0.777, valid_loss=3.580]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.731, train_loss_epoch=0.731, valid_loss=3.580]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.717, train_loss_epoch=0.717, valid_loss=3.580]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.671, train_loss_epoch=0.671, valid_loss=3.580]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.690, train_loss_epoch=0.690, valid_loss=3.580]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.712, valid_loss=3.580]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.738, train_loss_epoch=0.738, valid_loss=3.580]        \n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.707, train_loss_epoch=0.707, valid_loss=3.580]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.669, train_loss_epoch=0.669, valid_loss=3.580]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=3.580]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.633, train_loss_epoch=0.633, valid_loss=3.580]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.676, valid_loss=3.580]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.740, train_loss_epoch=0.740, valid_loss=3.580]        \n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724, valid_loss=3.580]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.690, train_loss_epoch=0.690, valid_loss=3.580]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=3.580]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.671, train_loss_epoch=0.671, valid_loss=3.580]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=3.580]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.608, train_loss_epoch=0.608, valid_loss=3.580]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=3.580]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.636, train_loss_epoch=0.636, valid_loss=3.580]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=3.580]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=3.580]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.685, train_loss_epoch=0.685, valid_loss=3.580]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=3.580]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704, valid_loss=3.580]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=3.580]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=3.580]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=3.580]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=3.580]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.694, train_loss_epoch=0.694, valid_loss=3.580]        \n",
      "Epoch 280: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.76it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=3.580]\n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=3.580]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=3.580]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=3.580]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=3.580]        \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=3.580]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=3.580]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579, valid_loss=3.580]        \n",
      "Epoch 296: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.70it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=3.580]\n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=3.580]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=3.580]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.06it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.574, valid_loss=3.580]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 399.04it/s]\u001b[A\n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=3.040]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=3.040]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=3.040]        \n",
      "Epoch 305: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.10it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=3.040]\n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=3.040]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=3.040]        \n",
      "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=3.040]        \n",
      "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=3.040]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=3.040]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=3.040]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=3.040]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=3.040]        \n",
      "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=3.040]        \n",
      "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=3.040]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=3.040]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=3.040]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=3.040]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.733, train_loss_epoch=0.733, valid_loss=3.040]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=3.040]        \n",
      "Epoch 333: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.98it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=3.040]\n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=3.040]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=3.040]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.518, train_loss_epoch=0.518, valid_loss=3.040]        \n",
      "Epoch 337: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.17it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=3.040]\n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=3.040]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=3.040]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=3.040]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.483, train_loss_epoch=0.483, valid_loss=3.040]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=3.040]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=3.040]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=3.040]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=3.040]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=3.040]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=3.040]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=3.040]        \n",
      "Epoch 358: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.85it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=3.040]\n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=3.040]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=3.040]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=3.040]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=3.040]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=3.040]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=3.040]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=3.040]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=3.040]        \n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=3.040]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=3.040]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=3.040]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=3.040]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=3.040]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442, valid_loss=3.040]        \n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=3.040]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=3.040]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=3.040]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=3.040]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=3.040]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=3.040]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.30it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.413, valid_loss=3.040]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 385.68it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=3.330]        \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=3.330]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=3.330]        \n",
      "Epoch 406: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.13it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.390, valid_loss=3.330]\n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=3.330]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=3.330]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=3.330]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=3.330]        \n",
      "Epoch 413: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.57it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.382, valid_loss=3.330]\n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=3.330]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=3.330]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=3.330]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=3.330]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=3.330]        \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=3.330]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=3.330]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=3.330]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=3.330]        \n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=3.330]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=3.330]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=3.330]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.330]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=3.330]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=3.330]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=3.330]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=3.330]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=3.330]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=3.330]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=3.330]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=3.330]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=3.330]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=3.330]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.330]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=3.330]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.330]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=3.330]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=3.330]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=3.330]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=3.330]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=3.330]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.330]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=3.330]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=3.330]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=3.330]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.391, valid_loss=3.330]        \n",
      "Epoch 489: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.99it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=3.330]\n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=3.330]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=3.330]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=3.330]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=3.330]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=3.330]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.73it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.366, valid_loss=3.330]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 381.23it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=49235)\u001b[0m \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.69it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=3.480]\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=3.480]        \n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=3.480]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=3.480]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.480]        \n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=3.480]\n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=3.480]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=3.480]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=3.480]        \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=3.480]        \n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=3.480]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=3.480]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.480]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=3.480]        \n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=3.480]        \n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=3.480]        \n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.480]        \n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=3.480]        \n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=3.480]        \n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.480]        \n",
      "Epoch 533: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.04it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.480]\n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=3.480]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=3.480]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=3.480]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=3.480]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=3.480]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.480]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=3.480]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.480]        \n",
      "Epoch 548: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.12it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.307, valid_loss=3.480]\n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=3.480]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=3.480]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=3.480]        \n",
      "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=3.480]        \n",
      "Epoch 555: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.44it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.480]\n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=3.480]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=3.480]        \n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=3.480]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=3.480]        \n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=3.480]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=3.480]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.480]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=3.480]        \n",
      "Epoch 570: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.24it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.480]\n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=3.480]        \n",
      "Epoch 574: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.83it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.326, valid_loss=3.480]\n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=3.480]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=3.480]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=3.480]        \n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.480]        \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=3.480]        \n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.480]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=3.480]        \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=3.480]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=3.480]        \n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=3.480]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=3.480]        \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=3.480]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.24it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.291, valid_loss=3.480]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 385.47it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=3.530]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=3.530]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=3.530]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=3.530]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.530]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=3.530]        \n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=3.530]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=3.530]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=3.530]        \n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=3.530]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=3.530]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=3.530]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=3.530]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.530]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=3.530]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=3.530]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.530]        \n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=3.530]        \n",
      "Epoch 637: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.38it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=3.530]\n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=3.530]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=3.530]        \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=3.530]        \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=3.530]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=3.530]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=3.530]        \n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=3.530]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=3.530]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=3.530]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=3.530]        \n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=3.530]        \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=3.530]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=3.530]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=3.530]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=3.530]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=3.530]        \n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=3.530]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=3.530]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=3.530]        \n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=3.530]        \n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=3.530]        \n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=3.530]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=3.530]        \n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=3.530]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=3.530]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=3.530]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=3.530]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=3.530]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=3.530]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=3.530]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.87it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.233, valid_loss=3.530]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 383.99it/s]\u001b[A\n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=3.620]        \n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=3.620]        \n",
      "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=3.620]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248, valid_loss=3.620]        \n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=3.620]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248, valid_loss=3.620]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=3.620]        \n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=3.620]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=3.620]        \n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=3.620]        \n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=3.620]        \n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=3.620]        \n",
      "Epoch 724: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.75it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=3.620]\n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=3.620]        \n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=3.620]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=3.620]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=3.620]        \n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=3.620]        \n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=3.620]        \n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=3.620]        \n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=3.620]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=3.620]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=3.620]        \n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=3.620]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=3.620]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=3.620]        \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=3.620]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=3.620]        \n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=3.620]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.620]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=3.620]        \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=3.620]        \n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=3.620]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=3.620]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=3.620]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=3.620]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=3.620]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=3.620]        \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=3.620]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.620]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=3.620]        \n",
      "Epoch 768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.86it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.213, valid_loss=3.620]\n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=3.620]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.620]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=3.620]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=3.620]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.620]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=3.620]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=3.620]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=3.620]        \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=3.620]        \n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.620]        \n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=3.620]        \n",
      "Epoch 787: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.01it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=3.620]\n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=3.620]        \n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=3.620]        \n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=3.620]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=3.620]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=3.620]        \n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=3.620]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=3.620]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=3.620]        \n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=3.620]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.18it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.209, valid_loss=3.620]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 359.07it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=3.700]        \n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.700]        \n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=3.700]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=3.700]        \n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.700]        \n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=3.700]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=3.700]        \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=3.700]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=3.700]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=3.700]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=3.700]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.700]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=3.700]        \n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.700]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.700]        \n",
      "Epoch 823: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.35it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=3.700]\n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=3.700]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=3.700]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=3.700]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.700]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=3.700]        \n",
      "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=3.700]        \n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=3.700]        \n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=3.700]        \n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.700]        \n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.700]        \n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.700]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.700]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=3.700]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=3.700]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=3.700]        \n",
      "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.700]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=3.700]        \n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.700]        \n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.700]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=3.700]        \n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=3.700]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=3.700]        \n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=3.700]        \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.700]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=3.700]        \n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=3.700]        \n",
      "Epoch 874: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.78it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=3.700]\n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=3.700]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=3.700]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=3.700]        \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=3.700]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=3.700]        \n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=3.700]        \n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=3.700]        \n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=3.700]        \n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=3.700]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=3.700]        \n",
      "Epoch 893: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.33it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.700]\n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.700]        \n",
      "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=3.700]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=3.700]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.69it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.193, valid_loss=3.700]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 319.59it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=3.720]        \n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=3.720]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=3.720]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.720]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.720]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.720]        \n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.720]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.720]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=3.720]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=3.720]        \n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=3.720]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.720]        \n",
      "Epoch 921: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.86it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.720]\n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.720]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=3.720]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.720]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.720]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=3.720]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=3.720]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=3.720]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.720]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.720]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=3.720]        \n",
      "Epoch 941: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.85it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=3.720]\n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=3.720]        \n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.720]        \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.720]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.720]        \n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=3.720]        \n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=3.720]        \n",
      "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=3.720]        \n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=3.720]        \n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=3.720]        \n",
      "Epoch 958: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.15it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.720]\n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.720]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=3.720]        \n",
      "Epoch 962: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.69it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.179, valid_loss=3.720]\n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=3.720]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=3.720]        \n",
      "Epoch 964: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.85it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.193, valid_loss=3.720]\n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=3.720]        \n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=3.720]        \n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=3.720]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=3.720]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.720]        \n",
      "Epoch 974: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.10it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=3.720]\n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.720]        \n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.720]        \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=3.720]        \n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=3.720]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.720]        \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=3.720]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=3.720]        \n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=3.720]        \n",
      "Epoch 988: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.26it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.188, valid_loss=3.720]\n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=3.720]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.720]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=3.720]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=3.720]        \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.720]        \n",
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=3.720]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.64it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.178, valid_loss=3.720]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 377.36it/s]\u001b[A\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.21it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=3.710]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=49235)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=49235)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[36m(_train_tune pid=49747)\u001b[0m Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]        \n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]        \n",
      "Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.95it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]\n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]        \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]        \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170]        \n",
      "Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.44it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]\n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.56it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060]        \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070]        \n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.89it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.030]\n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]        \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983]        \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.966]        \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928]        \n",
      "Epoch 86: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.96it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959]\n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940]        \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=0.917]        \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931]        \n",
      "Epoch 95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.56it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914]\n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914]        \n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=0.902]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.50it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.888]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 406.19it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=0.403]       \n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.904, train_loss_epoch=0.904, valid_loss=0.403]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.898, train_loss_epoch=0.898, valid_loss=0.403]        \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.833, train_loss_epoch=0.833, valid_loss=0.403]        \n",
      "Epoch 109: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.67it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=0.403]\n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=0.403]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=0.403]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=0.403]        \n",
      "Epoch 116: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.20it/s, v_num=0, train_loss_step=0.814, train_loss_epoch=0.814, valid_loss=0.403]\n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.814, train_loss_epoch=0.814, valid_loss=0.403]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=0.403]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780, valid_loss=0.403]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.760, train_loss_epoch=0.760, valid_loss=0.403]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=0.403]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.736, train_loss_epoch=0.736, valid_loss=0.403]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.726, train_loss_epoch=0.726, valid_loss=0.403]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.790, train_loss_epoch=0.790, valid_loss=0.403]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.782, train_loss_epoch=0.782, valid_loss=0.403]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=0.758, valid_loss=0.403]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714, valid_loss=0.403]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.729, train_loss_epoch=0.729, valid_loss=0.403]        \n",
      "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.744, train_loss_epoch=0.744, valid_loss=0.403]        \n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=0.403]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.666, train_loss_epoch=0.666, valid_loss=0.403]        \n",
      "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.650, train_loss_epoch=0.650, valid_loss=0.403]        \n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=0.403]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=0.403]        \n",
      "Epoch 153: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.60it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=0.403]\n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=0.403]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.403]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673, valid_loss=0.403]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=0.403]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.587, train_loss_epoch=0.587, valid_loss=0.403]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.403]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.403]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=0.403]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=0.403]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.403]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.403]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=0.403]        \n",
      "Epoch 176: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.06it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.403]\n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.403]        \n",
      "Epoch 178: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.61it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.403]\n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.586, train_loss_epoch=0.586, valid_loss=0.403]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.403]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.403]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582, valid_loss=0.403]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=0.403]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.403]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.403]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.403]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.403]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.403]        \n",
      "Epoch 198: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.76it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.403]\n",
      "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.403]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.28it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.561, valid_loss=0.403]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 397.11it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=2.150]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=2.150]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=2.150]        \n",
      "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=2.150]        \n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=2.150]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=2.150]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=2.150]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=2.150]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=2.150]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.588, train_loss_epoch=0.588, valid_loss=2.150]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=2.150]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=2.150]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=2.150]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=2.150]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=2.150]        \n",
      "Epoch 228: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.58it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=2.150]\n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=2.150]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=2.150]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=2.150]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=2.150]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=2.150]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=2.150]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=2.150]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=2.150]        \n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=2.150]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=2.150]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=2.150]        \n",
      "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=2.150]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=2.150]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=2.150]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=2.150]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=2.150]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474, valid_loss=2.150]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.447, train_loss_epoch=0.447, valid_loss=2.150]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=2.150]        \n",
      "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=2.150]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=2.150]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=2.150]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=2.150]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=2.150]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496, valid_loss=2.150]        \n",
      "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=2.150]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=2.150]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=2.150]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=2.150]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=2.150]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=2.150]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=2.150]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=2.150]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=2.150]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=2.150]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=2.150]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 24.22it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.399, valid_loss=2.150]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 395.47it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=2.760]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=2.760]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=2.760]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=2.760]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=2.760]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=2.760]        \n",
      "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=2.760]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=2.760]        \n",
      "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=2.760]        \n",
      "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=2.760]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=2.760]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=2.760]        \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=2.760]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=2.760]        \n",
      "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=2.760]        \n",
      "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=2.760]        \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=2.760]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=2.760]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=2.760]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=2.760]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=2.760]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=2.760]        \n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=2.760]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=2.760]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=2.760]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=2.760]        \n",
      "Epoch 350: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.37it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=2.760]\n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=2.760]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=2.760]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=2.760]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=2.760]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=2.760]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=2.760]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=2.760]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=2.760]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=2.760]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=2.760]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=2.760]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=2.760]        \n",
      "Epoch 371: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.03it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=2.760]\n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=2.760]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=2.760]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=2.760]\n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=2.760]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=2.760]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=2.760]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=2.760]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=2.760]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=2.760]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=2.760]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=2.760]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=2.760]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=2.760]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=2.760]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=2.760]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.20it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.320, valid_loss=2.760]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 375.23it/s]\u001b[A\n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=2.750]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=2.750]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=2.750]        \n",
      "Epoch 405: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.34it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=2.750]\n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=2.750]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=2.750]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=2.750]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=2.750]        \n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=2.750]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=2.750]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=2.750]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=2.750]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=2.750]        \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=2.750]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=2.750]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=2.750]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=2.750]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=2.750]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=2.750]        \n",
      "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=2.750]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=2.750]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=2.750]        \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=2.750]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=2.750]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=2.750]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=2.750]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=2.750]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=2.750]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=2.750]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=2.750]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=2.750]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=2.750]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=2.750]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=2.750]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=2.750]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=2.750]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=2.750]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=2.750]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=2.750]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=2.750]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=2.750]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=2.750]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=2.750]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=2.750]        \n",
      "Epoch 480: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.87it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=2.750]\n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=2.750]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=2.750]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=2.750]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=2.750]        \n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=2.750]        \n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=2.750]        \n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=2.750]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=2.750]        \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=2.750]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=2.750]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.01it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.277, valid_loss=2.750]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 322.37it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=2.870]        \n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=2.870]        \n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=2.870]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=2.870]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=2.870]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=2.870]        \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=2.870]        \n",
      "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=2.870]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=2.870]        \n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=2.870]        \n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=2.870]        \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=2.870]        \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=2.870]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=2.870]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=2.870]        \n",
      "Epoch 528: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.98it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=2.870]\n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=2.870]        \n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=2.870]        \n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=2.870]        \n",
      "Epoch 534: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.22it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=2.870]\n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=2.870]        \n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=2.870]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=2.870]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=2.870]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=2.870]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=2.870]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=2.870]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=2.870]        \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=2.870]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=2.870]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=2.870]        \n",
      "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=2.870]        \n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=2.870]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=2.870]        \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=2.870]        \n",
      "Epoch 561: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.86it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=2.870]\n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=2.870]        \n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=2.870]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=2.870]        \n",
      "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=2.870]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=2.870]        \n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=2.870]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=2.870]        \n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=2.870]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=2.870]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=2.870]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=2.870]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=2.870]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=2.870]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=2.870]        \n",
      "Epoch 588: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.23it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=2.870]\n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=2.870]        \n",
      "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=2.870]        \n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=2.870]        \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=2.870]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=2.870]        \n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=2.870]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.09it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.263, valid_loss=2.870]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 380.64it/s]\u001b[A\n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=3.190]        \n",
      "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=3.190]        \n",
      "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=3.190]        \n",
      "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=3.190]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=3.190]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248, valid_loss=3.190]        \n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=3.190]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=3.190]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=3.190]        \n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=3.190]        \n",
      "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=3.190]        \n",
      "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=3.190]        \n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=3.190]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=3.190]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=3.190]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=3.190]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=3.190]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=3.190]        \n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=3.190]        \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=3.190]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=3.190]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=3.190]        \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248, valid_loss=3.190]        \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=3.190]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=3.190]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=3.190]        \n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=3.190]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=3.190]        \n",
      "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=3.190]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=3.190]        \n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248, valid_loss=3.190]        \n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=3.190]        \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=3.190]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=3.190]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=3.190]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=3.190]        \n",
      "Epoch 669: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.93it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=3.190]\n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=3.190]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=3.190]        \n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.190]        \n",
      "Epoch 673: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.59it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=3.190]\n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=3.190]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=3.190]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=3.190]        \n",
      "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=3.190]        \n",
      "Epoch 679: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.94it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=3.190]\n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=3.190]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=3.190]        \n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=3.190]        \n",
      "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=3.190]        \n",
      "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=3.190]        \n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=3.190]        \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=3.190]        \n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=3.190]        \n",
      "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=3.190]        \n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=3.190]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.37it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.216, valid_loss=3.190]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 372.76it/s]\u001b[A\n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=3.260]        \n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=3.260]        \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=3.260]        \n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=3.260]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=3.260]        \n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=3.260]        \n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=3.260]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=3.260]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=3.260]        \n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=3.260]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=3.260]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.260]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=3.260]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=3.260]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.260]        \n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=3.260]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=3.260]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=3.260]        \n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=3.260]        \n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.260]        \n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=3.260]        \n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=3.260]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=3.260]        \n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.260]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.260]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=3.260]        \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=3.260]        \n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=3.260]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.260]        \n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=3.260]        \n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=3.260]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=3.260]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.260]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.260]        \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=3.260]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.260]        \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=3.260]        \n",
      "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=3.260]        \n",
      "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=3.260]        \n",
      "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=3.260]        \n",
      "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=3.260]        \n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=3.260]        \n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.260]        \n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=3.260]        \n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=3.260]        \n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.260]        \n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.260]        \n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=3.260]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.260]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=3.260]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.260]        \n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=3.260]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.68it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.214, valid_loss=3.260]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 376.91it/s]\u001b[A\n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=3.390]        \n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.390]        \n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.390]        \n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=3.390]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=3.390]        \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=3.390]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=3.390]        \n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=3.390]        \n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=3.390]        \n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=3.390]        \n",
      "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=3.390]        \n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.390]        \n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=3.390]        \n",
      "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.390]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.390]        \n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=3.390]        \n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.390]        \n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=3.390]        \n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=3.390]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.390]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=3.390]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=3.390]        \n",
      "Epoch 843: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.39it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=3.390]\n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=3.390]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.390]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=3.390]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=3.390]        \n",
      "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.390]        \n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=3.390]        \n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.390]        \n",
      "Epoch 855: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.61it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=3.390]\n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=3.390]        \n",
      "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=3.390]        \n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=3.390]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.390]        \n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=3.390]        \n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.390]        \n",
      "Epoch 865: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.63it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=3.390]\n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=3.390]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=3.390]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=3.390]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.390]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.390]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.390]        \n",
      "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=3.390]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.390]        \n",
      "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=3.390]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=3.390]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=3.390]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=3.390]        \n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=3.390]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.390]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=3.390]        \n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=3.390]        \n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=3.390]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.390]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.84it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.195, valid_loss=3.390]\n",
      "\u001b[36m(_train_tune pid=49747)\u001b[0m \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=49747)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 367.24it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=49747)\u001b[0m \n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.460]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.460]        \n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=3.460]        \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=3.460]        \n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=3.460]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=3.460]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=3.460]        \n",
      "Epoch 913: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  9.94it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.460]\n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.460]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.460]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=3.460]        \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=3.460]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=3.460]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=3.460]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=3.460]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=3.460]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=3.460]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.460]        \n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=3.460]        \n",
      "Epoch 931: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.63it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=3.460]\n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=3.460]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=3.460]        \n",
      "Epoch 934: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.28it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=3.460]\n",
      "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=3.460]        \n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.460]        \n",
      "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=3.460]        \n",
      "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=3.460]        \n",
      "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=3.460]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=3.460]        \n",
      "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=3.460]        \n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.460]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=3.460]        \n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=3.460]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=3.460]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.460]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=3.460]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.460]        \n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=3.460]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=3.460]        \n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=3.460]        \n",
      "Epoch 962: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.34it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.460]\n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.460]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=3.460]        \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=3.460]        \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.460]        \n",
      "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.460]        \n",
      "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=3.460]        \n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=3.460]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=3.460]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=3.460]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=3.460]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=3.460]        \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=3.460]        \n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=3.460]        \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=3.460]        \n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.460]        \n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=3.460]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=3.460]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=3.460]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=3.460]        \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=3.460]        \n",
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=3.460]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.39it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.190, valid_loss=3.460]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 353.74it/s]\u001b[A\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.53it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=3.540]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=49747)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=49747)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[36m(_train_tune pid=50258)\u001b[0m Seed set to 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 91.68it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870]       \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880]        \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770]        \n",
      "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760]        \n",
      "Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.11it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]\n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600]        \n",
      "Epoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.90it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530]\n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450]        \n",
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.01it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.450]\n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350]        \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270]        \n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260]        \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]        \n",
      "Epoch 87: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.89it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914]\n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.947, train_loss_epoch=0.947]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.926, train_loss_epoch=0.926]        \n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.888, train_loss_epoch=0.888]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.07it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.866]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 404.97it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=2.940]       \n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.821, train_loss_epoch=0.821, valid_loss=2.940]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=2.940]        \n",
      "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.837, train_loss_epoch=0.837, valid_loss=2.940]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.779, train_loss_epoch=0.779, valid_loss=2.940]        \n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=2.940]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=2.940]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714, valid_loss=2.940]        \n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.700, train_loss_epoch=0.700, valid_loss=2.940]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.720, train_loss_epoch=0.720, valid_loss=2.940]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=2.940]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660, valid_loss=2.940]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=2.940]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.636, train_loss_epoch=0.636, valid_loss=2.940]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=2.940]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=2.940]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=2.940]        \n",
      "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=2.940]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=2.940]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=2.940]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=2.940]        \n",
      "Epoch 141: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.23it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=2.940]\n",
      "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=2.940]        \n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=2.940]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=2.940]        \n",
      "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=2.940]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.495, train_loss_epoch=0.495, valid_loss=2.940]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=2.940]        \n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=2.940]        \n",
      "Epoch 155: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.43it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.454, valid_loss=2.940]\n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=2.940]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=2.940]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392, valid_loss=2.940]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=2.940]        \n",
      "Epoch 162: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.70it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.380, valid_loss=2.940]\n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=2.940]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=2.940]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=2.940]        \n",
      "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=2.940]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=2.940]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=2.940]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=2.940]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=2.940]        \n",
      "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=2.940]        \n",
      "Epoch 180: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.44it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.351, valid_loss=2.940]\n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=2.940]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=2.940]        \n",
      "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=2.940]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=2.940]        \n",
      "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=2.940]        \n",
      "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=2.940]        \n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=2.940]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=2.940]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=2.940]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.47it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.271, valid_loss=2.940]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 368.70it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=2.930]        \n",
      "Epoch 202: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.31it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=2.930]\n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=2.930]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=2.930]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=2.930]        \n",
      "Epoch 209: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.39it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=2.930]\n",
      "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=2.930]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=2.930]        \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=2.930]        \n",
      "Epoch 216: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.43it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=2.930]\n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=2.930]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=2.930]        \n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=2.930]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=2.930]        \n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=2.930]        \n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=2.930]        \n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=2.930]        \n",
      "Epoch 231: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.13it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.190, valid_loss=2.930]\n",
      "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=2.930]        \n",
      "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=2.930]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=2.930]        \n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=2.930]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=2.930]        \n",
      "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=2.930]        \n",
      "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=2.930]        \n",
      "Epoch 245: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.80it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=2.930]\n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=2.930]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=2.930]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=2.930]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=2.930]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=2.930]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=2.930]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=2.930]        \n",
      "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=2.930]        \n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=2.930]        \n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=2.930]        \n",
      "Epoch 265: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.46it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.128, valid_loss=2.930]\n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=2.930]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=2.930]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=2.930]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.133, train_loss_epoch=0.133, valid_loss=2.930]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118, valid_loss=2.930]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=2.930]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=2.930]        \n",
      "Epoch 278: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.11it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=2.930]\n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=2.930]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=2.930]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=2.930]        \n",
      "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121, valid_loss=2.930]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.100, train_loss_epoch=0.100, valid_loss=2.930]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=2.930]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102, valid_loss=2.930]          \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0921, train_loss_epoch=0.0921, valid_loss=2.930]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0944, train_loss_epoch=0.0944, valid_loss=2.930]        \n",
      "Epoch 297: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.84it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103, valid_loss=2.930]  \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0897, train_loss_epoch=0.0897, valid_loss=2.930]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.01it/s, v_num=0, train_loss_step=0.0913, train_loss_epoch=0.098, valid_loss=2.930] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 403.41it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0913, train_loss_epoch=0.0913, valid_loss=3.030]        \n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0819, train_loss_epoch=0.0819, valid_loss=3.030]        \n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0803, train_loss_epoch=0.0803, valid_loss=3.030]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0888, train_loss_epoch=0.0888, valid_loss=3.030]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0842, train_loss_epoch=0.0842, valid_loss=3.030]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.089, train_loss_epoch=0.089, valid_loss=3.030]          \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0811, train_loss_epoch=0.0811, valid_loss=3.030]        \n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0998, train_loss_epoch=0.0998, valid_loss=3.030]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=3.030]          \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0866, train_loss_epoch=0.0866, valid_loss=3.030]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111, valid_loss=3.030]          \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0803, train_loss_epoch=0.0803, valid_loss=3.030]        \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0865, train_loss_epoch=0.0865, valid_loss=3.030]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0933, train_loss_epoch=0.0933, valid_loss=3.030]        \n",
      "Epoch 328: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.32it/s, v_num=0, train_loss_step=0.0816, train_loss_epoch=0.0816, valid_loss=3.030]\n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0816, train_loss_epoch=0.0816, valid_loss=3.030]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0715, train_loss_epoch=0.0715, valid_loss=3.030]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0701, train_loss_epoch=0.0701, valid_loss=3.030]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0639, train_loss_epoch=0.0639, valid_loss=3.030]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0614, train_loss_epoch=0.0614, valid_loss=3.030]        \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0579, train_loss_epoch=0.0579, valid_loss=3.030]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0488, train_loss_epoch=0.0488, valid_loss=3.030]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0528, train_loss_epoch=0.0528, valid_loss=3.030]        \n",
      "Epoch 343: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.63it/s, v_num=0, train_loss_step=0.0414, train_loss_epoch=0.0414, valid_loss=3.030]\n",
      "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0414, train_loss_epoch=0.0414, valid_loss=3.030]        \n",
      "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0471, train_loss_epoch=0.0471, valid_loss=3.030]        \n",
      "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0434, train_loss_epoch=0.0434, valid_loss=3.030]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0428, train_loss_epoch=0.0428, valid_loss=3.030]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0416, train_loss_epoch=0.0416, valid_loss=3.030]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=3.030]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=3.030]        \n",
      "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.0396, valid_loss=3.030]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0395, train_loss_epoch=0.0395, valid_loss=3.030]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=3.030]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=3.030]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0271, train_loss_epoch=0.0271, valid_loss=3.030]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=3.030]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=3.030]          \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=3.030]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0273, train_loss_epoch=0.0273, valid_loss=3.030]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=3.030]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0361, train_loss_epoch=0.0361, valid_loss=3.030]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=3.030]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=3.030]        \n",
      "Epoch 381: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.36it/s, v_num=0, train_loss_step=0.0255, train_loss_epoch=0.026, valid_loss=3.030] \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0255, train_loss_epoch=0.0255, valid_loss=3.030]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0325, train_loss_epoch=0.0325, valid_loss=3.030]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.026, train_loss_epoch=0.026, valid_loss=3.030]          \n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274, valid_loss=3.030]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0235, train_loss_epoch=0.0235, valid_loss=3.030]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=3.030]        \n",
      "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=3.030]        \n",
      "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=3.030]        \n",
      "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0276, train_loss_epoch=0.0276, valid_loss=3.030]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.84it/s, v_num=0, train_loss_step=0.0224, train_loss_epoch=0.0276, valid_loss=3.030]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 379.68it/s]\u001b[A\n",
      "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0205, train_loss_epoch=0.0205, valid_loss=3.050]        \n",
      "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0241, valid_loss=3.050]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0206, train_loss_epoch=0.0206, valid_loss=3.050]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0194, train_loss_epoch=0.0194, valid_loss=3.050]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0221, train_loss_epoch=0.0221, valid_loss=3.050]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0207, train_loss_epoch=0.0207, valid_loss=3.050]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=3.050]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0213, train_loss_epoch=0.0213, valid_loss=3.050]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0207, train_loss_epoch=0.0207, valid_loss=3.050]        \n",
      "Epoch 417: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.05it/s, v_num=0, train_loss_step=0.0222, train_loss_epoch=0.0222, valid_loss=3.050]\n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0222, train_loss_epoch=0.0222, valid_loss=3.050]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0168, train_loss_epoch=0.0168, valid_loss=3.050]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.019, train_loss_epoch=0.019, valid_loss=3.050]          \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.019, train_loss_epoch=0.019, valid_loss=3.050]          \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0172, train_loss_epoch=0.0172, valid_loss=3.050]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0153, train_loss_epoch=0.0153, valid_loss=3.050]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0171, train_loss_epoch=0.0171, valid_loss=3.050]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0189, train_loss_epoch=0.0189, valid_loss=3.050]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.021, train_loss_epoch=0.021, valid_loss=3.050]          \n",
      "Epoch 434: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.33it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=3.050]\n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=3.050]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0197, train_loss_epoch=0.0197, valid_loss=3.050]        \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0202, train_loss_epoch=0.0202, valid_loss=3.050]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0209, train_loss_epoch=0.0209, valid_loss=3.050]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0176, train_loss_epoch=0.0176, valid_loss=3.050]        \n",
      "Epoch 443: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.88it/s, v_num=0, train_loss_step=0.020, train_loss_epoch=0.020, valid_loss=3.050]  \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.020, train_loss_epoch=0.020, valid_loss=3.050]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=3.050]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.017, train_loss_epoch=0.017, valid_loss=3.050]          \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0164, train_loss_epoch=0.0164, valid_loss=3.050]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=3.050]        \n",
      "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0178, train_loss_epoch=0.0178, valid_loss=3.050]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0182, train_loss_epoch=0.0182, valid_loss=3.050]        \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=3.050]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0173, train_loss_epoch=0.0173, valid_loss=3.050]        \n",
      "Epoch 459: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.62it/s, v_num=0, train_loss_step=0.0221, train_loss_epoch=0.0221, valid_loss=3.050]\n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0221, train_loss_epoch=0.0221, valid_loss=3.050]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=3.050]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0159, train_loss_epoch=0.0159, valid_loss=3.050]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=3.050]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=3.050]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=3.050]        \n",
      "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=3.050]        \n",
      "Epoch 472: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.73it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=3.050]\n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=3.050]        \n",
      "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0168, train_loss_epoch=0.0168, valid_loss=3.050]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=3.050]          \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0154, train_loss_epoch=0.0154, valid_loss=3.050]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00715, train_loss_epoch=0.00715, valid_loss=3.050]        \n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=3.050]          \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=3.050]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=3.050]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=3.050]          \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=3.050]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00942, train_loss_epoch=0.00942, valid_loss=3.050]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0146, valid_loss=3.050]          \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=3.050]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.05it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0106, valid_loss=3.050]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 390.31it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=3.000]        \n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00921, train_loss_epoch=0.00921, valid_loss=3.000]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=3.000]          \n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=3.000]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0077, train_loss_epoch=0.0077, valid_loss=3.000]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00852, train_loss_epoch=0.00852, valid_loss=3.000]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=3.000]            \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00801, train_loss_epoch=0.00801, valid_loss=3.000]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=3.000]          \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00896, train_loss_epoch=0.00896, valid_loss=3.000]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00768, train_loss_epoch=0.00768, valid_loss=3.000]        \n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=3.000]          \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00945, train_loss_epoch=0.00945, valid_loss=3.000]        \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00811, train_loss_epoch=0.00811, valid_loss=3.000]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00997, train_loss_epoch=0.00997, valid_loss=3.000]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00988, train_loss_epoch=0.00988, valid_loss=3.000]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00573, train_loss_epoch=0.00573, valid_loss=3.000]        \n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00764, train_loss_epoch=0.00764, valid_loss=3.000]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00931, train_loss_epoch=0.00931, valid_loss=3.000]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00876, train_loss_epoch=0.00876, valid_loss=3.000]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00573, train_loss_epoch=0.00573, valid_loss=3.000]        \n",
      "Epoch 540: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.94it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=3.000]  \n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=3.000]        \n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00696, train_loss_epoch=0.00696, valid_loss=3.000]        \n",
      "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=3.000]          \n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0082, train_loss_epoch=0.0082, valid_loss=3.000]          \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00618, train_loss_epoch=0.00618, valid_loss=3.000]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0089, train_loss_epoch=0.0089, valid_loss=3.000]          \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00904, train_loss_epoch=0.00904, valid_loss=3.000]        \n",
      "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00711, train_loss_epoch=0.00711, valid_loss=3.000]        \n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00582, train_loss_epoch=0.00582, valid_loss=3.000]        \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00888, train_loss_epoch=0.00888, valid_loss=3.000]        \n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00695, train_loss_epoch=0.00695, valid_loss=3.000]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00542, train_loss_epoch=0.00542, valid_loss=3.000]        \n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00945, train_loss_epoch=0.00945, valid_loss=3.000]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00907, train_loss_epoch=0.00907, valid_loss=3.000]        \n",
      "Epoch 566: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.35it/s, v_num=0, train_loss_step=0.00717, train_loss_epoch=0.00717, valid_loss=3.000]\n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00717, train_loss_epoch=0.00717, valid_loss=3.000]        \n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00816, train_loss_epoch=0.00816, valid_loss=3.000]        \n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00691, train_loss_epoch=0.00691, valid_loss=3.000]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00823, train_loss_epoch=0.00823, valid_loss=3.000]        \n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00578, train_loss_epoch=0.00578, valid_loss=3.000]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00877, train_loss_epoch=0.00877, valid_loss=3.000]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00863, train_loss_epoch=0.00863, valid_loss=3.000]        \n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00714, train_loss_epoch=0.00714, valid_loss=3.000]        \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00548, train_loss_epoch=0.00548, valid_loss=3.000]        \n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00623, train_loss_epoch=0.00623, valid_loss=3.000]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00783, train_loss_epoch=0.00783, valid_loss=3.000]        \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00798, train_loss_epoch=0.00798, valid_loss=3.000]        \n",
      "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00834, train_loss_epoch=0.00834, valid_loss=3.000]        \n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00904, train_loss_epoch=0.00904, valid_loss=3.000]        \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00571, train_loss_epoch=0.00571, valid_loss=3.000]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00668, train_loss_epoch=0.00668, valid_loss=3.000]        \n",
      "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00576, train_loss_epoch=0.00576, valid_loss=3.000]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.03it/s, v_num=0, train_loss_step=0.00648, train_loss_epoch=0.00576, valid_loss=3.000]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 352.02it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00648, train_loss_epoch=0.00648, valid_loss=3.000]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0081, train_loss_epoch=0.0081, valid_loss=3.000]          \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00656, train_loss_epoch=0.00656, valid_loss=3.000]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00735, train_loss_epoch=0.00735, valid_loss=3.000]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00812, train_loss_epoch=0.00812, valid_loss=3.000]        \n",
      "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00691, train_loss_epoch=0.00691, valid_loss=3.000]        \n",
      "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00846, train_loss_epoch=0.00846, valid_loss=3.000]        \n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00999, train_loss_epoch=0.00999, valid_loss=3.000]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00732, train_loss_epoch=0.00732, valid_loss=3.000]        \n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00673, train_loss_epoch=0.00673, valid_loss=3.000]        \n",
      "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00811, train_loss_epoch=0.00811, valid_loss=3.000]        \n",
      "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00813, train_loss_epoch=0.00813, valid_loss=3.000]        \n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00679, train_loss_epoch=0.00679, valid_loss=3.000]        \n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00707, train_loss_epoch=0.00707, valid_loss=3.000]        \n",
      "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00799, train_loss_epoch=0.00799, valid_loss=3.000]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00792, train_loss_epoch=0.00792, valid_loss=3.000]        \n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=3.000]          \n",
      "Epoch 631: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.07it/s, v_num=0, train_loss_step=0.00768, train_loss_epoch=0.00768, valid_loss=3.000]\n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00768, train_loss_epoch=0.00768, valid_loss=3.000]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00825, train_loss_epoch=0.00825, valid_loss=3.000]        \n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00869, train_loss_epoch=0.00869, valid_loss=3.000]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00638, train_loss_epoch=0.00638, valid_loss=3.000]        \n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00769, train_loss_epoch=0.00769, valid_loss=3.000]        \n",
      "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00837, train_loss_epoch=0.00837, valid_loss=3.000]        \n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00855, train_loss_epoch=0.00855, valid_loss=3.000]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00705, train_loss_epoch=0.00705, valid_loss=3.000]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00678, train_loss_epoch=0.00678, valid_loss=3.000]        \n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00828, train_loss_epoch=0.00828, valid_loss=3.000]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00761, train_loss_epoch=0.00761, valid_loss=3.000]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00807, train_loss_epoch=0.00807, valid_loss=3.000]        \n",
      "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00887, train_loss_epoch=0.00887, valid_loss=3.000]        \n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00694, train_loss_epoch=0.00694, valid_loss=3.000]        \n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00695, train_loss_epoch=0.00695, valid_loss=3.000]        \n",
      "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00729, train_loss_epoch=0.00729, valid_loss=3.000]        \n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0088, train_loss_epoch=0.0088, valid_loss=3.000]          \n",
      "Epoch 660: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.98it/s, v_num=0, train_loss_step=0.00634, train_loss_epoch=0.00726, valid_loss=3.000]\n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00634, train_loss_epoch=0.00634, valid_loss=3.000]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00754, train_loss_epoch=0.00754, valid_loss=3.000]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00764, train_loss_epoch=0.00764, valid_loss=3.000]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00629, train_loss_epoch=0.00629, valid_loss=3.000]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00571, train_loss_epoch=0.00571, valid_loss=3.000]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00454, train_loss_epoch=0.00454, valid_loss=3.000]        \n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00454, train_loss_epoch=0.00454, valid_loss=3.000]\n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00443, train_loss_epoch=0.00443, valid_loss=3.000]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00381, train_loss_epoch=0.00381, valid_loss=3.000]        \n",
      "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00392, train_loss_epoch=0.00392, valid_loss=3.000]        \n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00393, train_loss_epoch=0.00393, valid_loss=3.000]        \n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00325, train_loss_epoch=0.00325, valid_loss=3.000]        \n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00318, train_loss_epoch=0.00318, valid_loss=3.000]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00345, train_loss_epoch=0.00345, valid_loss=3.000]        \n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00343, train_loss_epoch=0.00343, valid_loss=3.000]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00272, train_loss_epoch=0.00272, valid_loss=3.000]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00242, train_loss_epoch=0.00242, valid_loss=3.000]        \n",
      "Epoch 692: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.19it/s, v_num=0, train_loss_step=0.00231, train_loss_epoch=0.00252, valid_loss=3.000]\n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00231, train_loss_epoch=0.00231, valid_loss=3.000]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00229, train_loss_epoch=0.00229, valid_loss=3.000]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00231, train_loss_epoch=0.00231, valid_loss=3.000]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=3.000]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.29it/s, v_num=0, train_loss_step=0.00221, train_loss_epoch=0.00254, valid_loss=3.000]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 377.08it/s]\u001b[A\n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00221, train_loss_epoch=0.00221, valid_loss=2.910]        \n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00263, train_loss_epoch=0.00263, valid_loss=2.910]        \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00198, train_loss_epoch=0.00198, valid_loss=2.910]        \n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00228, train_loss_epoch=0.00228, valid_loss=2.910]        \n",
      "Epoch 707: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.60it/s, v_num=0, train_loss_step=0.00222, train_loss_epoch=0.00197, valid_loss=2.910]\n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00222, train_loss_epoch=0.00222, valid_loss=2.910]        \n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00174, train_loss_epoch=0.00174, valid_loss=2.910]        \n",
      "Epoch 711: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.40it/s, v_num=0, train_loss_step=0.00176, train_loss_epoch=0.00218, valid_loss=2.910]\n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00176, train_loss_epoch=0.00176, valid_loss=2.910]        \n",
      "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00173, train_loss_epoch=0.00173, valid_loss=2.910]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00166, train_loss_epoch=0.00166, valid_loss=2.910]        \n",
      "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00185, train_loss_epoch=0.00185, valid_loss=2.910]        \n",
      "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00202, train_loss_epoch=0.00202, valid_loss=2.910]        \n",
      "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00204, train_loss_epoch=0.00204, valid_loss=2.910]        \n",
      "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00159, train_loss_epoch=0.00159, valid_loss=2.910]        \n",
      "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00175, train_loss_epoch=0.00175, valid_loss=2.910]        \n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00155, train_loss_epoch=0.00155, valid_loss=2.910]        \n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00171, train_loss_epoch=0.00171, valid_loss=2.910]        \n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00164, train_loss_epoch=0.00164, valid_loss=2.910]        \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00166, train_loss_epoch=0.00166, valid_loss=2.910]        \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00135, train_loss_epoch=0.00135, valid_loss=2.910]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00148, train_loss_epoch=0.00148, valid_loss=2.910]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=2.910]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00151, train_loss_epoch=0.00151, valid_loss=2.910]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00133, train_loss_epoch=0.00133, valid_loss=2.910]        \n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00141, train_loss_epoch=0.00141, valid_loss=2.910]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=2.910]        \n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00135, train_loss_epoch=0.00135, valid_loss=2.910]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00133, train_loss_epoch=0.00133, valid_loss=2.910]        \n",
      "Epoch 747: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.88it/s, v_num=0, train_loss_step=0.00137, train_loss_epoch=0.00133, valid_loss=2.910]\n",
      "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00137, train_loss_epoch=0.00137, valid_loss=2.910]        \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00132, train_loss_epoch=0.00132, valid_loss=2.910]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00135, train_loss_epoch=0.00135, valid_loss=2.910]        \n",
      "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00143, train_loss_epoch=0.00143, valid_loss=2.910]        \n",
      "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00138, train_loss_epoch=0.00138, valid_loss=2.910]        \n",
      "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=2.910]        \n",
      "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=2.910]        \n",
      "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00138, train_loss_epoch=0.00138, valid_loss=2.910]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=2.910]        \n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=2.910]        \n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00126, train_loss_epoch=0.00126, valid_loss=2.910]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=2.910]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00132, train_loss_epoch=0.00132, valid_loss=2.910]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0012, train_loss_epoch=0.0012, valid_loss=2.910]          \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00131, train_loss_epoch=0.00131, valid_loss=2.910]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00112, train_loss_epoch=0.00112, valid_loss=2.910]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0012, train_loss_epoch=0.0012, valid_loss=2.910]          \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00117, train_loss_epoch=0.00117, valid_loss=2.910]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0013, train_loss_epoch=0.0013, valid_loss=2.910]          \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00115, train_loss_epoch=0.00115, valid_loss=2.910]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00112, train_loss_epoch=0.00112, valid_loss=2.910]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0012, train_loss_epoch=0.0012, valid_loss=2.910]          \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00111, train_loss_epoch=0.00111, valid_loss=2.910]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00111, train_loss_epoch=0.00111, valid_loss=2.910]        \n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00115, train_loss_epoch=0.00115, valid_loss=2.910]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00102, train_loss_epoch=0.00102, valid_loss=2.910]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=2.910]            \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.31it/s, v_num=0, train_loss_step=0.000996, train_loss_epoch=0.00108, valid_loss=2.910]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=50258)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 352.61it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=50258)\u001b[0m \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.60it/s, v_num=0, train_loss_step=0.000996, train_loss_epoch=0.00108, valid_loss=2.930]\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000996, train_loss_epoch=0.000996, valid_loss=2.930]        \n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000988, train_loss_epoch=0.000988, valid_loss=2.930]        \n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000949, train_loss_epoch=0.000949, valid_loss=2.930]        \n",
      "Epoch 803: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.80it/s, v_num=0, train_loss_step=0.00124, train_loss_epoch=0.00124, valid_loss=2.930]  \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00124, train_loss_epoch=0.00124, valid_loss=2.930]        \n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00108, train_loss_epoch=0.00108, valid_loss=2.930]          \n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000986, train_loss_epoch=0.000986, valid_loss=2.930]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000923, train_loss_epoch=0.000923, valid_loss=2.930]        \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000984, train_loss_epoch=0.000984, valid_loss=2.930]        \n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000903, train_loss_epoch=0.000903, valid_loss=2.930]        \n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000931, train_loss_epoch=0.000931, valid_loss=2.930]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=2.930]            \n",
      "Epoch 816: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.78it/s, v_num=0, train_loss_step=0.000868, train_loss_epoch=0.0011, valid_loss=2.930]\n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000868, train_loss_epoch=0.000868, valid_loss=2.930]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000987, train_loss_epoch=0.000987, valid_loss=2.930]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000937, train_loss_epoch=0.000937, valid_loss=2.930]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000945, train_loss_epoch=0.000945, valid_loss=2.930]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000909, train_loss_epoch=0.000909, valid_loss=2.930]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000895, train_loss_epoch=0.000895, valid_loss=2.930]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00106, train_loss_epoch=0.00106, valid_loss=2.930]          \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00088, train_loss_epoch=0.00088, valid_loss=2.930]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00109, train_loss_epoch=0.00109, valid_loss=2.930]        \n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000911, train_loss_epoch=0.000911, valid_loss=2.930]        \n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000888, train_loss_epoch=0.000888, valid_loss=2.930]        \n",
      "Epoch 835: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.25it/s, v_num=0, train_loss_step=0.000954, train_loss_epoch=0.000954, valid_loss=2.930]\n",
      "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000954, train_loss_epoch=0.000954, valid_loss=2.930]        \n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000861, train_loss_epoch=0.000861, valid_loss=2.930]        \n",
      "Epoch 839: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.66it/s, v_num=0, train_loss_step=0.000841, train_loss_epoch=0.000841, valid_loss=2.930]\n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000841, train_loss_epoch=0.000841, valid_loss=2.930]        \n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000855, train_loss_epoch=0.000855, valid_loss=2.930]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000825, train_loss_epoch=0.000825, valid_loss=2.930]        \n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000917, train_loss_epoch=0.000917, valid_loss=2.930]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000794, train_loss_epoch=0.000794, valid_loss=2.930]        \n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000817, train_loss_epoch=0.000817, valid_loss=2.930]        \n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000831, train_loss_epoch=0.000831, valid_loss=2.930]        \n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000831, train_loss_epoch=0.000831, valid_loss=2.930]        \n",
      "Epoch 852: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.00it/s, v_num=0, train_loss_step=0.000796, train_loss_epoch=0.000796, valid_loss=2.930]\n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000796, train_loss_epoch=0.000796, valid_loss=2.930]        \n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000814, train_loss_epoch=0.000814, valid_loss=2.930]        \n",
      "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000899, train_loss_epoch=0.000899, valid_loss=2.930]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000884, train_loss_epoch=0.000884, valid_loss=2.930]        \n",
      "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000779, train_loss_epoch=0.000779, valid_loss=2.930]        \n",
      "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000795, train_loss_epoch=0.000795, valid_loss=2.930]        \n",
      "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000829, train_loss_epoch=0.000829, valid_loss=2.930]        \n",
      "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000829, train_loss_epoch=0.000829, valid_loss=2.930]        \n",
      "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00091, train_loss_epoch=0.00091, valid_loss=2.930]          \n",
      "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000781, train_loss_epoch=0.000781, valid_loss=2.930]        \n",
      "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000854, train_loss_epoch=0.000854, valid_loss=2.930]        \n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000787, train_loss_epoch=0.000787, valid_loss=2.930]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000842, train_loss_epoch=0.000842, valid_loss=2.930]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000761, train_loss_epoch=0.000761, valid_loss=2.930]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000834, train_loss_epoch=0.000834, valid_loss=2.930]        \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000791, train_loss_epoch=0.000791, valid_loss=2.930]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000785, train_loss_epoch=0.000785, valid_loss=2.930]        \n",
      "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000852, train_loss_epoch=0.000852, valid_loss=2.930]        \n",
      "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000763, train_loss_epoch=0.000763, valid_loss=2.930]        \n",
      "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000774, train_loss_epoch=0.000774, valid_loss=2.930]        \n",
      "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000714, train_loss_epoch=0.000714, valid_loss=2.930]        \n",
      "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000771, train_loss_epoch=0.000771, valid_loss=2.930]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000815, train_loss_epoch=0.000815, valid_loss=2.930]        \n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000619, train_loss_epoch=0.000619, valid_loss=2.930]        \n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000706, train_loss_epoch=0.000706, valid_loss=2.930]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000771, train_loss_epoch=0.000771, valid_loss=2.930]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.42it/s, v_num=0, train_loss_step=0.000849, train_loss_epoch=0.000771, valid_loss=2.930]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 381.54it/s]\u001b[A\n",
      "Epoch 900: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.67it/s, v_num=0, train_loss_step=0.000776, train_loss_epoch=0.000849, valid_loss=2.920]\n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000776, train_loss_epoch=0.000776, valid_loss=2.920]        \n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000784, train_loss_epoch=0.000784, valid_loss=2.920]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000714, train_loss_epoch=0.000714, valid_loss=2.920]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000753, train_loss_epoch=0.000753, valid_loss=2.920]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000768, train_loss_epoch=0.000768, valid_loss=2.920]        \n",
      "Epoch 908: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.87it/s, v_num=0, train_loss_step=0.000689, train_loss_epoch=0.000689, valid_loss=2.920]\n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000689, train_loss_epoch=0.000689, valid_loss=2.920]        \n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000741, train_loss_epoch=0.000741, valid_loss=2.920]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000648, train_loss_epoch=0.000648, valid_loss=2.920]        \n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000763, train_loss_epoch=0.000763, valid_loss=2.920]        \n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000778, train_loss_epoch=0.000778, valid_loss=2.920]        \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000794, train_loss_epoch=0.000794, valid_loss=2.920]        \n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00073, train_loss_epoch=0.00073, valid_loss=2.920]          \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000621, train_loss_epoch=0.000621, valid_loss=2.920]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000675, train_loss_epoch=0.000675, valid_loss=2.920]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000675, train_loss_epoch=0.000675, valid_loss=2.920]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000611, train_loss_epoch=0.000611, valid_loss=2.920]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000677, train_loss_epoch=0.000677, valid_loss=2.920]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000569, train_loss_epoch=0.000569, valid_loss=2.920]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000673, train_loss_epoch=0.000673, valid_loss=2.920]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000648, train_loss_epoch=0.000648, valid_loss=2.920]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000637, train_loss_epoch=0.000637, valid_loss=2.920]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000563, train_loss_epoch=0.000563, valid_loss=2.920]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000683, train_loss_epoch=0.000683, valid_loss=2.920]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000592, train_loss_epoch=0.000592, valid_loss=2.920]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000558, train_loss_epoch=0.000558, valid_loss=2.920]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000592, train_loss_epoch=0.000592, valid_loss=2.920]        \n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000622, train_loss_epoch=0.000622, valid_loss=2.920]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000551, train_loss_epoch=0.000551, valid_loss=2.920]        \n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000598, train_loss_epoch=0.000598, valid_loss=2.920]        \n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00064, train_loss_epoch=0.00064, valid_loss=2.920]          \n",
      "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000611, train_loss_epoch=0.000611, valid_loss=2.920]        \n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000632, train_loss_epoch=0.000632, valid_loss=2.920]        \n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000552, train_loss_epoch=0.000552, valid_loss=2.920]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000534, train_loss_epoch=0.000534, valid_loss=2.920]        \n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000611, train_loss_epoch=0.000611, valid_loss=2.920]        \n",
      "Epoch 962: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.22it/s, v_num=0, train_loss_step=0.000564, train_loss_epoch=0.000611, valid_loss=2.920]\n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000564, train_loss_epoch=0.000564, valid_loss=2.920]        \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00054, train_loss_epoch=0.00054, valid_loss=2.920]          \n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000591, train_loss_epoch=0.000591, valid_loss=2.920]        \n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000564, train_loss_epoch=0.000564, valid_loss=2.920]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000551, train_loss_epoch=0.000551, valid_loss=2.920]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000537, train_loss_epoch=0.000537, valid_loss=2.920]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000542, train_loss_epoch=0.000542, valid_loss=2.920]        \n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000557, train_loss_epoch=0.000557, valid_loss=2.920]        \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00055, train_loss_epoch=0.00055, valid_loss=2.920]          \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000572, train_loss_epoch=0.000572, valid_loss=2.920]        \n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000549, train_loss_epoch=0.000549, valid_loss=2.920]        \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000534, train_loss_epoch=0.000534, valid_loss=2.920]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000565, train_loss_epoch=0.000565, valid_loss=2.920]        \n",
      "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000567, train_loss_epoch=0.000567, valid_loss=2.920]        \n",
      "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00057, train_loss_epoch=0.00057, valid_loss=2.920]          \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00051, train_loss_epoch=0.00051, valid_loss=2.920]          \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000525, train_loss_epoch=0.000525, valid_loss=2.920]        \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000542, train_loss_epoch=0.000542, valid_loss=2.920]        \n",
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000513, train_loss_epoch=0.000513, valid_loss=2.920]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.69it/s, v_num=0, train_loss_step=0.000473, train_loss_epoch=0.000513, valid_loss=2.920]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 386.43it/s]\u001b[A\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.24it/s, v_num=0, train_loss_step=0.000473, train_loss_epoch=0.000473, valid_loss=2.920]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=50258)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=50258)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[36m(_train_tune pid=50786)\u001b[0m Seed set to 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040]        \n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.09it/s, v_num=0, train_loss_step=3.220, train_loss_epoch=3.040]\n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.220, train_loss_epoch=3.220]        \n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960]        \n",
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.34it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.960]\n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870]        \n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030]        \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120]        \n",
      "Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.98it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=3.120]\n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.060, train_loss_epoch=3.060]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930]        \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030]        \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730]        \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660]        \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.79it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.700]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 403.03it/s]\u001b[A\n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.762]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.762]        \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.762]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.762]        \n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.762]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.762]        \n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.762]        \n",
      "Epoch 116: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.89it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.762]\n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.762]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.762]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.762]        \n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.762]        \n",
      "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.762]        \n",
      "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.762]        \n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.762]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.762]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.762]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.762]        \n",
      "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.762]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.762]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.762]        \n",
      "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.762]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.762]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.762]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.762]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.762]        \n",
      "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.762]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.762]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.762]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.762]\n",
      "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.762]        \n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.762]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.762]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.762]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.762]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.762]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.762]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.762]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.762]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.762]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.762]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.762]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.762]        \n",
      "Epoch 193: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.34it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.762]\n",
      "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.762]        \n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.762]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.762]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.31it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.940, valid_loss=0.762]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 405.33it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=1.340]        \n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=1.340]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=1.340]        \n",
      "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=1.340]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=1.340]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=1.340]        \n",
      "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=1.340]\n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=1.340]        \n",
      "Epoch 216: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.61it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.900, valid_loss=1.340]\n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=1.340]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=1.340]        \n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=1.340]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=1.340]        \n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=1.340]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=1.340]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=1.340]        \n",
      "Epoch 232: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.28it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=1.340]\n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=1.340]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=1.340]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=1.340]        \n",
      "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=1.340]        \n",
      "Epoch 241: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.92it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.810, valid_loss=1.340]\n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=1.340]        \n",
      "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=1.340]        \n",
      "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=1.340]        \n",
      "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=1.340]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=1.340]        \n",
      "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=1.340]        \n",
      "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=1.340]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=1.340]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=1.340]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=1.340]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=1.340]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=1.340]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=1.340]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=1.340]        \n",
      "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=1.340]        \n",
      "Epoch 271: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.23it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=1.340]\n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=1.340]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=1.340]        \n",
      "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=1.340]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=1.340]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=1.340]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=1.340]        \n",
      "Epoch 283: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.78it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=1.340]\n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=1.340]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=1.340]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=1.340]        \n",
      "Epoch 290: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.86it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=1.340]\n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=1.340]        \n",
      "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=1.340]        \n",
      "Epoch 292: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.85it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=1.340]\n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=1.340]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=1.340]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=1.340]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=1.340]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.86it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.660, valid_loss=1.340]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 401.91it/s]\u001b[A\n",
      "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=2.940]        \n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=2.940]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=2.940]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=2.940]        \n",
      "Epoch 308: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.27it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=2.940]\n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=2.940]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=2.940]        \n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=2.940]        \n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=2.940]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=2.940]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=2.940]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=2.940]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=2.940]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=2.940]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=2.940]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=2.940]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=2.940]        \n",
      "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=2.940]        \n",
      "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=2.940]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=2.940]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=2.940]        \n",
      "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=2.940]        \n",
      "Epoch 342: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.87it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.390, valid_loss=2.940]\n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=2.940]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=2.940]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=2.940]        \n",
      "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350, valid_loss=2.940]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=2.940]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=2.940]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=2.940]        \n",
      "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=2.940]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=2.940]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=2.940]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=2.940]        \n",
      "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=2.940]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=2.940]        \n",
      "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=2.940]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=2.940]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.940]        \n",
      "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=2.940]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=2.940]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=2.940]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=2.940]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=2.940]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=2.940]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=2.940]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=2.940]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=2.940]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=2.940]        \n",
      "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=2.940]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=2.940]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=2.940]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.09it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.170, valid_loss=2.940]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 343.74it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.360]        \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.360]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.360]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=3.360]        \n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.360]        \n",
      "Epoch 407: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.22it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.360]\n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=3.360]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.360]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.360]        \n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.360]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.360]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=3.360]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.360]        \n",
      "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.360]        \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=3.360]        \n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.360]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.360]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.360]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.360]        \n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.360]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.360]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.360]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.360]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.360]        \n",
      "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.360]        \n",
      "Epoch 444: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.37it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.360]\n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.360]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.360]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.360]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.360]        \n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.360]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.360]        \n",
      "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.360]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.360]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.360]        \n",
      "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.360]        \n",
      "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.360]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=3.360]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=3.360]        \n",
      "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=3.360]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=3.360]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=3.360]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=3.360]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.360]        \n",
      "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.360]        \n",
      "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.360]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.360]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.360]        \n",
      "Epoch 488: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.32it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.360]\n",
      "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.360]        \n",
      "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.360]        \n",
      "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.360]        \n",
      "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.360]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=3.360]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.98it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.080, valid_loss=3.360]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 398.40it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.880]        \n",
      "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=3.880]        \n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.880]        \n",
      "Epoch 506: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 24.11it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.880]\n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.880]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.880]        \n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.880]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.880]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.880]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.880]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.880]        \n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.880]        \n",
      "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.880]        \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=3.880]        \n",
      "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.880]        \n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.880]        \n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.880]        \n",
      "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=3.880]        \n",
      "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.880]        \n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.880]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.880]        \n",
      "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=3.880]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.880]        \n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=3.880]        \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.880]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=3.880]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974, valid_loss=3.880]        \n",
      "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=3.880]        \n",
      "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.880]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=3.880]        \n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=3.880]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=3.880]        \n",
      "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=3.880]        \n",
      "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=3.880]        \n",
      "Epoch 566: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.11it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.880]\n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=3.880]        \n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=3.880]        \n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.880]        \n",
      "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=3.880]        \n",
      "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=3.880]        \n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.880]        \n",
      "Epoch 580: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.95it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.880]\n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.880]        \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=0.918, valid_loss=3.880]        \n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=3.880]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=3.880]        \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.978, train_loss_epoch=0.978, valid_loss=3.880]        \n",
      "Epoch 589: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.94it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=3.880]\n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.995, train_loss_epoch=0.995, valid_loss=3.880]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=3.880]        \n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.962, train_loss_epoch=0.962, valid_loss=3.880]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.915, train_loss_epoch=0.915, valid_loss=3.880]        \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983, valid_loss=3.880]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.54it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=0.973, valid_loss=3.880]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 393.72it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=4.540]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.966, valid_loss=4.540]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=4.540]        \n",
      "Epoch 604: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.92it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=4.540]\n",
      "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=4.540]        \n",
      "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974, valid_loss=4.540]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=4.540]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.967, valid_loss=4.540]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=4.540]        \n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=4.540]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=4.540]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=4.540]        \n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=4.540]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=0.937, valid_loss=4.540]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=4.540]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956, valid_loss=4.540]        \n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=4.540]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=4.540]        \n",
      "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=4.540]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.956, train_loss_epoch=0.956, valid_loss=4.540]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=4.540]        \n",
      "Epoch 633: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.14it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=4.540]\n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=4.540]        \n",
      "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=4.540]        \n",
      "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=4.540]        \n",
      "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.965, train_loss_epoch=0.965, valid_loss=4.540]        \n",
      "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=4.540]        \n",
      "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.966, train_loss_epoch=0.966, valid_loss=4.540]        \n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.960, train_loss_epoch=0.960, valid_loss=4.540]        \n",
      "Epoch 648: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.82it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=4.540]\n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=4.540]        \n",
      "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.931, train_loss_epoch=0.931, valid_loss=4.540]        \n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.984, train_loss_epoch=0.984, valid_loss=4.540]        \n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.976, train_loss_epoch=0.976, valid_loss=4.540]        \n",
      "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=4.540]        \n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.968, train_loss_epoch=0.968, valid_loss=4.540]        \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.902, train_loss_epoch=0.902, valid_loss=4.540]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=4.540]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.903, train_loss_epoch=0.903, valid_loss=4.540]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905, valid_loss=4.540]        \n",
      "Epoch 667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.42it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.905, valid_loss=4.540]\n",
      "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850, valid_loss=4.540]        \n",
      "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.849, valid_loss=4.540]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.920, train_loss_epoch=0.920, valid_loss=4.540]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=0.899, valid_loss=4.540]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=0.932, valid_loss=4.540]        \n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=0.848, valid_loss=4.540]        \n",
      "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=4.540]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.867, valid_loss=4.540]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=0.876, valid_loss=4.540]        \n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.865, train_loss_epoch=0.865, valid_loss=4.540]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=4.540]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=0.847, valid_loss=4.540]        \n",
      "Epoch 693: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.71it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.836, valid_loss=4.540]\n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.836, valid_loss=4.540]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=4.540]        \n",
      "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.830, valid_loss=4.540]        \n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=4.540]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.71it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=0.839, valid_loss=4.540]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 383.46it/s]\u001b[A\n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=0.885, valid_loss=4.460]        \n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.870, train_loss_epoch=0.870, valid_loss=4.460]        \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850, valid_loss=4.460]        \n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=4.460]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=0.879, valid_loss=4.460]        \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=4.460]        \n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.790, train_loss_epoch=0.790, valid_loss=4.460]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=4.460]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.875, train_loss_epoch=0.875, valid_loss=4.460]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=4.460]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=4.460]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.879, train_loss_epoch=0.879, valid_loss=4.460]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.853, train_loss_epoch=0.853, valid_loss=4.460]        \n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.877, train_loss_epoch=0.877, valid_loss=4.460]        \n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=4.460]        \n",
      "Epoch 729: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.45it/s, v_num=0, train_loss_step=0.840, train_loss_epoch=0.840, valid_loss=4.460]\n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.840, train_loss_epoch=0.840, valid_loss=4.460]        \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.839, train_loss_epoch=0.839, valid_loss=4.460]        \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.832, train_loss_epoch=0.832, valid_loss=4.460]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.835, train_loss_epoch=0.835, valid_loss=4.460]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=0.847, valid_loss=4.460]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.833, train_loss_epoch=0.833, valid_loss=4.460]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.800, train_loss_epoch=0.800, valid_loss=4.460]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.814, train_loss_epoch=0.814, valid_loss=4.460]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.790, train_loss_epoch=0.790, valid_loss=4.460]        \n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.849, valid_loss=4.460]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.844, train_loss_epoch=0.844, valid_loss=4.460]        \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.825, train_loss_epoch=0.825, valid_loss=4.460]        \n",
      "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.891, train_loss_epoch=0.891, valid_loss=4.460]        \n",
      "Epoch 750: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.06it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=0.891, valid_loss=4.460]\n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=0.846, valid_loss=4.460]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.830, valid_loss=4.460]        \n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=4.460]        \n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=4.460]        \n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=0.847, valid_loss=4.460]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893, valid_loss=4.460]        \n",
      "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.868, train_loss_epoch=0.868, valid_loss=4.460]        \n",
      "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.878, train_loss_epoch=0.878, valid_loss=4.460]        \n",
      "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.816, train_loss_epoch=0.816, valid_loss=4.460]        \n",
      "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=4.460]        \n",
      "Epoch 769: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.96it/s, v_num=0, train_loss_step=0.792, train_loss_epoch=0.792, valid_loss=4.460]\n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.792, train_loss_epoch=0.792, valid_loss=4.460]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893, valid_loss=4.460]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.840, train_loss_epoch=0.840, valid_loss=4.460]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=4.460]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=4.460]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=4.460]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.832, train_loss_epoch=0.832, valid_loss=4.460]        \n",
      "Epoch 782: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.75it/s, v_num=0, train_loss_step=0.832, train_loss_epoch=0.832, valid_loss=4.460]\n",
      "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817, valid_loss=4.460]        \n",
      "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=0.803, valid_loss=4.460]        \n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.814, train_loss_epoch=0.814, valid_loss=4.460]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.820, train_loss_epoch=0.820, valid_loss=4.460]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854, valid_loss=4.460]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=0.847, valid_loss=4.460]        \n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.853, train_loss_epoch=0.853, valid_loss=4.460]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=4.460]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=4.460]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.12it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=0.803, valid_loss=4.460]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 372.76it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=0.819, valid_loss=4.570]        \n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.839, train_loss_epoch=0.839, valid_loss=4.570]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=0.803, valid_loss=4.570]        \n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=0.827, valid_loss=4.570]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.798, train_loss_epoch=0.798, valid_loss=4.570]        \n",
      "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.839, train_loss_epoch=0.839, valid_loss=4.570]        \n",
      "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817, valid_loss=4.570]        \n",
      "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.829, train_loss_epoch=0.829, valid_loss=4.570]        \n",
      "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.773, train_loss_epoch=0.773, valid_loss=4.570]        \n",
      "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.793, train_loss_epoch=0.793, valid_loss=4.570]        \n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.826, train_loss_epoch=0.826, valid_loss=4.570]        \n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.853, train_loss_epoch=0.853, valid_loss=4.570]        \n",
      "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=4.570]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.814, train_loss_epoch=0.814, valid_loss=4.570]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.782, train_loss_epoch=0.782, valid_loss=4.570]        \n",
      "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.844, train_loss_epoch=0.844, valid_loss=4.570]        \n",
      "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.825, train_loss_epoch=0.825, valid_loss=4.570]        \n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796, valid_loss=4.570]        \n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.830, train_loss_epoch=0.830, valid_loss=4.570]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.798, train_loss_epoch=0.798, valid_loss=4.570]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.846, train_loss_epoch=0.846, valid_loss=4.570]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=4.570]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.840, train_loss_epoch=0.840, valid_loss=4.570]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.844, train_loss_epoch=0.844, valid_loss=4.570]        \n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.767, train_loss_epoch=0.767, valid_loss=4.570]        \n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.833, train_loss_epoch=0.833, valid_loss=4.570]        \n",
      "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.833, train_loss_epoch=0.833, valid_loss=4.570]        \n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=0.803, valid_loss=4.570]        \n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=4.570]        \n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.802, train_loss_epoch=0.802, valid_loss=4.570]        \n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806, valid_loss=4.570]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.802, train_loss_epoch=0.802, valid_loss=4.570]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=4.570]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=4.570]        \n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.823, train_loss_epoch=0.823, valid_loss=4.570]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=4.570]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.827, train_loss_epoch=0.827, valid_loss=4.570]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=0.822, valid_loss=4.570]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796, valid_loss=4.570]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.570]        \n",
      "Epoch 875: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.84it/s, v_num=0, train_loss_step=0.794, train_loss_epoch=0.809, valid_loss=4.570]\n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.794, train_loss_epoch=0.794, valid_loss=4.570]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.570]        \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=4.570]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=4.570]        \n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=4.570]        \n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.849, valid_loss=4.570]        \n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.786, train_loss_epoch=0.786, valid_loss=4.570]        \n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.745, train_loss_epoch=0.745, valid_loss=4.570]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.766, valid_loss=4.570]        \n",
      "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.783, valid_loss=4.570]        \n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.777, train_loss_epoch=0.777, valid_loss=4.570]        \n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.777, train_loss_epoch=0.777, valid_loss=4.570]\n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=4.570]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.777, train_loss_epoch=0.777, valid_loss=4.570]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.70it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.777, valid_loss=4.570]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 365.48it/s]\u001b[A\n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.832, train_loss_epoch=0.832, valid_loss=4.890]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850, valid_loss=4.890]        \n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=0.758, valid_loss=4.890]        \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=4.890]        \n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.768, train_loss_epoch=0.768, valid_loss=4.890]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.800, train_loss_epoch=0.800, valid_loss=4.890]        \n",
      "Epoch 913: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.56it/s, v_num=0, train_loss_step=0.802, train_loss_epoch=0.802, valid_loss=4.890]\n",
      "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.802, train_loss_epoch=0.802, valid_loss=4.890]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=0.761, valid_loss=4.890]        \n",
      "Epoch 915: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.63it/s, v_num=0, train_loss_step=0.787, train_loss_epoch=0.761, valid_loss=4.890]\n",
      "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.787, train_loss_epoch=0.787, valid_loss=4.890]        \n",
      "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.743, train_loss_epoch=0.743, valid_loss=4.890]        \n",
      "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806, valid_loss=4.890]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.774, train_loss_epoch=0.774, valid_loss=4.890]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.799, train_loss_epoch=0.799, valid_loss=4.890]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=4.890]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.788, train_loss_epoch=0.788, valid_loss=4.890]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.792, train_loss_epoch=0.792, valid_loss=4.890]        \n",
      "Epoch 931: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.49it/s, v_num=0, train_loss_step=0.768, train_loss_epoch=0.768, valid_loss=4.890]\n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.768, train_loss_epoch=0.768, valid_loss=4.890]        \n",
      "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=0.801, valid_loss=4.890]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=4.890]        \n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=4.890]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.786, train_loss_epoch=0.786, valid_loss=4.890]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=4.890]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=4.890]        \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.823, train_loss_epoch=0.823, valid_loss=4.890]        \n",
      "Epoch 946: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.97it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.823, valid_loss=4.890]\n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746, valid_loss=4.890]        \n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=4.890]        \n",
      "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.803, train_loss_epoch=0.803, valid_loss=4.890]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.756, train_loss_epoch=0.756, valid_loss=4.890]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.819, train_loss_epoch=0.819, valid_loss=4.890]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.792, train_loss_epoch=0.792, valid_loss=4.890]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.812, train_loss_epoch=0.812, valid_loss=4.890]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.771, train_loss_epoch=0.771, valid_loss=4.890]        \n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.771, train_loss_epoch=0.771, valid_loss=4.890]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.757, train_loss_epoch=0.757, valid_loss=4.890]        \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.763, train_loss_epoch=0.763, valid_loss=4.890]        \n",
      "Epoch 966: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11.32it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.795, valid_loss=4.890]\n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=4.890]        \n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=0.758, valid_loss=4.890]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806, valid_loss=4.890]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.755, train_loss_epoch=0.755, valid_loss=4.890]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=4.890]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776, valid_loss=4.890]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.763, train_loss_epoch=0.763, valid_loss=4.890]        \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.784, train_loss_epoch=0.784, valid_loss=4.890]        \n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.778, train_loss_epoch=0.778, valid_loss=4.890]        \n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.764, train_loss_epoch=0.764, valid_loss=4.890]        \n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.760, train_loss_epoch=0.760, valid_loss=4.890]        \n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.798, train_loss_epoch=0.798, valid_loss=4.890]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.778, train_loss_epoch=0.778, valid_loss=4.890]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741, valid_loss=4.890]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.790, train_loss_epoch=0.790, valid_loss=4.890]        \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.787, train_loss_epoch=0.787, valid_loss=4.890]        \n",
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=4.890]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.63it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=0.754, valid_loss=4.890]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 349.03it/s]\u001b[A\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.75it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=0.748, valid_loss=4.950]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=50786)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=50786)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[36m(_train_tune pid=51279)\u001b[0m Seed set to 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=216.0, train_loss_epoch=216.0]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340]        \n",
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.59it/s, v_num=0, train_loss_step=4.870, train_loss_epoch=4.870]\n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.700, train_loss_epoch=3.700]       \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660]        \n",
      "Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.74it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370]\n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050]        \n",
      "Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.47it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050]\n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970]        \n",
      "Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.84it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840]\n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750]        \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]        \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]        \n",
      "Epoch 67: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.56it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780]\n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780]        \n",
      "Epoch 69: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.95it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800]\n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830]        \n",
      "Epoch 76: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.62it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800]\n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690]        \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720]        \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.88it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.780]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 405.17it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=51279)\u001b[0m \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.55it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.780, valid_loss=0.353]\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.353]       \n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.353]        \n",
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.353]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.353]        \n",
      "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.353]        \n",
      "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.353]        \n",
      "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.353]        \n",
      "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.353]        \n",
      "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.353]\n",
      "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.353]        \n",
      "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.353]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.353]        \n",
      "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.353]        \n",
      "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.353]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.353]        \n",
      "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.353]        \n",
      "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.353]        \n",
      "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.353]        \n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.353]        \n",
      "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.353]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.353]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.353]        \n",
      "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.353]        \n",
      "Epoch 143: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.48it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.353]\n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.353]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.353]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.353]        \n",
      "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.353]        \n",
      "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=0.353]        \n",
      "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=0.353]        \n",
      "Epoch 156: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.70it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=0.353]\n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=0.353]        \n",
      "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=0.353]        \n",
      "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=0.353]        \n",
      "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=0.353]        \n",
      "Epoch 165: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.59it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.353]\n",
      "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.353]        \n",
      "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=0.353]        \n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=0.353]        \n",
      "Epoch 172: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.56it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=0.353]\n",
      "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=0.353]        \n",
      "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=0.353]        \n",
      "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=0.353]        \n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=0.353]        \n",
      "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=0.353]        \n",
      "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=0.353]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=0.353]        \n",
      "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=0.353]        \n",
      "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270, valid_loss=0.353]        \n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=0.353]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=0.353]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.353]        \n",
      "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=0.353]        \n",
      "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.353]        \n",
      "Epoch 197: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.21it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.353]\n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.353]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 24.76it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.220, valid_loss=0.353]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 420.31it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.347]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.347]        \n",
      "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.347]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.347]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.347]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.347]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.347]        \n",
      "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.347]        \n",
      "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.347]        \n",
      "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.347]        \n",
      "Epoch 219: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.58it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.347]\n",
      "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.347]        \n",
      "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.347]        \n",
      "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.347]        \n",
      "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.347]        \n",
      "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.347]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.347]        \n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.347]        \n",
      "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.347]        \n",
      "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=0.347]        \n",
      "Epoch 237: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.37it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.347]\n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.347]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.347]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.347]        \n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.347]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.347]        \n",
      "Epoch 249: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 24.01it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.347]\n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.347]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.347]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.347]        \n",
      "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.347]        \n",
      "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.347]        \n",
      "Epoch 261: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.74it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.347]\n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.347]        \n",
      "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.347]        \n",
      "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=0.963, valid_loss=0.347]        \n",
      "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=0.937, valid_loss=0.347]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.347]        \n",
      "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.979, train_loss_epoch=0.979, valid_loss=0.347]        \n",
      "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.974, train_loss_epoch=0.974, valid_loss=0.347]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.969, train_loss_epoch=0.969, valid_loss=0.347]        \n",
      "Epoch 279: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.11it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.347]\n",
      "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.961, train_loss_epoch=0.961, valid_loss=0.347]        \n",
      "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=0.347]        \n",
      "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=0.918, valid_loss=0.347]        \n",
      "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.347]        \n",
      "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=0.918, valid_loss=0.347]        \n",
      "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951, valid_loss=0.347]        \n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.849, train_loss_epoch=0.849, valid_loss=0.347]        \n",
      "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861, valid_loss=0.347]        \n",
      "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=0.347]        \n",
      "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=0.921, valid_loss=0.347]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.17it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=0.864, valid_loss=0.347]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 400.64it/s]\u001b[A\n",
      "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.848, train_loss_epoch=0.848, valid_loss=0.612]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.874, train_loss_epoch=0.874, valid_loss=0.612]        \n",
      "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.867, valid_loss=0.612]        \n",
      "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.884, train_loss_epoch=0.884, valid_loss=0.612]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860, valid_loss=0.612]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=0.612]        \n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.612]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.855, train_loss_epoch=0.855, valid_loss=0.612]        \n",
      "Epoch 315: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.23it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.855, valid_loss=0.612]\n",
      "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861, valid_loss=0.612]        \n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=0.612]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.804, train_loss_epoch=0.804, valid_loss=0.612]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=0.612]        \n",
      "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.818, train_loss_epoch=0.818, valid_loss=0.612]        \n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.811, train_loss_epoch=0.811, valid_loss=0.612]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.836, train_loss_epoch=0.836, valid_loss=0.612]        \n",
      "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=0.612]        \n",
      "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=0.758, valid_loss=0.612]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.722, train_loss_epoch=0.722, valid_loss=0.612]        \n",
      "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.722, train_loss_epoch=0.722, valid_loss=0.612]        \n",
      "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=0.612]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=0.612]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=0.612]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=0.612]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=0.612]        \n",
      "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=0.612]        \n",
      "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.654, train_loss_epoch=0.654, valid_loss=0.612]        \n",
      "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649, valid_loss=0.612]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.612]        \n",
      "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.612]        \n",
      "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.612, train_loss_epoch=0.612, valid_loss=0.612]        \n",
      "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.612]        \n",
      "Epoch 364: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.92it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.612]\n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.612]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.612]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.612]        \n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=0.612]        \n",
      "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=0.612]        \n",
      "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=0.612]        \n",
      "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.612]        \n",
      "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.612]        \n",
      "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.612]        \n",
      "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.612]        \n",
      "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.612]        \n",
      "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=0.612]        \n",
      "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=0.612]        \n",
      "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=0.612]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=0.612]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.612]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.612]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.25it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.578, valid_loss=0.612]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 377.70it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=0.450]        \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.450]        \n",
      "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.450]        \n",
      "Epoch 406: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.43it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.511, valid_loss=0.450]\n",
      "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=0.450]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.450]        \n",
      "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.450]        \n",
      "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.450]        \n",
      "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.534, train_loss_epoch=0.534, valid_loss=0.450]        \n",
      "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.450]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.450]        \n",
      "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=0.450]        \n",
      "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.450]        \n",
      "Epoch 425: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 12.99it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.450]\n",
      "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.450]        \n",
      "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=0.450]        \n",
      "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=0.450]        \n",
      "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=0.450]        \n",
      "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.450]        \n",
      "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.450]        \n",
      "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482, valid_loss=0.450]        \n",
      "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.450]        \n",
      "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.450]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=0.450]        \n",
      "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.450]        \n",
      "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.450]        \n",
      "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.450]        \n",
      "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.450]        \n",
      "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.450]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.450]        \n",
      "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.450]        \n",
      "Epoch 462: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.78it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.450]\n",
      "Epoch 462: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.62it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.481, valid_loss=0.450]\n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.450]        \n",
      "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.450]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.450]        \n",
      "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.450]        \n",
      "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.450]        \n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.450]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457, valid_loss=0.450]        \n",
      "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.450]        \n",
      "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459, valid_loss=0.450]        \n",
      "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.467, train_loss_epoch=0.467, valid_loss=0.450]        \n",
      "Epoch 482: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.56it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.450]\n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.450]        \n",
      "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.450]        \n",
      "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.450]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.450]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.450]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=0.450]        \n",
      "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.485, train_loss_epoch=0.485, valid_loss=0.450]        \n",
      "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.450]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.92it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.449, valid_loss=0.450]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 394.50it/s]\u001b[A\n",
      "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.638]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.638]        \n",
      "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.638]        \n",
      "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.638]        \n",
      "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.465, train_loss_epoch=0.465, valid_loss=0.638]        \n",
      "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429, valid_loss=0.638]        \n",
      "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.638]        \n",
      "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.638]        \n",
      "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.638]        \n",
      "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.638]        \n",
      "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.638]        \n",
      "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.638]        \n",
      "Epoch 524: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.77it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=0.638]\n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431, valid_loss=0.638]        \n",
      "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.638]        \n",
      "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417, valid_loss=0.638]        \n",
      "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.638]        \n",
      "Epoch 531: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.55it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.638]\n",
      "Epoch 531: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.44it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.396, valid_loss=0.638]\n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.638]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.638]        \n",
      "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.638]        \n",
      "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=0.638]        \n",
      "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.638]        \n",
      "Epoch 540: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.05it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.422, valid_loss=0.638]\n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406, valid_loss=0.638]        \n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.638]        \n",
      "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.638]        \n",
      "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.638]        \n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.638]        \n",
      "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=0.638]        \n",
      "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.638]        \n",
      "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.638]        \n",
      "Epoch 553: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.58it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.638]\n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.638]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.638]        \n",
      "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.638]        \n",
      "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.638]        \n",
      "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.391, valid_loss=0.638]        \n",
      "Epoch 564: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.24it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.418, valid_loss=0.638]\n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.638]        \n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=0.638]        \n",
      "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.638]        \n",
      "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=0.638]        \n",
      "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.638]        \n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.638]        \n",
      "Epoch 577: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.98it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.409, valid_loss=0.638]\n",
      "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417, valid_loss=0.638]        \n",
      "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.638]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.638]        \n",
      "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=0.638]        \n",
      "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=0.638]        \n",
      "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.638]        \n",
      "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.638]        \n",
      "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.638]        \n",
      "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.638]        \n",
      "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.638]        \n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.638]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.07it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.397, valid_loss=0.638]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 384.16it/s]\u001b[A\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.856]        \n",
      "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.856]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.856]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.856]        \n",
      "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.856]        \n",
      "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=0.856]        \n",
      "Epoch 610: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.67it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=0.856]\n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=0.856]        \n",
      "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.856]        \n",
      "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.856]        \n",
      "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.856]        \n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.856]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.856]        \n",
      "Epoch 623: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 23.06it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.856]\n",
      "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.856]        \n",
      "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.856]        \n",
      "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.856]        \n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409, valid_loss=0.856]        \n",
      "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=0.856]        \n",
      "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.856]        \n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=0.856]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.856]        \n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=0.856]        \n",
      "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.391, valid_loss=0.856]        \n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=0.856]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.856]        \n",
      "Epoch 645: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.48it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.370, valid_loss=0.856]\n",
      "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=0.856]        \n",
      "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=0.856]        \n",
      "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=0.856]        \n",
      "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=0.856]        \n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=0.856]        \n",
      "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=0.856]        \n",
      "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=0.856]        \n",
      "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=0.856]        \n",
      "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=0.856]        \n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=0.856]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=0.856]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=0.856]        \n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.856]        \n",
      "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=0.856]        \n",
      "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.856]        \n",
      "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=0.856]        \n",
      "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=0.856]        \n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.856]        \n",
      "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.856]        \n",
      "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.856]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=0.856]        \n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=0.856]        \n",
      "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=0.856]        \n",
      "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=0.856]        \n",
      "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=0.856]        \n",
      "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=0.856]        \n",
      "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.856]        \n",
      "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.856]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.57it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.326, valid_loss=0.856]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 397.45it/s]\u001b[A\n",
      "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=0.651]        \n",
      "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=0.651]        \n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=0.651]        \n",
      "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=0.651]        \n",
      "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.651]        \n",
      "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=0.651]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=0.651]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.651]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.651]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=0.651]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=0.651]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=0.651]        \n",
      "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=0.651]        \n",
      "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=0.651]        \n",
      "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.651]        \n",
      "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.651]        \n",
      "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=0.651]        \n",
      "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=0.651]        \n",
      "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=0.651]        \n",
      "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.651]        \n",
      "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=0.651]        \n",
      "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.651]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=0.651]        \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.651]        \n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=0.651]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.651]        \n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.651]        \n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=0.651]        \n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.651]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=0.651]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.651]        \n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.651]        \n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.651]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.651]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=0.651]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=0.651]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.651]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.651]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=0.651]        \n",
      "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.651]        \n",
      "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.651]        \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=0.651]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=0.651]        \n",
      "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.651]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=0.651]        \n",
      "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.651]        \n",
      "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.651]        \n",
      "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=0.651]        \n",
      "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.651]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.10it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.298, valid_loss=0.651]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 329.59it/s]\u001b[A\n",
      "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=0.669]        \n",
      "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.669]        \n",
      "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.669]        \n",
      "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=0.669]        \n",
      "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.669]        \n",
      "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.669]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.669]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.669]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.669]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=0.669]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.669]        \n",
      "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=0.669]        \n",
      "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.669]        \n",
      "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.669]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=0.669]        \n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=0.669]        \n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.669]        \n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.669]        \n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=0.669]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.669]        \n",
      "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=0.669]        \n",
      "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.669]        \n",
      "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.669]        \n",
      "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.669]        \n",
      "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.669]        \n",
      "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.669]        \n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=0.669]        \n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.669]        \n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=0.669]        \n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.669]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.669]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.669]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.669]        \n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.669]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.669]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.669]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=0.669]        \n",
      "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=0.669]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.669]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=0.669]        \n",
      "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=0.669]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.669]        \n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.669]        \n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.669]        \n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=0.669]        \n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.669]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.669]        \n",
      "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=0.669]        \n",
      "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.669]        \n",
      "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.669]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.51it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.322, valid_loss=0.669]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 385.33it/s]\u001b[A\n",
      "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.635]        \n",
      "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=0.635]        \n",
      "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=0.635]        \n",
      "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.635]        \n",
      "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.635]        \n",
      "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.635]        \n",
      "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.635]        \n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=0.635]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.635]        \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.635]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.635]        \n",
      "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.635]        \n",
      "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.635]        \n",
      "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.635]        \n",
      "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.635]        \n",
      "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=0.635]        \n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.635]        \n",
      "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.635]        \n",
      "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=0.635]        \n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=0.635]        \n",
      "Epoch 937: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.54it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.315, valid_loss=0.635]\n",
      "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.635]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.635]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=0.635]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=0.635]        \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=0.635]        \n",
      "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.635]        \n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=0.635]        \n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=0.635]        \n",
      "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.635]        \n",
      "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.635]        \n",
      "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.635]        \n",
      "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.635]        \n",
      "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=0.635]        \n",
      "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=0.635]        \n",
      "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.635]        \n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=0.635]        \n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.635]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.635]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.635]        \n",
      "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.635]        \n",
      "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.635]        \n",
      "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.635]        \n",
      "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.635]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.635]        \n",
      "Epoch 983: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.42it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.635]\n",
      "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.635]        \n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.635]\n",
      "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=0.635]        \n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.635]        \n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=0.635]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.635]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.635]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=0.635]        \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.635]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.27it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.296, valid_loss=0.635]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 387.29it/s]\u001b[A\n",
      "\u001b[36m(_train_tune pid=51279)\u001b[0m \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.03it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.296, valid_loss=0.595]\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.40it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=0.595]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=51279)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=51279)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[36m(_train_tune pid=51770)\u001b[0m Seed set to 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.180, train_loss_epoch=7.180]        \n",
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.79it/s, v_num=0, train_loss_step=4.630, train_loss_epoch=7.180]\n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.630, train_loss_epoch=4.630]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.830, train_loss_epoch=3.830]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090]        \n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.370, train_loss_epoch=3.370]       \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.060, train_loss_epoch=3.060]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940]        \n",
      "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110]        \n",
      "Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.02it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.210]\n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020]        \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890]        \n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860]        \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590]        \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.98it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.700]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 401.64it/s]\u001b[A\n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.617]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.617]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.617]        \n",
      "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.617]        \n",
      "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.617]        \n",
      "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.617]        \n",
      "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.617]        \n",
      "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.617]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.617]        \n",
      "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.617]        \n",
      "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.617]\n",
      "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.617]        \n",
      "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.617]        \n",
      "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.617]        \n",
      "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.617]        \n",
      "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.617]        \n",
      "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.617]        \n",
      "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.617]        \n",
      "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.617]        \n",
      "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.617]        \n",
      "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.617]        \n",
      "Epoch 143: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.95it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.290, valid_loss=0.617]\n",
      "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.617]        \n",
      "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.617]        \n",
      "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.617]        \n",
      "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.617]        \n",
      "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.617]        \n",
      "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.617]        \n",
      "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.617]        \n",
      "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.617]        \n",
      "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.617]        \n",
      "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.617]        \n",
      "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.617]        \n",
      "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.617]        \n",
      "Epoch 169: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.81it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=0.617]\n",
      "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.617]        \n",
      "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.617]        \n",
      "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.617]        \n",
      "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.617]        \n",
      "Epoch 178: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 24.92it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=2.060, valid_loss=0.617]\n",
      "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.617]        \n",
      "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=0.617]        \n",
      "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.617]        \n",
      "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.617]        \n",
      "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.617]        \n",
      "Epoch 188: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.85it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.910, valid_loss=0.617]\n",
      "Epoch 188: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.40it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.617]\n",
      "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.617]        \n",
      "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.617]        \n",
      "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.617]        \n",
      "Epoch 195: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.52it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.850, valid_loss=0.617]\n",
      "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.617]        \n",
      "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.617]        \n",
      "Epoch 199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.19it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.650, valid_loss=0.617]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 374.96it/s]\u001b[A\n",
      "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=1.990]        \n",
      "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=1.990]        \n",
      "Epoch 202: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.34it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=1.990]\n",
      "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=1.990]        \n",
      "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=1.990]        \n",
      "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=1.990]        \n",
      "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=1.990]        \n",
      "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=1.990]        \n",
      "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=1.990]        \n",
      "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=1.990]        \n",
      "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=1.990]        \n",
      "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=1.990]        \n",
      "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=1.990]        \n",
      "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=1.990]        \n",
      "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=1.990]        \n",
      "Epoch 225: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.70it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=1.990]\n",
      "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=1.990]        \n",
      "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=1.990]        \n",
      "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=1.990]        \n",
      "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=1.990]\n",
      "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=1.990]        \n",
      "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=1.990]        \n",
      "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=1.990]        \n",
      "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=1.990]        \n",
      "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=1.990]        \n",
      "Epoch 244: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.06it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=1.990]\n",
      "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=1.990]        \n",
      "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=1.990]        \n",
      "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=1.990]        \n",
      "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=1.990]        \n",
      "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=1.990]        \n",
      "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=1.990]        \n",
      "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=1.990]        \n",
      "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=1.990]        \n",
      "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=1.990]        \n",
      "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=1.990]        \n",
      "Epoch 262: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.42it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=1.990]\n",
      "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=1.990]        \n",
      "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=1.990]        \n",
      "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=1.990]        \n",
      "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=1.990]        \n",
      "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=1.990]        \n",
      "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=1.990]        \n",
      "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=1.990]        \n",
      "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=1.990]        \n",
      "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=1.990]        \n",
      "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=1.990]        \n",
      "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=1.990]        \n",
      "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=1.990]        \n",
      "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=1.990]        \n",
      "Epoch 292: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.33it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=1.990]\n",
      "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=1.990]        \n",
      "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=1.990]        \n",
      "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=1.990]        \n",
      "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=1.990]        \n",
      "Epoch 299: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.40it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.170, valid_loss=1.990]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 369.15it/s]\u001b[A\n",
      "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=1.140]        \n",
      "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=1.140]        \n",
      "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=1.140]        \n",
      "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=1.140]        \n",
      "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=1.140]        \n",
      "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=1.140]        \n",
      "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.140]        \n",
      "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=1.140]        \n",
      "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=1.140]        \n",
      "Epoch 317: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.75it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.140]\n",
      "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.140]        \n",
      "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=1.140]        \n",
      "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=1.140]        \n",
      "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=1.140]        \n",
      "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=1.140]        \n",
      "Epoch 326: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.49it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.040, valid_loss=1.140]\n",
      "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=1.140]        \n",
      "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=1.140]        \n",
      "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100, valid_loss=1.140]        \n",
      "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=1.140]        \n",
      "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=1.140]        \n",
      "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=1.140]        \n",
      "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=1.140]        \n",
      "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=1.140]        \n",
      "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.891, train_loss_epoch=0.891, valid_loss=1.140]        \n",
      "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.893, train_loss_epoch=0.893, valid_loss=1.140]        \n",
      "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.882, train_loss_epoch=0.882, valid_loss=1.140]        \n",
      "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.839, train_loss_epoch=0.839, valid_loss=1.140]        \n",
      "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.826, train_loss_epoch=0.826, valid_loss=1.140]        \n",
      "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=0.847, valid_loss=1.140]        \n",
      "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.789, train_loss_epoch=0.789, valid_loss=1.140]        \n",
      "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=1.140]        \n",
      "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.814, train_loss_epoch=0.814, valid_loss=1.140]        \n",
      "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=1.140]        \n",
      "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.774, train_loss_epoch=0.774, valid_loss=1.140]        \n",
      "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.782, train_loss_epoch=0.782, valid_loss=1.140]        \n",
      "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.766, valid_loss=1.140]        \n",
      "Epoch 370: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.41it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.824, valid_loss=1.140]\n",
      "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.824, train_loss_epoch=0.824, valid_loss=1.140]        \n",
      "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.762, train_loss_epoch=0.762, valid_loss=1.140]        \n",
      "Epoch 374: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.21it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.805, valid_loss=1.140]\n",
      "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=1.140]        \n",
      "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=0.758, valid_loss=1.140]        \n",
      "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759, valid_loss=1.140]        \n",
      "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.770, train_loss_epoch=0.770, valid_loss=1.140]        \n",
      "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776, valid_loss=1.140]        \n",
      "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.725, train_loss_epoch=0.725, valid_loss=1.140]        \n",
      "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.749, valid_loss=1.140]        \n",
      "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.749, train_loss_epoch=0.749, valid_loss=1.140]        \n",
      "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.738, train_loss_epoch=0.738, valid_loss=1.140]        \n",
      "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.755, train_loss_epoch=0.755, valid_loss=1.140]        \n",
      "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.698, valid_loss=1.140]        \n",
      "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.733, train_loss_epoch=0.733, valid_loss=1.140]        \n",
      "Epoch 399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.08it/s, v_num=0, train_loss_step=0.735, train_loss_epoch=0.739, valid_loss=1.140]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 383.32it/s]\u001b[A\n",
      "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.735, train_loss_epoch=0.735, valid_loss=1.710]        \n",
      "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.719, train_loss_epoch=0.719, valid_loss=1.710]        \n",
      "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.714, train_loss_epoch=0.714, valid_loss=1.710]        \n",
      "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.743, train_loss_epoch=0.743, valid_loss=1.710]        \n",
      "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=1.710]        \n",
      "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=1.710]        \n",
      "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=1.710]        \n",
      "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.679, train_loss_epoch=0.679, valid_loss=1.710]        \n",
      "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=1.710]        \n",
      "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.676, train_loss_epoch=0.676, valid_loss=1.710]        \n",
      "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.713, train_loss_epoch=0.713, valid_loss=1.710]        \n",
      "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.712, valid_loss=1.710]        \n",
      "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=1.710]        \n",
      "Epoch 424: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.66it/s, v_num=0, train_loss_step=0.744, train_loss_epoch=0.744, valid_loss=1.710]\n",
      "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.744, train_loss_epoch=0.744, valid_loss=1.710]        \n",
      "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.710, train_loss_epoch=0.710, valid_loss=1.710]        \n",
      "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.712, valid_loss=1.710]        \n",
      "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704, valid_loss=1.710]        \n",
      "Epoch 433: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.55it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.706, valid_loss=1.710]\n",
      "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.718, train_loss_epoch=0.718, valid_loss=1.710]        \n",
      "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=1.710]        \n",
      "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.717, train_loss_epoch=0.717, valid_loss=1.710]        \n",
      "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=1.710]        \n",
      "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=1.710]        \n",
      "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=1.710]        \n",
      "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670, valid_loss=1.710]        \n",
      "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.709, train_loss_epoch=0.709, valid_loss=1.710]        \n",
      "Epoch 451: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.51it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=1.710]\n",
      "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=1.710]        \n",
      "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660, valid_loss=1.710]        \n",
      "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=1.710]        \n",
      "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.729, train_loss_epoch=0.729, valid_loss=1.710]        \n",
      "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=1.710]        \n",
      "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.697, train_loss_epoch=0.697, valid_loss=1.710]        \n",
      "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.699, train_loss_epoch=0.699, valid_loss=1.710]        \n",
      "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.648, train_loss_epoch=0.648, valid_loss=1.710]        \n",
      "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661, valid_loss=1.710]        \n",
      "Epoch 470: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.37it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.663, valid_loss=1.710]\n",
      "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=1.710]        \n",
      "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=1.710]        \n",
      "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.655, train_loss_epoch=0.655, valid_loss=1.710]        \n",
      "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=1.710]        \n",
      "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=1.710]        \n",
      "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=1.710]        \n",
      "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.625, train_loss_epoch=0.625, valid_loss=1.710]        \n",
      "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=1.710]        \n",
      "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=1.710]        \n",
      "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=1.710]        \n",
      "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.653, train_loss_epoch=0.653, valid_loss=1.710]        \n",
      "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=1.710]        \n",
      "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.667, train_loss_epoch=0.667, valid_loss=1.710]        \n",
      "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.630, train_loss_epoch=0.630, valid_loss=1.710]        \n",
      "Epoch 499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.73it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.630, valid_loss=1.710]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 380.37it/s]\u001b[A\n",
      "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=2.020]        \n",
      "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.659, train_loss_epoch=0.659, valid_loss=2.020]        \n",
      "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=2.020]        \n",
      "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602, valid_loss=2.020]        \n",
      "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=2.020]        \n",
      "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=2.020]        \n",
      "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=2.020]        \n",
      "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.621, train_loss_epoch=0.621, valid_loss=2.020]        \n",
      "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=2.020]        \n",
      "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.643, train_loss_epoch=0.643, valid_loss=2.020]        \n",
      "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=2.020]        \n",
      "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.612, train_loss_epoch=0.612, valid_loss=2.020]        \n",
      "Epoch 527: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.15it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=2.020]\n",
      "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.629, train_loss_epoch=0.629, valid_loss=2.020]        \n",
      "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=2.020]        \n",
      "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584, valid_loss=2.020]        \n",
      "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632, valid_loss=2.020]        \n",
      "Epoch 536: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.50it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=2.020]\n",
      "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.627, train_loss_epoch=0.627, valid_loss=2.020]        \n",
      "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=2.020]        \n",
      "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.642, train_loss_epoch=0.642, valid_loss=2.020]        \n",
      "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=2.020]        \n",
      "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.599, train_loss_epoch=0.599, valid_loss=2.020]        \n",
      "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.660, train_loss_epoch=0.660, valid_loss=2.020]        \n",
      "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=2.020]        \n",
      "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=2.020]        \n",
      "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.619, train_loss_epoch=0.619, valid_loss=2.020]        \n",
      "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597, valid_loss=2.020]        \n",
      "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.600, train_loss_epoch=0.600, valid_loss=2.020]        \n",
      "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=2.020]        \n",
      "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=2.020]        \n",
      "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=2.020]        \n",
      "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=2.020]        \n",
      "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574, valid_loss=2.020]        \n",
      "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=2.020]        \n",
      "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613, valid_loss=2.020]        \n",
      "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.594, train_loss_epoch=0.594, valid_loss=2.020]        \n",
      "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.622, train_loss_epoch=0.622, valid_loss=2.020]        \n",
      "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=2.020]        \n",
      "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=2.020]        \n",
      "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.623, train_loss_epoch=0.623, valid_loss=2.020]        \n",
      "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.575, train_loss_epoch=0.575, valid_loss=2.020]        \n",
      "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=2.020]        \n",
      "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.634, train_loss_epoch=0.634, valid_loss=2.020]        \n",
      "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=2.020]        \n",
      "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=2.020]        \n",
      "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=2.020]        \n",
      "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=2.020]        \n",
      "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=2.020]        \n",
      "Epoch 597: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.87it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=2.020]\n",
      "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=2.020]        \n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.69it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.589, valid_loss=2.020]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 392.14it/s]\u001b[A\n",
      "Epoch 599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 14.32it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=1.960]\n",
      "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=1.960]        \n",
      "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=1.960]        \n",
      "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=1.960]        \n",
      "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=1.960]        \n",
      "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=1.960]        \n",
      "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=1.960]        \n",
      "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=1.960]        \n",
      "Epoch 613: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.71it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=1.960]\n",
      "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=1.960]        \n",
      "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.602, train_loss_epoch=0.602, valid_loss=1.960]        \n",
      "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=1.960]        \n",
      "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=1.960]        \n",
      "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=1.960]        \n",
      "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=1.960]        \n",
      "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.581, train_loss_epoch=0.581, valid_loss=1.960]        \n",
      "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.606, train_loss_epoch=0.606, valid_loss=1.960]        \n",
      "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=1.960]        \n",
      "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=1.960]        \n",
      "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=1.960]        \n",
      "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.618, train_loss_epoch=0.618, valid_loss=1.960]        \n",
      "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=1.960]        \n",
      "Epoch 634: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 22.54it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=1.960]\n",
      "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=1.960]        \n",
      "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=1.960]        \n",
      "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.617, train_loss_epoch=0.617, valid_loss=1.960]        \n",
      "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.620, train_loss_epoch=0.620, valid_loss=1.960]        \n",
      "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=1.960]        \n",
      "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.611, train_loss_epoch=0.611, valid_loss=1.960]        \n",
      "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.593, train_loss_epoch=0.593, valid_loss=1.960]        \n",
      "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=1.960]        \n",
      "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=1.960]        \n",
      "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=1.960]        \n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.570, train_loss_epoch=0.570, valid_loss=1.960]        \n",
      "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=1.960]        \n",
      "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=1.960]\n",
      "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=1.960]        \n",
      "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=1.960]        \n",
      "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=1.960]        \n",
      "Epoch 664: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 21.28it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.549, valid_loss=1.960]\n",
      "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=1.960]        \n",
      "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.573, train_loss_epoch=0.573, valid_loss=1.960]        \n",
      "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576, valid_loss=1.960]        \n",
      "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=1.960]        \n",
      "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=1.960]        \n",
      "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=1.960]        \n",
      "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=1.960]        \n",
      "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.585, train_loss_epoch=0.585, valid_loss=1.960]        \n",
      "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=1.960]        \n",
      "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=1.960]        \n",
      "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=1.960]        \n",
      "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.564, train_loss_epoch=0.564, valid_loss=1.960]        \n",
      "Epoch 689: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.34it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.520, valid_loss=1.960]\n",
      "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=1.960]        \n",
      "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=1.960]        \n",
      "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=1.960]        \n",
      "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=1.960]        \n",
      "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=1.960]        \n",
      "Epoch 699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.28it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.533, valid_loss=1.960]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 331.57it/s]\u001b[A\n",
      "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=1.970]        \n",
      "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=1.970]        \n",
      "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=1.970]        \n",
      "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.558, train_loss_epoch=0.558, valid_loss=1.970]        \n",
      "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=1.970]        \n",
      "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=1.970]        \n",
      "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=1.970]        \n",
      "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=1.970]        \n",
      "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=1.970]        \n",
      "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=1.970]        \n",
      "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=1.970]        \n",
      "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=1.970]        \n",
      "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=1.970]        \n",
      "Epoch 725: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.22it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=1.970]\n",
      "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=1.970]        \n",
      "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=1.970]        \n",
      "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=1.970]        \n",
      "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=1.970]        \n",
      "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=1.970]        \n",
      "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=1.970]        \n",
      "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=1.970]        \n",
      "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=1.970]        \n",
      "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=1.970]        \n",
      "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=1.970]        \n",
      "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=1.970]        \n",
      "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=1.970]        \n",
      "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.530, train_loss_epoch=0.530, valid_loss=1.970]        \n",
      "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540, valid_loss=1.970]        \n",
      "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=1.970]        \n",
      "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=1.970]        \n",
      "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=1.970]        \n",
      "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=1.970]        \n",
      "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=1.970]        \n",
      "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=1.970]        \n",
      "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=1.970]        \n",
      "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.554, train_loss_epoch=0.554, valid_loss=1.970]        \n",
      "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=1.970]        \n",
      "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=1.970]        \n",
      "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=1.970]        \n",
      "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=1.970]        \n",
      "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=1.970]        \n",
      "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=1.970]        \n",
      "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=1.970]        \n",
      "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=1.970]        \n",
      "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=1.970]        \n",
      "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=1.970]        \n",
      "Epoch 786: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.34it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.513, valid_loss=1.970]\n",
      "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=1.970]        \n",
      "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=1.970]        \n",
      "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=1.970]        \n",
      "Epoch 790: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.35it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=1.970]\n",
      "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=1.970]        \n",
      "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=1.970]        \n",
      "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=1.970]        \n",
      "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=1.970]        \n",
      "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=1.970]        \n",
      "Epoch 799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.48it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.511, valid_loss=1.970]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 392.03it/s]\u001b[A\n",
      "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=2.020]        \n",
      "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=2.020]        \n",
      "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=2.020]        \n",
      "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=2.020]        \n",
      "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=2.020]        \n",
      "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=2.020]        \n",
      "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=2.020]        \n",
      "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=2.020]        \n",
      "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.537, train_loss_epoch=0.537, valid_loss=2.020]        \n",
      "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.538, train_loss_epoch=0.538, valid_loss=2.020]        \n",
      "Epoch 820: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.96it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.538, valid_loss=2.020]\n",
      "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=2.020]        \n",
      "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544, valid_loss=2.020]        \n",
      "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=2.020]        \n",
      "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=2.020]        \n",
      "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=2.020]        \n",
      "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=2.020]        \n",
      "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=2.020]        \n",
      "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=2.020]        \n",
      "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=2.020]        \n",
      "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=2.020]        \n",
      "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=2.020]        \n",
      "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=2.020]        \n",
      "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=2.020]        \n",
      "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=2.020]        \n",
      "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=2.020]        \n",
      "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=2.020]        \n",
      "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=2.020]        \n",
      "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=2.020]        \n",
      "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=2.020]        \n",
      "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=2.020]        \n",
      "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=2.020]        \n",
      "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=2.020]        \n",
      "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.522, train_loss_epoch=0.522, valid_loss=2.020]        \n",
      "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=2.020]        \n",
      "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=2.020]        \n",
      "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=2.020]        \n",
      "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.541, train_loss_epoch=0.541, valid_loss=2.020]        \n",
      "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=2.020]        \n",
      "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548, valid_loss=2.020]        \n",
      "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.532, train_loss_epoch=0.532, valid_loss=2.020]        \n",
      "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=2.020]        \n",
      "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=2.020]        \n",
      "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=2.020]        \n",
      "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.559, train_loss_epoch=0.559, valid_loss=2.020]        \n",
      "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=2.020]        \n",
      "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=2.020]        \n",
      "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=2.020]        \n",
      "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=2.020]        \n",
      "Epoch 894: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 18.85it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=2.020]\n",
      "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=2.020]        \n",
      "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=2.020]        \n",
      "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=2.020]        \n",
      "Epoch 899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.66it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.516, valid_loss=2.020]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 381.23it/s]\u001b[A\n",
      "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=2.040]        \n",
      "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=2.040]        \n",
      "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=2.040]        \n",
      "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=2.040]        \n",
      "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=2.040]        \n",
      "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=2.040]        \n",
      "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=2.040]        \n",
      "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.507, train_loss_epoch=0.507, valid_loss=2.040]        \n",
      "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=2.040]        \n",
      "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.533, train_loss_epoch=0.533, valid_loss=2.040]        \n",
      "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=2.040]        \n",
      "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=2.040]        \n",
      "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=2.040]        \n",
      "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=2.040]        \n",
      "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=2.040]        \n",
      "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=2.040]        \n",
      "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=2.040]        \n",
      "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=2.040]        \n",
      "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=2.040]        \n",
      "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.510, train_loss_epoch=0.510, valid_loss=2.040]        \n",
      "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=2.040]        \n",
      "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=2.040]        \n",
      "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=2.040]        \n",
      "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.539, train_loss_epoch=0.539, valid_loss=2.040]        \n",
      "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=2.040]        \n",
      "Epoch 948: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.30it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=2.040]\n",
      "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=2.040]        \n",
      "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=2.040]        \n",
      "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.511, train_loss_epoch=0.511, valid_loss=2.040]        \n",
      "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=2.040]        \n",
      "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=2.040]        \n",
      "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.516, train_loss_epoch=0.516, valid_loss=2.040]        \n",
      "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=2.040]        \n",
      "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=2.040]        \n",
      "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=2.040]        \n",
      "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=2.040]        \n",
      "Epoch 966: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.71it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=2.040]\n",
      "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.542, train_loss_epoch=0.542, valid_loss=2.040]        \n",
      "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=2.040]        \n",
      "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.523, train_loss_epoch=0.523, valid_loss=2.040]        \n",
      "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=2.040]        \n",
      "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=2.040]        \n",
      "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=2.040]        \n",
      "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=2.040]        \n",
      "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531, valid_loss=2.040]        \n",
      "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.543, train_loss_epoch=0.543, valid_loss=2.040]        \n",
      "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=2.040]        \n",
      "Epoch 983: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 16.11it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=2.040]\n",
      "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.545, train_loss_epoch=0.545, valid_loss=2.040]        \n",
      "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.512, train_loss_epoch=0.512, valid_loss=2.040]        \n",
      "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=2.040]        \n",
      "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=2.040]        \n",
      "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=2.040]        \n",
      "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=2.040]        \n",
      "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=2.040]        \n",
      "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=2.040]        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 15:49:24,380\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n",
      "You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n",
      "You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n",
      "2024-03-30 15:49:24,393\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-28-06' in 0.0179s.\n",
      "Seed set to 2\n",
      "\u001b[36m(_train_tune pid=51770)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=51770)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.503, train_loss_epoch=0.503, valid_loss=2.040]        \n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 17.50it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.503, valid_loss=2.040]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 379.64it/s]\u001b[A\n",
      "Epoch 999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 13.72it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=1.970]\n",
      "Epoch 99: 100%|â–ˆ| 1/1 [00:00<00:00, 19.99it/s, v_num=47, train_loss_step=1.610, \n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 91.51it/s]\u001b[A\n",
      "Epoch 199: 100%|â–ˆ| 1/1 [00:00<00:00, 21.35it/s, v_num=47, train_loss_step=1.150,\u001b[A\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 34.97it/s]\u001b[A\n",
      "Epoch 299: 100%|â–ˆ| 1/1 [00:00<00:00, 12.78it/s, v_num=47, train_loss_step=0.848,\u001b[A\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 83.26it/s]\u001b[A\n",
      "Epoch 399: 100%|â–ˆ| 1/1 [00:00<00:00, 22.07it/s, v_num=47, train_loss_step=0.531,\u001b[A\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 93.10it/s]\u001b[A\n",
      "Epoch 499: 100%|â–ˆ| 1/1 [00:00<00:00, 19.88it/s, v_num=47, train_loss_step=0.471,\u001b[A\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 91.26it/s]\u001b[A\n",
      "Epoch 599: 100%|â–ˆ| 1/1 [00:00<00:00, 19.42it/s, v_num=47, train_loss_step=0.416,\u001b[A\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 94.93it/s]\u001b[A\n",
      "Epoch 699: 100%|â–ˆ| 1/1 [00:00<00:00, 20.07it/s, v_num=47, train_loss_step=0.347,\u001b[A\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 93.34it/s]\u001b[A\n",
      "Epoch 799: 100%|â–ˆ| 1/1 [00:00<00:00, 20.83it/s, v_num=47, train_loss_step=0.327,\u001b[A\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 90.77it/s]\u001b[A\n",
      "Epoch 899: 100%|â–ˆ| 1/1 [00:00<00:00, 20.70it/s, v_num=47, train_loss_step=0.326,\u001b[A\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 97.67it/s]\u001b[A\n",
      "Epoch 999: 100%|â–ˆ| 1/1 [00:00<00:00, 14.10it/s, v_num=47, train_loss_step=0.304,\u001b[A\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 98.96it/s]\u001b[A\n",
      "Epoch 999: 100%|â–ˆ| 1/1 [00:00<00:00,  9.76it/s, v_num=47, train_loss_step=0.304,\u001b[A\n"
     ]
    }
   ],
   "source": [
    "nf = NeuralForecast(models=models, freq='D')\n",
    "nf.fit(df=features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46fcdfd-eb31-4f19-b9b1-4871b2e1f166",
   "metadata": {},
   "source": [
    "## predict future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1729a1c1-286a-4ca7-94ce-30ce1cd10e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 171.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>AutoNHITS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-13</td>\n",
       "      <td>72.983673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>73.235390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-15</td>\n",
       "      <td>73.990532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>74.745682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-17</td>\n",
       "      <td>74.580498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ds  AutoNHITS\n",
       "unique_id                      \n",
       "0         2024-01-13  72.983673\n",
       "0         2024-01-14  73.235390\n",
       "0         2024-01-15  73.990532\n",
       "0         2024-01-16  74.745682\n",
       "0         2024-01-17  74.580498"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcst_df = nf.predict()\n",
    "fcst_df.columns = fcst_df.columns.str.replace('-median', '')\n",
    "fcst_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "454daabe-2762-4db8-bd09-31edf89ef222",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'AutoNHITS-lo-80'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AutoNHITS-lo-80'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mStatsForecast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcst_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatplotlib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_insample_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsforecast/core.py:1331\u001b[0m, in \u001b[0;36m_StatsForecast.plot\u001b[0;34m(df, forecasts_df, unique_ids, plot_random, models, level, max_insample_length, plot_anomalies, engine, id_col, time_col, target_col, resampler_kwargs)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1326\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the ids as the index is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease provide them as a column instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1328\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1329\u001b[0m     )\n\u001b[1;32m   1330\u001b[0m     forecasts_df \u001b[38;5;241m=\u001b[39m forecasts_df\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m-> 1331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mplot_series\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecasts_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforecasts_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munique_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_random\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_random\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_insample_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_insample_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_anomalies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_anomalies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresampler_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresampler_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpalette\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtab20b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/utilsforecast/plotting.py:345\u001b[0m, in \u001b[0;36mplot_series\u001b[0;34m(df, forecasts_df, ids, plot_random, max_ids, models, level, max_insample_length, plot_anomalies, engine, palette, id_col, time_col, target_col, seed, resampler_kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y_col, color \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m([target_col] \u001b[38;5;241m+\u001b[39m models, colors):\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 345\u001b[0m         \u001b[43m_add_mpl_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m         _add_plotly_plot(fig, uid_df, y_col, level)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/utilsforecast/plotting.py:248\u001b[0m, in \u001b[0;36mplot_series.<locals>._add_mpl_plot\u001b[0;34m(axi, df, y_col, levels)\u001b[0m\n\u001b[1;32m    246\u001b[0m times \u001b[38;5;241m=\u001b[39m df[time_col]\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m level \u001b[38;5;129;01min\u001b[39;00m levels:\n\u001b[0;32m--> 248\u001b[0m     lo \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43my_col\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-lo-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlevel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    249\u001b[0m     hi \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-hi-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    250\u001b[0m     axi\u001b[38;5;241m.\u001b[39mfill_between(\n\u001b[1;32m    251\u001b[0m         times,\n\u001b[1;32m    252\u001b[0m         lo,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_level_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    257\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3807\u001b[0m     ):\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AutoNHITS-lo-80'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "StatsForecast.plot(features_df, fcst_df, engine='matplotlib', max_insample_length=7 * 3, level=[80, 90])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "001253ee-4a4d-40a6-b8c5-cd7c0b6e9857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(features_df['ds'].iloc[-20:], features_df['y'].iloc[-20:])\n",
    "plt.plot(fcst_df['ds'], fcst_df['AutoNHITS'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e2cedf-d242-4f80-bd11-a59d6c4c096f",
   "metadata": {},
   "source": [
    "## cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9902f3a1-7aa9-42ec-a664-b64a1805bfa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_train_tune pid=35284)\u001b[0m Seed set to 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 36.42it/s]\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s]                             \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508]        \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950]        \n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569]        \n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505]        \n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499]        \n",
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.68it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466]\n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466]        \n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493]        \n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449]        \n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461]        \n",
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10.14it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.461]\n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443]       \n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468]        \n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478]        \n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472]        \n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470]        \n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477]        \n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.459, train_loss_epoch=0.459]        \n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473]        \n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452]        \n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438]        \n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.429, train_loss_epoch=0.429]        \n",
      "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471]        \n",
      "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.442, train_loss_epoch=0.442]        \n",
      "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435]        \n",
      "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.427, train_loss_epoch=0.427]        \n",
      "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410]        \n",
      "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446]        \n",
      "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423]        \n",
      "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416]        \n",
      "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473]        \n",
      "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461]        \n",
      "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.417, train_loss_epoch=0.417]        \n",
      "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400]        \n",
      "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423]        \n",
      "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425]        \n",
      "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386]        \n",
      "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400]        \n",
      "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421]        \n",
      "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363]        \n",
      "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382]        \n",
      "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400]        \n",
      "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367]        \n",
      "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343]        \n",
      "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364]        \n",
      "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337]        \n",
      "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346]        \n",
      "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353]        \n",
      "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322]        \n",
      "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321]        \n",
      "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304]        \n",
      "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295]        \n",
      "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320]        \n",
      "Epoch 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.17it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.320]\n",
      "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314]        \n",
      "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255]        \n",
      "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260]        \n",
      "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246]        \n",
      "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276]        \n",
      "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248]        \n",
      "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284]        \n",
      "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266]        \n",
      "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265]        \n",
      "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214]        \n",
      "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234]        \n",
      "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236]        \n",
      "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209]        \n",
      "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239]        \n",
      "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202]        \n",
      "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235]        \n",
      "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228]        \n",
      "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224]        \n",
      "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199]        \n",
      "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210]        \n",
      "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183]        \n",
      "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184]        \n",
      "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169]        \n",
      "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157]        \n",
      "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174]        \n",
      "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149]        \n",
      "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182]        \n",
      "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200]        \n",
      "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212]        \n",
      "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331]        \n",
      "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202]        \n",
      "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185]        \n",
      "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160]        \n",
      "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158]        \n",
      "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174]        \n",
      "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144]        \n",
      "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177]        \n",
      "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.143, train_loss_epoch=0.143]        \n",
      "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177]        \n",
      "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130]        \n",
      "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149]        \n",
      "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127]        \n",
      "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135]        \n",
      "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131]        \n",
      "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129]        \n",
      "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0966, train_loss_epoch=0.0966]        \n",
      "Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.87it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.0966] \n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 199.97it/s]\u001b[A\n",
      "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=1.180]        \n",
      "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.101, train_loss_epoch=0.101, valid_loss=1.180]        \n",
      "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124, valid_loss=1.180]        \n",
      "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0998, train_loss_epoch=0.0998, valid_loss=1.180]        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-30 15:12:22,043\tWARNING tune.py:229 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2024-03-30 15:12:22,047\tERROR tune_controller.py:1332 -- Trial task failed for trial _train_tune_92ed0_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TaskCancelledError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=35284, ip=127.0.0.1, actor_id=0623dec7fe08536aa0305edc01000000, repr=_train_tune)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    result = self.step()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 112, in step\n",
      "    training_result: Optional[_TrainingResult] = session.get_next()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/train/_internal/session.py\", line 282, in get_next\n",
      "    result = self.result_queue.get(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/queue.py\", line 180, in get\n",
      "    self.not_empty.wait(remaining)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py\", line 324, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "ray.exceptions.TaskCancelledError: Task: TaskID(3d3e27c54ed1f5cf0623dec7fe08536aa0305edc01000000) was cancelled.\n",
      "2024-03-30 15:12:22,085\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45' in 0.0173s.\n",
      "2024-03-30 15:12:22,117\tERROR tune.py:1044 -- Trials did not complete: [_train_tune_92ed0_00000]\n",
      "2024-03-30 15:12:22,118\tWARNING tune.py:1063 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45\", trainable=...)\n",
      "2024-03-30 15:12:22,142\tWARNING experiment_analysis.py:190 -- Failed to fetch metrics for 19 trial(s):\n",
      "- _train_tune_92ed0_00001: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00001: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00001_1_input_size=7,learning_rate=0.0002,n_freq_downsample=1_1_1_1_1,random_seed=1,scaler_type=robust_2024-03-30_15-11-54')\n",
      "- _train_tune_92ed0_00002: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00002: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00002_2_input_size=7,learning_rate=0.0002,n_freq_downsample=8_4_2_1_1,random_seed=3,scaler_type=robust_2024-03-30_15-11-54')\n",
      "- _train_tune_92ed0_00003: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00003: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00003_3_input_size=14,learning_rate=0.0002,n_freq_downsample=8_4_2_1_1,random_seed=3,scaler_type=robust_2024-03-30_15-11-54')\n",
      "- _train_tune_92ed0_00004: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00004: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00004_4_input_size=21,learning_rate=0.0010,n_freq_downsample=1_1_1_1_1,random_seed=1,scaler_type=robust_2024-03-30_15-11-54')\n",
      "- _train_tune_92ed0_00005: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00005: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00005_5_input_size=7,learning_rate=0.0073,n_freq_downsample=8_4_2_1_1,random_seed=4,scaler_type=robust_2024-03-30_15-11-54')\n",
      "- _train_tune_92ed0_00006: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00006: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00006_6_input_size=7,learning_rate=0.0009,n_freq_downsample=1_1_1_1_1,random_seed=1,scaler_type=robust_2024-03-30_15-11-54')\n",
      "- _train_tune_92ed0_00007: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00007: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00007_7_input_size=21,learning_rate=0.0001,n_freq_downsample=8_4_2_1_1,random_seed=2,scaler_type=robust_2024-03-30_15-11-54')\n",
      "- _train_tune_92ed0_00008: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00008: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00008_8_input_size=21,learning_rate=0.0009,n_freq_downsample=1_1_1_1_1,random_seed=4,scaler_type=robust_2024-03-30_15-11-54')\n",
      "- _train_tune_92ed0_00009: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00009: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00009_9_input_size=14,learning_rate=0.0005,n_freq_downsample=1_1_1_1_1,random_seed=4,scaler_type=robust_2024-03-30_15-11-54')\n",
      "- _train_tune_92ed0_00010: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00010: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00010_10_input_size=7,learning_rate=0.0023,n_freq_downsample=1_1_1_1_1,random_seed=1,scaler_type=robust_2024-03-30_15-11-54')\n",
      "- _train_tune_92ed0_00011: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00011: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00011_11_input_size=14,learning_rate=0.0010,n_freq_downsample=1_1_1_1_1,random_seed=3,scaler_type=robust_2024-03-30_15-11-54')\n",
      "- _train_tune_92ed0_00012: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00012: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00012_12_input_size=14,learning_rate=0.0003,n_freq_downsample=1_1_1_1_1,random_seed=4,scaler_type=robust_2024-03-30_15-11-54')\n",
      "- _train_tune_92ed0_00013: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00013: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00013_13_input_size=21,learning_rate=0.0029,n_freq_downsample=8_4_2_1_1,random_seed=4,scaler_type=robust_2024-03-30_15-11-54')\n",
      "- _train_tune_92ed0_00014: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00014: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00014_14_input_size=7,learning_rate=0.0040,n_freq_downsample=8_4_2_1_1,random_seed=1,scaler_type=robust_2024-03-30_15-11-54')\n",
      "- _train_tune_92ed0_00015: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00015: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00015_15_input_size=14,learning_rate=0.0002,n_freq_downsample=8_4_2_1_1,random_seed=1,scaler_type=robust_2024-03-30_15-11-54')\n",
      "- _train_tune_92ed0_00016: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00016: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00016_16_input_size=21,learning_rate=0.0008,n_freq_downsample=1_1_1_1_1,random_seed=3,scaler_type=robust_2024-03-30_15-11-54')\n",
      "- _train_tune_92ed0_00017: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00017: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00017_17_input_size=21,learning_rate=0.0004,n_freq_downsample=8_4_2_1_1,random_seed=2,scaler_type=robust_2024-03-30_15-11-54')\n",
      "- _train_tune_92ed0_00018: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00018: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00018_18_input_size=14,learning_rate=0.0043,n_freq_downsample=1_1_1_1_1,random_seed=3,scaler_type=robust_2024-03-30_15-11-54')\n",
      "- _train_tune_92ed0_00019: FileNotFoundError('Could not fetch metrics for _train_tune_92ed0_00019: both result.json and progress.csv were not found at /Users/ryderkemper/ray_results/_train_tune_2024-03-30_15-11-45/_train_tune_92ed0_00019_19_input_size=21,learning_rate=0.0013,n_freq_downsample=1_1_1_1_1,random_seed=1,scaler_type=robust_2024-03-30_15-11-54')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0866, train_loss_epoch=0.0866, valid_loss=1.180]        \n",
      "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0979, train_loss_epoch=0.0979, valid_loss=1.180]        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2\n",
      "\u001b[36m(_train_tune pid=35284)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 4 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[36m(_train_tune pid=35284)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|â–ˆ| 1/1 [00:00<00:00,  6.04it/s, v_num=43, train_loss_step=0.120, \n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 40.55it/s]\u001b[A\n",
      "Epoch 199: 100%|â–ˆ| 1/1 [00:00<00:00,  7.15it/s, v_num=43, train_loss_step=0.0356\u001b[A\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 50.81it/s]\u001b[A\n",
      "Epoch 299: 100%|â–ˆ| 1/1 [00:00<00:00,  6.88it/s, v_num=43, train_loss_step=0.0063\u001b[A\n",
      "Validation: |                                             | 0/? [00:00<?, ?it/s]\u001b[A\n",
      "Validation:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                            | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 32.34it/s]\u001b[A\n",
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 42.43it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "cv_df = nf.cross_validation(features_df, n_windows=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "66043d47-b21d-4661-97b3-d96f411ca86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAACTrUlEQVR4nO2ddXxk9dX/33ckk4m7J+tuLMuy7OLOFi+FAjXsobT84KH0oaUClNIWqVGgpUYpTqFIkZYtLLawsA7rbsnG3Ufv74/vvSPJxG2SnPfrldedXJvvDEvmM+d8zjmarus6giAIgiAIw4RlpBcgCIIgCML4QsSHIAiCIAjDiogPQRAEQRCGFREfgiAIgiAMKyI+BEEQBEEYVkR8CIIgCIIwrIj4EARBEARhWBHxIQiCIAjCsGIb6QV0xO/3U1paSmJiIpqmjfRyBEEQBEHoBbqu09TURF5eHhZL97GNqBMfpaWlFBYWjvQyBEEQBEHoB8XFxRQUFHR7TtSJj8TEREAtPikpaYRXIwiCIAhCb2hsbKSwsDDwOd4dUSc+zFRLUlKSiA9BEARBGGX0xjIhhlNBEARBEIYVER+CIAiCIAwrIj4EQRAEQRhWRHwIgiAIgjCsiPgQBEEQBGFYEfEhCIIgCMKwIuJDEARBEIRhRcSHIAiCIAjDiogPQRAEQRCGFREfgiAIgiAMKyI+BEEQBEEYVkR8CIIgCIIwrIj4GI80lsFHv4WWmpFeiSAIgjAOEfExHvn0D/DOT2Dj30d6JYIgCMI4RMTHeKSlWm3b6kZ2HYIgCMK4RMTHeMTdpLZe18iuQxAEQRiXiPgYj7hb1NbTNrLrEARBEMYlIj7GI65mtZXIhyAIgjACiPgYj5iRD2/7yK5DEARBGJeI+BiPiOdDEARBGEH6LD6ampq45ZZbmDBhAk6nk2XLlrFu3brA8auuugpN08J+zjnnnEFdtDBAJPIhCIIgjCC2vl5w3XXXsXXrVp566iny8vJ4+umnOeOMM9i+fTv5+fkAnHPOOTz++OOBaxwOx+CtWBg4Ac+HiA9BEARh+OlT5KOtrY2XXnqJBx54gJNOOompU6fyk5/8hKlTp/Loo48GznM4HOTk5AR+UlNTB33hQj/xecBnpFtEfAiCIAgjQJ/Eh9frxefzERsbG7bf6XTy0UcfBX5///33ycrKYsaMGXzrW9+ipqbrNt4ul4vGxsawH2EIcTcHH4vnQxAEQRgB+iQ+EhMTWbp0Kffccw+lpaX4fD6efvppPvnkE8rKygCVcnnyySdZuXIl999/Px988AHLly/H5/NFvOe9995LcnJy4KewsHDgr0roGtPvARL5EARBEEYETdd1vS8X7Nu3j2uuuYYPP/wQq9XK0UcfzfTp09mwYQM7duzodP7+/fuZMmUK77zzDqeffnqn4y6XC5cr+A28sbGRwsJCGhoaSEpK6sdLErqlcif8YYl6nJgL3905susRBEEQxgSNjY0kJyf36vO7z9UuU6ZM4YMPPqC5uZni4mLWrl2Lx+Nh8uTJEc+fPHkyGRkZ7N27N+Jxh8NBUlJS2I8whEjkQxAEQRhh+t3nIz4+ntzcXOrq6lixYgUXXnhhxPNKSkqoqakhNze334sUBhGzxweAR8SHIAiCMPz0udR2xYoV6LrOjBkz2Lt3L7fddhszZ87k6quvprm5mbvvvptLLrmEnJwc9u3bx/e+9z2mTp3K2WefPRTrF/pKx8iHroOmjdx6BEEQhHFHnyMfDQ0N3HjjjcycOZOvf/3rnHDCCaxYsQK73Y7VamXz5s1ccMEFTJ8+nWuvvZZFixaxatUq6fURLbhCql3QVemtIAiCIAwjfY58XHbZZVx22WURjzmdTlasWDHgRQlDSGipLajohy1mZNYiCIIgjEtktst4o5P4kF4fgiAIwvAi4mO8Eer5APC2jcw6BEEQhHGLiI/xhksiH4IgCMLIIuJjvBHJ8yEIgiAIw4iIj/GGeD4EQRCEEUbEx3ijk+dDIh+CIAjC8CLiY7zRyfMh4kMQBEEYXkR8jDdC26vDuGmxvnpfNZ/urxnpZQiCIAiI+Bh/mGkXi9FfbhxEPto9Pq5+fB1XPb6WNrdvpJcjCIIw7hHxMd4w0y5x6Wo7DgynVU0uXF4/7R4/JXWtI70cQRCEcY+Ij/GGGfmIy1DbcRD5qG8Nzq8pqWuDf98Gr92khuoJgiAIw46Ij/GErgdLbePHT+SjttUdeFxWVQVr/wwbn4Ta/SO4KkEQhPGLiI/xhKcVML7tB9IuY7+9en2I+KirPBI8ULppBFYjCIIgiPgYTwTKbDVwpqqH0Rj58Hl6PqcP1LYExUdzbXnwQNlng/o8giAIQu8Q8TGeMFMuMfFgj1OPo83zUXsAfj0DXv7moN2yLsTz4W6sCB4o/WzQnkMQBEHoPSI+xhMB8ZEAtlj1ONoiH2v+BK01sO/dQbtlXUjkw9dUHTxQ9jn4/YP2PIIgCELvEPExnjArXWLiQ8RHFEU+XM3w2TPqcWs1+AenJ0eo4TTOUxvyfI1Qd2BQnkMQBEHoPSI+xhOm58ORADaHehxNHU63vKAEAYDuh5bq7s/vJaGG0wytMfygmE4FQRCGHREf44mIaZcoER+6Dmv/Er6vpXJQbl3bEvR8pJviw+zwKqZTQRCEYUfEx3giTHwYkY9o8Xwc+hgqtysjbEqR2tdc0f01vcSMfBSlxZGGIT6KlqqtmE4FQRCGHREf44lo9nys/bPazv8ypE9Vj5sHHvnQdT1Qaju/IDmYdpl6htqWbZZOp4IgCMOMiI/xRKjnwx5F1S6NZbDjDfX42P+BhGz1eBDER5vHh8urKlrmFyQH0y6TTgSrA1wN0ulUEARhmBHxMZ6IVs9HyVrQfZAzH7LnQHym2j8I4sPs8RFjtTA9Kz6YdknMhZy56rH4PgRBEIYVER/jiYiejygQH2bkIXOm2gYiHwP3fJg9PlLj7UyId2PTVBREj0uH3KPUSeL7EARBGFZEfIwnotXzYYqP9ClqO5jiwzCbpsbFkGdTr79Bj6POpUHeUeokiXwIgiAMKyI+xhOuJrV1RFm1S63R6CttstomGGmXlqqB37olKD4cLtVgrFpPpri2NSTy8bmYTgVBEIYRER/jiUDkI8o8HzX71DYgPgY/7ZIWHxMQM7UkUlzXClmzwB6vTKeHPh7wcwmCIAi9Q8THeCIaZ7u4W6GpVD3uKD7a6sDrjnxdLzENpylx9oD4qNGTKalrA6sd5l+mTlzzpwE9jyAIgtB7RHyMJyJ5PjxtI7cegLqDahubDM5U43FKsAPpAFMvpucjLT5GDawDavQklXYBWGJMz935BtQXD+i5BEEQhN4h4mM8EejzkRj0fOg+8HlHbk2m2TRtCmiaemyxQHyWejzA1Esw8hFMu1STRHGdIbqyZsGkk9QsmXV/HdBzCYIgCL1DxMd4IlLaBUbW91Hbwe9hkmCKj4H1+gh6PoJpl1o9iZK61uBJS25Q241PjHwkSBAEYRwg4mM8ERAf8R3Exwj6PgKRjy7ExwCHy4VWu5hTcmv0JErq2vD7jQqX6eeoeTJtdbDlxQE9nyAIgtAzIj7GC143+AzzpiNBpTasMcaxkYx89CA+Bph2qW8NFR8q8tFkTcHt9bOn0hBjFiss/h/1eM2fpexWEARhiBHxMV4wox6g0i4w4uW2uq4He3yYDcZMBmm+S22o4dSIfOTlq6m5q/aEmFmP/pqaqFuxBQ6tHtBzCoIgCN0j4mO8YFa6WB2qxBRGtMX6qj1VnPDz/+BvKFE7OkY+4gfu+Whz+2j3qHbqKbEatKkmY3OmTTbWUB082ZkaUnb7x34/pyAIgtAzIj7GC6F+D5MRiny8tbWca/++HmdLMRZ02i3x6M608JMGwXBqltnarRoJvgZjr8biWVMBWHOghnaPL3jBsWbZ7ZtSdisIgjCEiPgYL5iRD0dCcN8ItFh/aUMJNz67EbfPzxlZak17vJn87t294ScOQpdTU3ykxMWgGSkX4tKZnptMVqKDdo+fDYfqghdkzzbKbn2w/rF+P68gCILQPSI+xgvmXJeYUPExvJGPJ1Yf5Lsvfo7Pr3PpogJuO1alfw7qOTz4zh5eWBcSbQhUu/S/yVhdi+rxkRYXA62G+IjPRNM0Tpym5sd8uKfD/c3ox4a/S9mtIAjCECHiY7wQOtfFZJharOu6ziPv7uGu17YBcPXxE7n/kvlY61SlS+aEWQD8+u1dyoQKQfHhalQt2PuBaTZNjbcHzKbEZwBw0nS1XbW7OvyiGcsh2Sy7/We/nlcQBEHoHhEf44XuPB9D+A1f13Xu+89OfvXf3QD87+nTuPO82VgsWqDMdtFRi3DYLFQ0uoLlr46k4Pr62esjUpmtKT5OmKq228saqWoKEV8WKxx7nXq85k9SdisIgjAEiPgYL5jiYxg9Hz6/zg9f2cqfPlQi48fnzuI7Z05HM9uoG+LDnjmVJZPTAfhwtyESNC2k4qV/qZdAg7H4UPGh0i3pCQ7m5icB8NHeDvdf+DWwOVXZ7eFP+vXcgiAIQteI+BgvuEJaq5sMoefD4/Nzyz8+47m1h9E0uP+SeVx3Ykg5rdcFZplt+hROmqYiER+Glr8OsNFYvTHXJTUuNO2SGThu+j46pV7i0mDBl9VjKbsVBEEYdER8jBciej6GJvLh8vr45lMbeP3zUuxWjYevWMiXFxeFn1R3SA1zi0mA+MyAEFizP6T8dYAVL5Faq5tpF4ATQwSP3jG9cuz1arvjjaBIEgRBEAYFER/jhWHs8/HcmsO8u7MSh83Cn79+DOfNzws/oe4gvHSNepw5AzSN6dkJZCc5cHn9rD9olL8mGFGKfla81EXyfMQFxceiCanEx1ipbnax7mBd+MXZc2Diiarsdp2U3QqCIAwmIj7GC+4IaRf74IsPXdd56tNDAPzwC7M4dUZW+Al73oY/nQzlW5QQOOc+gLDy10Db8wFGPurCWquHez4AHDYr587PBeCF9RGaii2RsltBEIShQMTHeMEsV42JC+4bgsjHJ/tr2FfVQnyMlUsWFQQP+P3w/n3wzKXQXg/5x8A3P4DCYwOnnNjR9zHALqdmn4/U+JiIng+Ay44pBODNzWU0u7zhN5hult3WStmtIAjCICLiY7zgMcSHPVR8DL7n42kj6nHx0fkkOGxqZ2stPPdleP9eQIfF18HV/4bkgrBrzfLXHWWNVDa1D3i+SyDyYfeA22iyFp8eds6iCalMzoynzePjzc2l4Tew2oJlt6sfhq0vQ8l6aG/s13oEQRAEhYiP8ULAcDp0no+KxnZWbFMpkq8eN0HtLPsc/nwK7Pmver6L/gjn/joofEIILX/9eG91MO3SVNbntbR7fLS6lXE1vVn1GCE+E2JTws7TNC0Q/XhhfQRjqVl2W70L/nk1/PV0eHBuMJIiCIIg9BkRH+OFYYh8PL+2GJ9fZ/HEVGbmJMFnz8JjZ0H9IUiZANe+DUdd0e09wspf06eonQ3FQfHUS9YcUBNs0+JjiKvcqHYWHKv6h3TgiwvzsVo0NhyqY6/Z5MwkLg0u/TvMuwyKlqr3r70Bitf0aT2CIAhCkD6Lj6amJm655RYmTJiA0+lk2bJlrFu3LnBc13XuvPNOcnNzcTqdnHHGGezZs2dQFy30gyH2fHh8fp5dq1IuX11SCG98B179lrr3tLOVvyN3fo/3OckQH+/uqsTlSA2mXqp29mk9/9p0BIBz5+WilaxXOwuOiXhuVlIsp85Qz/vihgjG0xnnwCV/gWvegtkXqn0V2/q0HkEQBCFIn8XHddddx9tvv81TTz3Fli1bOOusszjjjDM4ckT9sX/ggQd46KGH+OMf/8iaNWuIj4/n7LPPpr19eMe2Cx3wGJEDe6T26gP/b/Ph7ioqGl1kJMTwBftGWP83QINTfwRXPA/O1F7d59hJaeQmx1Lf6uG/2yoga6Y6ULmj12tpc/tYsa0cgIsW5imfBnQpPgAuNVIvL204gsfn7/rm2XPUVsSHIAhCv+mT+Ghra+Oll17igQce4KSTTmLq1Kn85Cc/YerUqTz66KPous6DDz7Ij3/8Yy688ELmz5/Pk08+SWlpKa+++uoQvQShVwxx5GNzSQMAp83Mwl5tCIUFV8DJ3wNL7/+ZWS0alxpVMi+sL4as2QDoFdv520cHeHbNYdoML0dXvLOjgha3j8I0J0entkNjCWgWyFvY5TWnzcwiIyGG6mYX7+/qpq+IsR4RH4IgCP2nT+LD6/Xi8/mIjY0N2+90Ovnoo484cOAA5eXlnHHGGYFjycnJLFmyhE8+iTwjw+Vy0djYGPYjDAFD7PnYX60iK1MyE6D2gNqZMbVf9zKjEB/traYuQfk+Svdu4qdvbOeHr2zh+Pvf5Xfv7KHO6GDakX99pqJwFy7IRzuyQe3Mmg2OxC6f0261cPHCfKCLnh8mZuSjdp/0/hAEQegnfRIfiYmJLF26lHvuuYfS0lJ8Ph9PP/00n3zyCWVlZZSXq1B3dnZ22HXZ2dmBYx259957SU5ODvwUFhb286UIXaLrQ17tsr9KGTUnZyaoDqYAqRP7da/CtDiOn5qOrsOKyjQAbIbnIyXOTm2Lm9++s5tl973LT17bRklda+DauhZ3IHJx4VF5UGL4kbpJuZiYVS/v7qxUpb6RSMiGuHTVGr5qV79e36ijpRr83UebBEEQ+kKfPR9PPfUUuq6Tn5+Pw+HgoYce4oorrsDSh9B6KD/4wQ9oaGgI/BQXd/OtU+gf3nbAmF0yBJEPv19nf5UZ+YiHOiPykTqp3/c0hcBfd6k1Zmu1LMu3svaHZ/DQFQuZnZtEm8fH31cf5ORfvs93/vEZO8oaeXNLGV6/zuzcJKZlJ4b4PRb3+JzTshNZWJSCz6/zqmFY7YSmja/Uy7534dcz4O07R3olgiCMIfqsGKZMmcIHH3xAc3MzxcXFrF27Fo/Hw+TJk8nJyQGgoiK8HXZFRUXgWEccDgdJSUlhP8Ig4w5GBsIiH3an2noHlj4ob2ynzePDZtEoTNCD7dDT+i8+zp6TQ7LTzt5GC0d01Rjs58fbiLFZuGBBHm/efAJPXnMsx09Nx+fXeWXTEZb/bhX3/UdFSC5amAc+Lxwxy2x7Fh9AWM+PTsPmTLLnqm3l9n6/vlHD+/eB3xuMIAmCIAwC/e7zER8fT25uLnV1daxYsYILL7yQSZMmkZOTw8qVKwPnNTY2smbNGpYuXTooCxb6gVnpYnWAxRrcP0iRDzPqUZQeh73RiFzFJve6wiUSsXZrwIOx268MqJN8hwLHNU3jpOmZPHPdcbz2/47n3Pm5WDRodnnRNDh/QR5UblPCypEM6dN69bznzc8l1m5hb2UzGw/XRz4p24x8bO336xsVHP402M+ktXZk1yIIwpjC1tcLVqxYga7rzJgxg71793Lbbbcxc+ZMrr76ajRN45ZbbuFnP/sZ06ZNY9KkSdxxxx3k5eVx0UUXDcHyhV4RqdIFBs3zsc/we0zJTBiUlIvJFccW8cyaQ5THTgLP5132+phfkMLvrzyag9UtPLfuMFMyEshNdsJuM+WyqNcVN4mxdr4wL5eXNx7hxfXFLJoQQUBlmeW2Yzzy8fFDwcdtIj4EQRg8+hz5aGho4MYbb2TmzJl8/etf54QTTmDFihXY7XYAvve973HTTTdx/fXXs3jxYpqbm3nrrbc6VcgIw0ikHh8QIj4GGvkwzabxwUqXAaRcTGbkJLLilpO44EyjeqqHXh8TM+L5wfJZXLbYMC2bfo/8ns2moZipl9c/L6XV7e18QtZMQIOWSmjupix3NFO1G3a9Gfy9rU4NBxQEQRgE+iw+LrvsMvbt24fL5aKsrIxHHnmE5OTkwHFN0/jpT39KeXk57e3tvPPOO0yfPn1QFy30EbMktFPkw0y7DCzyESizzRh4pUtHJmcmEF9geCwqtqnKnd6g61CyVj3upd/DZMmkNCakx9Hi9vHvLRGqtGLig+KqcnSZTmtb3PzktW2BaFWXfPKw2k41hJ/uV9OIBUEQBgGZ7TIeMNMupsHUxIx8+NwD+la7rzIk8jGIaZcAGTMATYX+W3qINHjaYOOT8OjxULNX7etFmW0o4cPmuqi+ClS8jK7Uy19W7efvqw/yo1e2dH1SUzl8/rx6fNJtEGP0R2mrG/oFCoIwLhDxMR7oKe0C/Y5+tLq9lDaoa8MajA1C2iVATFxIpCHCh72uqxTLG7fCr2fCazepiIQ9Dk75oRoO10e+eHQ+Fg3WHqjlgBHZ0XWd/3vxc859aBXezNFZblu362M+ctxMxsE3Ow/RM1nzJyVIC46FouMgzvC9iOlUEIRBQsTHeKAnwyn0W3yYH8ypcXZSnVaoP6wODFLaJYAZaQj1fdQXw4e/gkcWq1H36x9TqYHkIjjzHrh1O5zy/X49XW6yk5Omq2Fz/zSGzb32eSn/3FDCttJGDttHX9qlze2jqPpDCrRqvmJdyXNrD3c+ydWk3keA4/9XbZ2GeBPTqSAIg4SIj/FApNbqAFYbaEbpbT9Np/uMMtvJmQnQeAT8HrDYISm/v6uNTNYstT2yAT57Dp44Hx6cB+/eAzV71Gub/2X42qvwv5/B8TcPqNQXgsbTf24oob7Vzc/eDAqf2nijdLdyR/R0/yzZAH8/D0o3RTy8qbiODF2lThZa9vDq+gO0ezqsfeOT0N4A6VNhxhfUPjNy1FozVCsXBGGc0edSW2EUEqm1uoktVqVl+hn52B8osw2pdEmdEN5PZDDINKbbbnlR/ZhMPFENsJt9QbezW/rD6bOySI2zU9Ho4muPraWqKSjQqmPywOZUfURqD/R7js2gsvHvcHAVbPlnxCF66w7UsUCrByBW8zDBtZs3Ny/gEmOQHz4PfPIH9XjZTcHy5DjV5E3SLoIgDBYS+RgPdBX5gD43GvP7dTaX1AfGzu8PjXwMcqVLGPmLwGJo5bTJcOqP4ZYtcNUbsPArgy48ABw2KxcZjc62HFFTezMSYgBoceuQbHxoN1dEvH7Yqdmntq7IwxnXHawlyxAfAEssO3lmTbBxG1tfVhOA47Ng/uXB/ZJ2EQRhkBHxMR4IRD4iiQ+z10fvWqy/saWMCx75mGv+vg6fXw+UbE7OGKJKF5O0SXDNf+G6lXDTRjj5NkgpGvzn6YCZegE1qG7xRPVB3OL2BiNJ5vs70gTER2cjqcfnZ8OhOjK1YMXKsdadbDxcz/bSRmXaXW00FVvyTbCH+IECaRcRH4IgDA4iPsYDgchHhLSLvW+NxtYfVB9Aq/ZU8+v/7goYTqdkhVS6DEXkA1Sn0oJj1HC3YWJWbhLnzstlckY8Pzp3FvEOFX1pdnkhJkGd5O6hZ8Zw4GqCZqMnSYT1bCttxO1xk641BfYdZ9uDBb8qJ963UrWLt8fD4mvDL5bIhyAIg4x4PsYDXVW7QJ9brO+pCH6w/fP99fzG/ndetJ5KUdryYNplMMtso4Dff+XowOMEQ3y0unzRFfmo3R98HCHyse5ALRk0YEFXJmN7HE53E7O0w3yyLxnqjKjHom90NupK5EMQhEFGxMd4INDnY+Cej71GmuX4qekcfeBlzrGu41Tr59jLlw9t2iVKiHcoI62KfESR+DAbqgG4mzodXnMgxO+RkAXZc2DvOyy27GR9lQ4NHyhRcty3Ot9bxIcgCIOMpF3GA4HIRxfVLtCryEd9qztQ8fGHKxdxSoLqf+HADc9+WZVogqp2GaOYaZeWMPERBWmXmq4jH36/zvpDtWSZfo+EbJiwDIBTY/dwvfUNtX/uJZF9NJJ2EQRhkJHIx3igN9Uunp7Fh9kRMy85lmSnjYVW9YHnjU3F1lKpTkrIjixyxghm2qXF7YUE0/MRbZGPcPGxt6qZ+lYP+TFGFUxiDkw4HoBj9c3YLYbZ+PibI987NPKh68PquREEYWwikY/xQLd9Pox5L72IfJjiY2p2IjSUYGmtAosN29X/htgUddIYTrkAxMeYhtNo83zsCz7uEPlYe0BFLBakGP+NE7JVHxCrA6e/BZvm5/OYoyFnXuR7m5EPnysoZAVBEAaAiI/xwCD1+dhjio/MBNVpFJR3IHs2XPYkJBfCvC8NxoqjFtPz0RLNng9vG/i8gV93lquIx+RYQ5Qk5qj/7iHTfh9sW47b28VwwZh4sKr+JtLlVBCEwUDEx3jAY4TVB1jtYoqPadkh4iN/kdpOPhm+sxWO/Z+BrjaqCfd8REmpbWtt54mzIaZTsxFcdsBwmq22E1XqZQeTeM8zm22lDZHvr2nS5VQQhEFFxMd4wN3FVFvoU+Rjnxn5yEqAIxvVTlN8jBPC+3wYYm6kUxFmmW1inpqrA2GpF1N8JPsM4ZCYo7ZLboDF1/F8/g8AjQ2HOgiYUMR0KgjCICLiYzwQSLs4Ox8zIx/ln3crQFpcXo7UqwjK1HRncHjZOBMfgT4f7ijyfJgpl/Qp4AiPxrS4vJQ3qqiW01WljiUY4iMuDc79NTnTjgFg/cFuxIeU2wqCMIiI+Bjr+Lzgc6vHkQyn2cao+h2vw6PL4MCqiLcx26hnJDhIbT2geofEJEDG9KFYddQSlR1Ozbbq6VMgxphxY0Q+zA606XE2LGZFUmJ22OXHTFRNxdYfqkXX9cjPYTYeE/EhCMIgIOJjrOMJ+VYeyXB69DfgS39Tw8Rq9sIT58GrN3b6kDE7m07Nig/6PfIWDv702ignwah2cXv9eM1KoWiJfKSFRj6U58MUjQvSfeA3TKjxWWGXz8tPJsZqobrZzaGaLlJIcZJ2EQRh8BDxMdYxG4xplqC/IxRNU82l/t86OOYate+zp+GRY+Cz51RfB0LMplmJUGr4PSKMbR/rxDmCYqsNI2U1DOKjutnFSxtKaPf4Oh80y2zTpwajMR0iH3OTDUNxXDrYYsIuj7VbmVeQDMD6rnwfYjgVBGEQEfEx1gkdKtddcyhnCpz3WzU5Nmu2Kql89QZ48gKo3hvo8RGx0mUcYbdaiLGp/21a9OETH4+8u5fvvvg5333x8/DUiK6Hp10cRtrFSAWZZtPpccYaTb9HB46ZYKReDnYhLsRwKgjCICLiY6xjfDB6bU7u+tfWQHt0E6/Pz5r9NdS2GL6QoiXwzQ/hjJ+oBmQHPoRHl7G05K8k0Mr0VBtUbFPnjkPxAUHTaXNAfDQHIkRDRVmDMvu+ubmMf6wrDh5orlTPr1nUNGFHeORjf7XaTnQYpbcd/B4mx0xU4qLryIcYTgVBGDykvfpYx4h81LptPPHJIVxeP/ddMj9w+KF39/LQyj1oGhxVmMJpM7I4dWYWc46/BW32RfDmd2HfSq71PcfXHS/Au7OVdyA+C5ILRuhFjSzxDiu1LdCkG2ks3a/6pESqJhokml3BpmE/eX0biyakMi07Mej3SC5UaTXTcOpuQtd1DhiRj1yL0cOji8jHIiPysbeymboWN6nx4amZQORDmowJgjAISORjrGNEPmo9Sme+sbmMNrfyDbi9fp5dcwhQX9w3Ha7n12/v5ryHP2LJL1byvXcbeeuoR9h30kPs8+di13zYK7eo++YvGrczPgIt1n324M4hTr00u9R/s7T4GNo9fv7fs5uU/6M2JOUCYZGPikYXLW4fVotGit/s8RE58pEWH8PkTFUNFbHfh+n5kLSLIAiDgIiPsY4R+WgxvqU3u7ys2FYOwModFVQ3u8lMdLDqe6fyi4vncebsbOJirFQ2uXhhfQk3PLOJ0/+bwenuX3Nj+mOw/Jew8Gtw2o9G7CWNNIHhch49WEE0xOW2ze0eAH564RwyEhzsqmjinje2h/g9pqptwHDaFEi5FKY6sbZUGIuPHPkAWDyhm9RLIO3STS8QQRCEXiLiY6xjVLu06g6cdlWp8c8NJQA8b3gHLl1UQGFaHFcuKeIvXz+GTXeeyVPXHsvVx09kUkawN0jOpNmw5Hq48JGuh5CNA4K9Poav0ViLEfmYmB7Pb7+8AIBn1hym/IDhv0nrEPlwNwfMppMzE6DJEB9dRD4AFhn9PjYcihDdMPt8uJvA6x7AKxEEQRDPx5hHd7egAW04+N45M7j79e18vK+adQdr+XCP6nj55cWFYdc4bFZOnJbJidMyuet8Va65s6yR46dljMAriD4Swua7xENL1TCID+X5iHfYmJufzLdOmcKj7++jqXQnORA58mGKj4x42FduLL7ryIdZ8fJ5SQMurw+HLaSHS2yKMrXqfjVHphsRIwiC0BMS+RjjVNepMHm7FsuXFxeydHI6ug43PrMRXYdlU9KZkB6h82kIkzLiWT4vl6RYe7fnjRfMybbD1eVU13Wa3Up8mMLn1jOnc3RhEoW6EhWelEnq5JBSWzPtMjkjvleRj0kZ8aTHx+D2+tl6pMOQOYtFCRAQ06kgCANGxMcY50CZim4kJSYTF2PjS4tUhUqlUXJ7+bFFI7a20UpcTIfIBwxp5KPV7QtU8priw2618Mh52cRqHty6lQfXG5OLHcH26mbkY2qyH7zG8W4iH5qmBapeIs55EdOpIAiDhIiPMc6RSvUtNStDGQaXz8shPkZ9c0+Ns3P2HAmf95WwtEvAcDp0k23NMlurRSPWHvxfNs97BIBiPYs/fHiIj/ZUByIxflcTJXVqTVNijR4fjqTgJN4uMOe8rIsoPqTXhyAIg4OIjzFMfaubhgYVPs/PUt9a42JsXHBUHgBfWlQQntcXeoVpOG0Jm2w7dGkXU3zEx1jRQsubjTJbd8okdB2+88Jn1PlUVZOvvQm/roRSmm6IhYSehabZbGzj4brOQ+aky6kgCIOEGE7HMB/srsKJSq8kJyYF9v/o3NksmpDGefNzR2ppo5oEw/PR4vJCnOn5GLq0S3O7Eh+JHT03RpnttFlHMV1LYHdFM/e9W8/9gG50OJ2cGY/WXKrOT+w65WIyNy8Zh81CbYub/dUtTMlMCB6UyIcgCIOERD7GKPWtbh5+dy9xmjFQLCZoKk1wKO9HrF2iHv0hWGo7PJ6PYKVLh/9ehviwZUzlkSuPJtZu4f0DytthcTcDumE2NStdeo58xNgsLChIASLMeTHLbQfDcHr4U6g7OPD7CIIwKhHxMQZp9/i4/skN7K1sJtVmtOW2d5/rF3pPfMdSWxjStEuTK7zSJUDINNvp2Yn84uJ5eI3/zjbNT7pD59z5edBsVrr0HPmAoO+jk+k0YDgdYKOxuoPwt3PguSsGdh9BEEYtIj7GGH6/zndf+Jy1B2tJdNhYmGvM6IjpvpxW6D1Bw6kvpNR2OCIfIeLD5w1GDozW6l88uoANd18cOGXDbcdx5uzsYOQjsXdptmMCzcY6io9BSrtUbAd0iXwIwjhGxMcY4xf/3sGbW8qwWzX+9LVFxGvGFFuJfAwacTGhfT6GPu3SHCnyUX9IDfizOSExL7jfYgG7sSZXo9oGxEfvIh9HFynxsb+6hermkCnIZp+P9vo+voIO1Kt5QnhapVuqIIxTRHyMIR776AB//egAAL+6dAHLpmYES0B7KLEUek8g8uEeIvHh94f9GlF8mDNd0iYrwRGKo0Pjs+a+iY+UuBimZal7hEU/QobWDYjQiEd7Q5enCYIwdhHxMUb495YyfvbmdgC+f85MLjwqXx3wGB+Kdkm7DBZm+qM1LO0ySJ6PTx+F+ydA6abALrPaJSztEvB7TO58j5BGY0CI4bR34gOCJbdh4iMm2D11QISJj/qB3UsQhFGJiI8xwLqDtdzyj8/QdfjacRO44eSQDySJfAw6pghw+/x4bE61c7AiH3tXqnTJ3pWBXabnIzE2NPKxV23NmS6hhAoiV1NQLPRhHssxgU6nIf6OjhGV/hIqPtrqB3YvQRBGJSI+Rjl7K5u47on1uL1+zpydzU8umBPeiMpjiA/xfAwaZodYgHYGWXy4jG6kpi+CYLVLfMS0y5TO9whEPpqCM11iEoP7e4FpOt1ypIF2j8+4h+klGYD40HVJuwiCIOJjNFPZ2M43/raOhjYPC4tSeOjyhVgtIcLD7w+KD6l2GTRsVkugzXkrsWrnAMTHB7ur+OZT62lo9QTFR11QfLR05/noKfLRVKYe93EKbVFaHJmJDjw+nc0lhkAw0y7eNlVt0x+aK8DbHvxd0i6CMC4R8TFKaXZ5ufrv6zhS38akjHge+8ZinDEdmlCZw8RAIh+DTMB0impnPpBUxN2vb2PFtgpe31waMfLRyXDqaYeGYvU4PVLkI8QYGujx0bdutpqmBVMvh2rD7wtBL1FfCRFVwMB7hgiCMCoR8TEK8fj8fPuZjWwrbSQ9Poa/X72YtPiYzieGDjsT8TGomJNtm3VDfHj6N1hub2VTYPpsZWN7sDy2oQT8Kt3R7FLbgPioOwjoalBcfGbnm0aKfPSiu2lHOk24tTnAYrR472/qpWNvD0m7CMK4RMTHKEPXdX748hY+3F2F027lb1ctZkJ6FykV89upzdm5HFMYEKb/oslviA9ve79SESu2VQQeVzS0ByMffi80qqm1ze2esOcMmE3TJkOov8ckEPlo6nOPj1AWh1S8+P3GkLmBdnTtJD7q+3cfQRBGNfKJNMp48J09vLihBIsGj1y5kAWFKV2f7DHSLlLpMuiYw+WajCmyQL9SESu2lQce1zU2gO4LHjRSFC1G5CNQ7VLbjd8Dwkti+9jdNJTZeUk47VYa2jzsqzLERscy3r5iig+z9FuqXQRhXCLiYxTxr8+O8LuVewD42UXzOH1WD6F0M+0iPT4GnUDkw6OBxRAFfTSdlta3Bc2cQHNjffgJhu+juWO1S6DMNoLfA8KrXfo41yUUu9XCgsJkANaZqZce+pp4fX5+899drN5bHfmmpvjIna+2knYRhHGJiI9RxNOfqg+j60+azJVLinq+wPwmLpGPQScwXM7t63eX0/8aUY90w6/T1tTBfFl3EL9fV51UCfF81OxX20hlthBuOA1Uu/RdfEAw9dLJdNqF+FhzoJaH3t3L91/eHPmGAfFxlNpK2kUQxiUiPkYRh2pUJOO8+b0MoQciH84hWtH4JSEmVHz0r/mW6ff48uJCALxtjeEn1B2i1eNDN+wWCZ0iH12lXUINp33vbhrKvHwV+dhdYXhRDKHV2lTP1/+2lpc3loSdX1Kn/s0V17ZR1tAWdgxPe1AM5S5QW4l8CMK4RMTHKKHd46OySQ35KkztZSRDWqsPGWbko7/D5epa3Kw1uodevrgIu1UjQevwYV1/KNDjw2rRVG8RV3NwVkuk1uoQTLs0lferu2kokzLUaztY3Yqu6wFhs/NwGR/uruIvqw6EnV/WEOzhEaiSMWkoBox7mCkj8XwIwrikT+LD5/Nxxx13MGnSJJxOJ1OmTOGee+5Rf5QMrrrqKjRNC/s555xzBn3h4w3zG2Wiw0ZKnL13F0lr9SHDNJy29FN8vLOjAp9fZ1ZuEkXpcWQlxpKI8d/LaphY6w7RZM51ibGqzrWm2TQuHZypkW9uRj7MFEcfu5uGUpgWh6YpkVXd7A7cp7FBCYuO0Y2KxlDxURt2LLCe1ImDNyFXEIRRia3nU4Lcf//9PProozzxxBPMmTOH9evXc/XVV5OcnMzNN98cOO+cc87h8ccfD/zucDgi3U7oA4dr1QeT+jCIUF4ZCWmtPmTEhUU++p52MVMuZ89REYnsJAcJjcYHedYsKPsMmstpbVH3TIw1BGd3bdVNTF+GWTnTz6gHQKzdSl6ykyP1bRysaSHTeK0tTSpdUt/qocXlDUSCQiMf6zpGPkLFhzNFPW5vVJ14pRRcEMYVfRIfq1ev5sILL+Tcc88FYOLEiTz33HOsXbs27DyHw0FOTv9yzEJkimvVB1NhWh/8G+Y3cWmtPugEDKf9iHy0ur2s2lMFwNlz1P8n2UmxwbRL6gTl63A34609ZDyf0b22pzJbCIohk36U2YYyMSNOiY/qFhYbr9XVEvRqlDW0MTVLRUTKQ8THzvJGmto9QeEUFvlINs7SVWM1U4wIgjAu6NPXjWXLlrFy5Up2794NwOeff85HH33E8uXLw857//33ycrKYsaMGXzrW9+ipqamy3u6XC4aGxvDfoTOmJGPorQ+RDEk8jFkmGmX1n5Uu3ywqwqX109RWhwzc9SHdnZSLAkY4sORBCkTANCND+yg2dQUH134PaBziqUf3U1DmWg0sTtY0xKIqvjamwLHS+uDgqPcSLvYrRp+HTYdrg/eKFR82Byq+R1I6kUQxiF9Eh+33347l19+OTNnzsRut7Nw4UJuueUWvvKVrwTOOeecc3jyySdZuXIl999/Px988AHLly/H5/NFvOe9995LcnJy4KewsHBgr2iMUhySduk14vkYMuJjIhlOe5d2ecsosT17TnYghZaV5CBRCxEfqUp8WBoOq+frKD66S7t0inwMLAoZajo1G5jF6kGvR2m9etzu8VHfqrqxnjxdtX0P832Yc10MYRVMvUjFiyCMN/qUdnnhhRd45plnePbZZ5kzZw6fffYZt9xyC3l5eXzjG98A4PLLLw+cP2/ePObPn8+UKVN4//33Of300zvd8wc/+AG33npr4PfGxkYRIBE43B/xIdUuQ0ZCWNrF9Hz0HPlwe/28u7MSCKZcALITY2kNRD4SAx/QMU3FwOxgd9OeymwhOIPFr4TAgNMuRuTjQHULzFavNZ5gtKPUSLWYKZe4GCunzszinR2VQd+HrodHPkClXprKpOJFEMYhfRIft912WyD6AUpcHDp0iHvvvTcgPjoyefJkMjIy2Lt3b0Tx4XA4xJDaA7quByMfvS2zdTXD7v+qx0kD+/AROhP0fISmXXoeLvfJ/hqa2r1kJjo4uihYrZKdFEuVFiI+jKhAbLPqoxEfY4PWWmgzIglp3aRdNE2lR8yJsQOMfEzMCKZddHs8GhCvhYgPI/Jhmk1zkmI51mhOtqm4Do/Pj729DtxGqibFaJAnFS+CMG7pU9qltbUVSwdXutVqxe/3d3lNSUkJNTU15ObKB2B/qWv1qGZWQEFqLw2nHz4ATaXqW+a8S4duceOUsD4fpqemF5EPc5bLmbOzsViCVUvZSY4Qz0diIDoQ31YSfL5ao7NpYm74ePtIxIT4PgYoPgrTnFg05W9pMGbZJNBGfor6t2iW25Yb1To5ybFMyUwgJc5Ou8fPttLGYNQjMQ/sseqxpF0EYdzSJ/Fx/vnn8/Of/5w333yTgwcP8sorr/Cb3/yGiy++GIDm5mZuu+02Pv30Uw4ePMjKlSu58MILmTp1KmefffaQvIDxgJlyyUmKJdZu7fmCql3wye/V43Pulw6nQ0B8SJ8PvZeeD79f5+3tZoltuCDISooNeD7ctvhA2iWpvRQwhsr1xu9hEipO+tndNHArm5U8Q2iUtivRFUc7J0zNUPvqzbSLaoKXkxyLxaJxzAQV2Vl/sBbqjGZkZsoFghUvknYRhHFHn8THww8/zJe+9CW+/e1vM2vWLP7v//6Pb37zm9xzzz2AioJs3ryZCy64gOnTp3PttdeyaNEiVq1aJamVARA0m/ZCROg6/Ps2NZJ9+nKYIQ3ehgIz8uH163itvYt8bCquo6rJRWKsjaWT08OOJcXaAuKj3hcbSE3E+ZpIpFU9X08D5UIJNZ0OoM+HiWk6LW5WfzIStHaOn2aKjzZ0XafciIDkJKnIxqIJKvWy7mBtYEheuPhIUVtJuwjCuKNPno/ExEQefPBBHnzwwYjHnU4nK1asGIx1CSH0yWy67RU48AHYYmH5fUO8svGLWe0C0G5xYocexYfZWOy0mVnE2MJ1v6ZpJFvaQYcar4MsRwLEZUBrNYVapTK4lphltn2IfAygu2koE9PjWbWnmu01Ps5GGU6XTVECyuX1U9viDng+cpOV+Fg8UUU+NhyqQ086iAaBKh4gGPmQtIsgjDukreAooNdmU1cTrPihenzCreHfMoVBxWrRcBopsHYMD0M3aRdd1wN+j44pFxMz8lHpMppyGR/UhVqVEh81vWgwZmJGPgYh6gFB0+nK/erfYpzmIiPORmaiimiW1rcHWqvnJKsI3byCZGJsFqqb3bRXGX6V0H+TpudD0i6CMO4Q8TEKKK7rZYOxDx5QpYupE+H4/x36hY1zAhUvAfHRdeRjV0UTh2paibFZAj0wOhKnq//OZa4YtSN9GgDnWz8hIcbaR8+HEe0YYJmtyaQM9W9vT33ITnczeUaUo7Z0L9X1qprFTLs4bFYWFKjohq8mkucjRW0l7SII4w4RH6OAXqVdKnfCp39Qj5c/EKwoEIaMZKcSH/VeQyx0Iz5WbFUpl5OmZQQbhoXidWHXVV+O0lbj+NJv48PCedZPmXjkX0apqta7iJYpPgbY3dTE7PXhwo5HN0zP7hbyUpxM00o4+d+n8SPXbwBlODU5ZmIaNrzEtZWpHZEMp5J2EYRxh4iPKMfr8weqCbqMfOg6/Mcwmc74AkyXyqLhwBSDR1qN/426Ex9GyuWsLlIuuIIpm+IW4365C/iHRc1RmrzmDrUvpbB3wtLsIpo1s+dze0FBahyqMlijFUdgzbnJTmZrBwGYqR3GbtVIj48JXLd4Yip5Wg0W/MqHFCqGJO0iCOMWER9RTllDOz6/TozNQlZiFxVD216GAx+qP+7n3Du8CxzHmB6cQ01Gvw53sxKCHSiubWV7WSMWDc6Y1UUkwqVmGrXoDsqbvIHdv/VdSomegcWnylh7lXIBWHwtfPVlWPr/end+D8TYLBQYr7cZo+rK3UReSiyZmopcpGlNZCXGhvUvWVSURqGmOrp6kyeoBmgmfUm7NJZBc9VAX4YgCFGCiI8oxzSbFqQ6w/6oB3A1wYofqccnfldMpsOIGYnaF5iFqIOnrdN5ZtTj2ElppIVEBcJwKb9EM04qmlSky+/XqXbbuNNzVfC83phNQbVYn3r6oPZ4MU2nLboReXE1k5fiJMMQH0m0kp9kD7smOc7O4mR1vNbewX8SmnaJINoCeNrgD0vgTyeBzzPwFyIIwogj4iPK6XGa7Qf3GybTSbDs5mFcmWCmXfbVhXT4jZB66anKBQiKD91JZaOKcrR6fOg6vOs/Gu+si4wnPXbgC+8nk9LV620NRD6U5yNTqwfAoulMTugsDhYmKPFxyN/BaGumXXzuiKItQGOpEihNpVC+ZSAvQRCEKEHER5RzuLsy28od8Omj6vHy+8VkOsyYgrC4rj04vK9DuW1Vk4v1h9SMld6IjyacNLu8NLu8amgdqqzX+qW/wnXvwtwvDfKr6D1m5MMXaCffrNIuBA2jE5ztna6bYq8GYHNLaviBmATQDPNqd6mXlurg48Of9nndgiBEHyI+opziOvWNsFPkI7ST6YxzxWQ6ApgdZ2ta3PgDLdbDIx/v7KhA12F+QXKgRXlEDPHRpqn7VDa209SuxEd8jBXNaoeCRWAZuf9lT5iagdNuJTHJEBGuJjLiHWRaAnknCmI7RzCyvKrSZW19Im3GjCJA+T96U/HSGio+Vvd7/YIgRA8iPqKcLlurb30JDq4Sk+kIkhhrJzVOeRy8VuO/jzlJ1qBXKRcIGE69RgSlotEViHwkxtq7vGw4mZadyOd3ncX0QsO74W7GYtHI0oLCIcfeebKvvfEwAAf8WXxWXB9+sDcVLx0jH935QwRBGBWI+IhySupMw2lI5KOTyXRChCuF4cCMSNUmzVI7Nvw9cKyp3cPqvTUAnD2nh34bRuTDb1f9Ocoa2tTEXIJD7KKBGJsl2Lrd3QJ+H6kEIx+Z1g5dXtvq0YyUSrGeqYbMhdKbipfQyEdLVXC6ryAIoxYRH1FMm9tHdbMb6OD5eP8+aC4Xk2kUYJpOV+ddpXZsfUk1fAPe21WF2+dncmY8U7N6mK9iiI/YhBQA/r2lLCA+EiI1JRtJzBSTqxlajR4eBqk0hZ9rDJRri0mjjVjWHQqPDPUq7dJSE/774U/6s2pBEKIIER9RzJF6FfVIdNhIMrppUrE9aDL9wi/FZDrCmOLjc08hzDwP0OHDB4A+pFwgID6mF6mUxsqdlWwrVRGFiB1RR5IYQ0i5m6C5MuxQgr8x/Ny6gwDoKRMB2HioDp8/JG3Sq7SL0d/DNPUeEvEhCKMdER9RjGk2zU91omla0GSq+9QH3bQzR3iFgpl2OVzbCqfcrnZufRlX6Vbe36k+mPsiPlJT0zllRia6Dk+sPghAYmyUiQ8z7eJqhpZw8WHt4HkxxUds1mQSHDaaXV52lYdER/qSdjH/vUvkQxBGPSI+opiSjjNdtr4Ehz4CmxPO/sUIrkwwCRMfOfNg1vmATv1/fkaL20dOUizz85N7vpFhOMWRyNXHTwKgoU31zIiPiTLxERPi+egQ+aCtg6fDEB+WtEksLEoBYP2hkHN6lXYxxMfM8wANavd1fl5BEEYVIj6imBIj8lGQalRSrP2L2p7wHTGZRgmmF6ekrg2/X4eTVfQjs/gt5mn7OWtOduTOtB0xIh84kjhpWgZTMuMDhxKiLfIRE9LTxBABgWqf1g7+jDrl+SB1IosnpgGw7mBIdKQ3aRfznumTIWu2eiz9PgRhVCPiI4oJio848Hmh7HN1YM7FI7gqIZTclFisFg2X109Vswty5uKf+yUs6PzW/geWz0jp3Y0C4iMRTdO4yoh+QBQaTs2Jua4maFbTem3ZxgC7TuLjoNqmTuSYiao/yLoDtehmuWwg8lEf+bl0PRj5iMuAouPUYxEfgjCqEfERxQTLbJ1QtQO8beBI6v18D2HIsVst5KUo06/ZjXbj7Nup1FOYainl2H2/692NQsQHwCVH55NkRDyiz3Bqpl2ag2bQTKPUuDUkpeL3Qb3q8UHKBI4qTMFm0ShvbOdIvdGMLOD56CLt4m4Gc6hefAYULVWPpdmYIIxqRHxEMWbkozA1Do5sVDvzjhrRLpdCZwK+jxolPt7c5+Z7nusBsK77M+xd2fNNOoiPuBgbt545nQSHjWVT0gd/0QPBEcHzkWVEPtrqlOgANZPF7wGLHZLyiIuxMcfwv6w3Uy89pV3MqIfNqdI9EwzxUbZZGV4FQRiVyKdYlNLi8lLTonp85Kc6odQUH0eP4KqESJi+j8O1rTS7vPzrs1Le9x/F4SlXqhP+dWN4RCASHcQHwFXHT2LLT85ifkHKEKx6AIT2+TDFR6YhPtCDUQwz5ZJSBBbVKO2YCUbqxWw21lPaxUzjxGeobXIBJBeqiq8j6wf8UgRBGBlEfEQpZlg6KdZGstMejHzki/iINgoDA+ZaeWzVAWpb3EzOiCfv0l+qFFlTGbx5a9dtwf0+8BgzYRxJYYc0rRdm1eHG7PPhaVHN7gCS8sBhCAlTMIT4PUwWG76PDWazMacxJ6Zjia5JwO8REv0R34cgjHpEfEQpYW3VPe1QuV0dkMhH1GGmXbYeaeAvq1Tr71vPmo4tNgG++Gew2GDbK7Dlxcg3cIX0vTBTGtFM6BpNoZGQDXGp4fvqg5UuJosmqIqXXRVNNLR6lIkUwNMK7s5zYQKeEjPyAUHxcUh8H4IwWhHxEaUE/B5pTijfoqbXxmeqsLMQVZjiY3dFM80uL7Nzk/jCXGP4Wv4iOPn76vGb/wf1xZ1vYIoPqwNsjmFY8QCxxYIWMm9Gs6jIhBmdMFNMESIfmYkOJmXEo+uw8XCdSjNZjMF5HSplnllziB37Dqhf4jODB4qWqW3JevB5Buc1CYIwrIj4iFLMabYFqXFwZIPamXe0GkMuRBWBJnAGt50zI7y3xwm3QsFicDXAq98Cvz/8BhH8HlGNpgUrXkCJDos1RHx0TLuE96QJ831oWjCqETJArqyhjR+9spXVW3YGn8Mkc6byinhalDAXBGHUIeIjSglrMFYqfo9oJjXOHujFsXhiKqdMzww/wWqDi/8E9jg4uAo+/X348dEmPiA89ZJgTOx1qpRKoMtphMgHEGg2Fqh4MVMvIZGPQ0blUIpudH4NTbtYLFAovg9BGM2I+IhSwhqMHZFKl2hG0zSOnpCKzaLx/XNmRjaJpk8JtsRf+VOo2BY8NhrFR2jkw0yJhEY+XCE9QDqIj6ONyMfmI/V4fX6IM0RLyPRa899/Gob4iMsIu0fQdCpzXgRhNCLiI0oxDacT4j1Qs0ftlMhH1PL7Kxfy3v+dwjHGt/qILLoKpp8DPje89D/gNZpnBea6JHV5adQRKfIRajg1zabO1GA5rcHkjHjiY6y0e/zsr26JmHYx//2naYYwi+8gPiYYvo/Dn3RdRSQIQtQyfsRHwxF4+y747x0jvZIeaXZ5qWtVRrqCtl1qZ3JR5z/AQtSQGGvv5P3ohKbBBQ+rb/GV2+Ddn6n9ozLyEZw9Q0LHyEdd2EyXjlgsGrPzlNDaeqQhYtrFjHyka11EPvIWKoNuSxXU7h/QSxEEYfgZP+LD3QIfPwgb/j7SK+kR81tfSpyduOrNamf+whFckTBoJGTBBQ+px6sfhoMfjVLxEbLW+Cy1NT0frTVd+j1M5uSpaMjWI41B0dISjHwcCaRdzMhHhy6vNkcwEiipF0EYdYwf8ZGYo7auxqhvy1xSG2I2Fb/H2GPmubDwa4AOr9wAjUfU/tEkPiKmXQyB0FYb0t008vTluUab9a2lDUFhERr5qG8lFhdxmpGa6hj5APF9CMIoZvyIj9ikoEnOmMQZrZiRj8IUZ/APa8HiEVyRMOicc6+KCjQUw9q/qH2jSXyEGk47pV16jnzMzVdpl+2ljfid4WkXr89PWX076YbZ1IU98ntj9vuQihdBGHWMH/EBwehHU9nIrqMHio2Q81HOcpXTtsVCwTEjvCphUHEkwsV/Vg26/J7gvtFCmOfDjHyYpbZ1QR9GF+JjamYCDpuFZpeXCq9xLyPtUtHkwuvXybAo8VGjJ9Lu9Xe+SeFiQIOavcEZM4IgjArGmfgwuk42Rrf4MCMfR3mNBkpFx42OzpdC3yhaohqQmYyqapduPB+6XwkC6FJ82KwWZuaq17uzKUbtNKpdSowGezMSVcqlVk8K/D8RhjMVsmarxxL9EIRRxTgTH9Ef+Whs97D2gGrSNLllk9o58cQRXJEwpJz8fcg9Sj1OmzSiS+kTZtpFswYjHraYECOqro51Mw5grlHxsrlONWijrR583kCly5S4dgBq9USKDR9UJ2TInCCMSsap+Cgf2XV0w18+3E9dq4epGU4yqteqnZNOHtlFCUOHLQauegO+/hpMOX2kV9N7TMNpfIZqrW4SF9LnJLkArPYub2GaTjdUmE3ZdGirCzbYc6hoRw1JFEeKfEB4vw9BEEYN40x8GGmXKI18VDa189dVapDW3ceB1lanvmHmHTWyCxOGFkciTD5ZtQ0fLZieDzPlYhIqPlIjV7qYzDXKbbeUNaM7gw3KzBRLjk1VpdXqSYFZR50wIx9ln0d9FZsgCEFG0V+7QSAgPsIjHz6/jh4FXRIfXrmXNo+PowpTWGYx2m9PWNbtt0dBGBEmHK8GvC24PHx/6AC4LvweJtNzErBZNOpaPXhjzUqZ6kDkI8OienzUdJd2SS6A5ELQfXBkfX9eiSAII8A4FR/ByEeb28fpv36f03/9ARsO1Y3QwuBgdQvPrT0MoOaDHPxIHRC/hxCNJObAjWtg2f8L398H8eGwWZmerTwizRbDbNtSTUm9inIk+xsAqO0u7QLi+xCEUcg4Ex8hng8j0rF6XzUHa1rZX93CpX9czW/+uwuPL0JZ3xCi6zq/+PcOvH6dU2ZksnRiMhxarQ5OEvEhjCKcoWmXiT2ebvb7qNGVCPG31FBWr4ymcd5641g3aReAoqVqK74PQRg1jE/x4W2DdvWt6t2dqj9AZqIDvw4PvbuXLz26mv1Vw5c/fvrTQ/x3e0VgKqrKXzeqgVw584dtHYIwYPoQ+YCg6fSIW3lImuvK8fp17FYNu0tVfdXoSTS2e2kw5h11whQfxevA5+330gVBGD7Gl/iwOyE2RT1uKkPXdd4zxMcDl8zn4SsWkhRr4/OSBs596COeWXNoyL0gW0oauOeNHQDcvnwms3KT4OCH6uCEE8IrCQQh2jEn2wKk9lw6bM542dus+ti01qnuw3kpTjSj6ZhuCJouUy+ZM5VQ97RA+eb+rlwQhGFkfIkPCPN97KpoorShnVi7haVT0jl/QR4rvnMSy6ak0+bx8aNXtnLdE+upanINyVIa2jx8+9kNuH1+zpqdzbUnGH+sD6xS20knDcnzCsKQYUY+YhJVE7AemJefTFaig1KPinx4mqoAmJRiBbeKPsalqA6qXaZeLBYoFN+HIIwmxqH4CPo+zJTLsikZxNpVhCE32cnT1y7hx+fOIsZqYeXOSs558EPe2T6482B0Xee2Fz+nuLaNwjQnv/zSAjRNA78/6No3jXSCMFowox3Zc0DTuj8XiLFZ+OpxE6jRlfdDN6Ids+Ja1AnWGNLS1eyYriIf7R4f2+xzAFi/6t9RUbkmCEL3jD/xkZSntk1lgZTLqTPDexVYLBrXnTiZ1246npk5idS0uLnuyfXc9a+tg/aH7bGPDvDf7RXEWC38/sqjSY4zymlr9ys/ii1W/QEXhNFE3lHw1Zfgkr/2+pIrlxTRZFS7eBpV5GO+9aA6mDWbwrQ4gE7ltodrWrn3PztYdt+73LlJGVantGyifvXfoHKnEvKCIEQltpFewLBjRD5cdUcCpbWnzsiMeOrMnCRevfF4fv3fXfxl1QGe+OQQs3KTuPzYInWCrsPut8DTCnMv6fUSNhyq477/7ATgjvNmMb8gJXiwdKPa5i6Q/h7C6GTqGX06PSPBwdzpU2A/xPmUEXyKd486mHdUUHzUteLz67y7s5KnPz3Eh3uqzKI1EpJm0+xykqo1w9u3wttA5iz45oeqi6wgCFHFOBQfyvNRU3YYvw7TsxMoSI3r8vRYu5UfnTubzEQHv/j3Tu55YzvHT82gMLYd3rgFtv9LnVi0DJJye3z62hY3/+/ZjXj9OufNz+Wrx3XoAnlkg9rmL+rPqxOEUcm5x82F/ZBGI6CT3aLEOblHUZis/v/cdLieE+9/l9KG9sB1J03P5KtLijhtZhb/+5ufMbfhfa7MqyS5ah1U7YC6A5A5YwRekSAI3TEOxYeKfLjrjgCdUy5dce0Jk3l7ewXrDtbx92ee4MeuB9GaQzql1h3oUXz4/Tq3vvAZZQ3tTM6I575L5iufRygiPoRxyPSJEwFwaF4SaCOx1ujwm3cURQ4lPhraPDS0eUiNs3PZMYVcuaSICenxgXtUJc7h/ppcik44mnM/OB9q9kBzpYgPQYhCxqH4UALB0a78HqfNyIKGErA6ICFy+gXAatH41aULuODBlfxv9d1oWhtkTFcHq3ere/TAox/s4/1dVThsFn7/laNJcHR4+71uKDNKBfMW9v21CcJoJSYOr9WJzdfGItsBLK56sNiV58MawxePzqe8oZ1Ljylg+dzcgEE8FNM3VdfqhoQsQ3wMrlFcEITBYRyKDxX5yNDrSIq1sCjTD48sVf00rlsJ6VO6vHRCejwPLPWQtLaNSj2FuKveJeGd7xvio7jbp/10fw2//u8uAH564RzVz6MjldvA51K9SNIm9/slCsJoxJqQAQ3FfH/aETgAZM8GmwMN+M1lR/V4faohPhraPBBvfJFoqRqy9QqC0H/6VO3i8/m44447mDRpEk6nkylTpnDPPfeEVYDous6dd95Jbm4uTqeTM844gz179gz6wvtNQjY6GnbNx+lFVmy7/626ibbVwXNXBDqfdsVZzt0AfOqfxc5qjxpsBd1GPqqaXNz03Cb8Onzx6HwuO6Yw8omhKZdelCkKwlhCM3qEzG5Zp3bkHtWn61PjlLG0rsWIfIBKuwiCEHX0SXzcf//9PProozzyyCPs2LGD+++/nwceeICHH344cM4DDzzAQw89xB//+EfWrFlDfHw8Z599Nu3t7d3ceRix2mm0pABwYo4PdrwePFa9C166Dvy+Li/XDn0MwKf+2eyqaOpRfPj8Orf8YxNVTS6mZSXws4vmdvZ5mBwxKl3E7yGMR+Iz1LYy6PfoCymm+Gj1iPgQhCinT+Jj9erVXHjhhZx77rlMnDiRL33pS5x11lmsXbsWUFGPBx98kB//+MdceOGFzJ8/nyeffJLS0lJeffXVoVh/n/H6/BzxpQCwOL4S9r+vDlz8Z9VbY89/YeXdXVzsghL1rWyNfya7y3sWHw+t3MPHe2tw2q08+tWjiYvpJtMlZlNhPBOXEf57HyMfKYG0ixviDfHRIuJDEKKRPomPZcuWsXLlSnbvVqmHzz//nI8++ojly5cDcODAAcrLyznjjGCdf3JyMkuWLOGTTyJPnHS5XDQ2Nob9DCXbyxop86cAULD/H+D3QMYMWPBluPD36qSPfwefP9/54iMbwNtOuyOdfXqeEfkwUij1xYFJuSar9lTx0Lsq5fSLL85lalZi1wtrb4Qq5Qkh/+iBvERBGJ2EDqWz2PvcZC81YDiVyIcgRDt9MpzefvvtNDY2MnPmTKxWKz6fj5///Od85StfAaC8XJWeZmdnh12XnZ0dONaRe++9l7vv7iLSMASs2V9LvJ4CBFMozL5Abed9CSq3w6pfw2s3Q/pUKDgmePHBjwBw5S+FBo1d5U3oSfPRANxNyi/iVPcub2jnluc/Q9fhimMLuXhhQfcLK/sM0CG5KPiHUxDGE/Eh4iNrFtgcfbo8mHYJ8XyI4VQQopI+RT5eeOEFnnnmGZ599lk2btzIE088wa9+9SueeOKJfi/gBz/4AQ0NDYGf4uLuq0YGyqf7a6ikw8CrWRcEH5/6Y5hxrqo6ef5KaDgSPGaIj7hpJ6Np6htWtcsW/MYWknq57Z+fU9PiZlZuEned34tvcIGUi0Q9hHFKaNqlj34PCEm7tHqCaZfmyk4RSUEQRp4+iY/bbruN22+/ncsvv5x58+bxta99je985zvce++9AOTkqDLWiorw2vqKiorAsY44HA6SkpLCfoYKn19n7YFaKvTQsd8TIWde8HeLBb74J8iarXoEPH8leNpUD45i5W2xTzmJiUZzo90RTKclda2s2lONRYPfX7kwYk+CMJoqYOe/1WPxewjjldC0S+6CPl9uVrvUt3nQTfOq36Mq2QRBiCr6JD5aW1uxWMIvsVqt+I0BTpMmTSInJ4eVK1cGjjc2NrJmzRqWLl06CMsdGNtLG2lyeWm0hXzDmnVB57JWRyJc8Rw401Q65F83Gn6PNvXtLHMG07MTANhVHuL7MHp9vLVVpZgWT0xjcmZC1wtqLIP/3A6/mw8la0GzwpRTB+vlCsLoIj7k/8vcvjfZS3aqyIfPr9PotUFssjogqRdBiDr65Pk4//zz+fnPf05RURFz5sxh06ZN/OY3v+Gaa64BQNM0brnlFn72s58xbdo0Jk2axB133EFeXh4XXXTRUKy/T3y6vwaArLyJUGbsnH1h5JNTJ8KXn4InL4StLwU7j048HjSNGdmJrNhWETHyYYqPc+ZGjvbQcAQ+fhA2PKHSOwCFS+DUH4VHYQRhPGH6NCy2fk10jrVbcdqttHl8NLR6SI7PUj6s5gppsS4IUUafxMfDDz/MHXfcwbe//W0qKyvJy8vjm9/8JnfeeWfgnO9973u0tLRw/fXXU19fzwknnMBbb71FbGzsoC++r5jio3D6fGjOhaQ8yOvGYzHxBPjCL+GN76hWzQATTgBgRo5KD+0sb4KFQfFR2djOhsMqzNtJfDSUwEe/hY1Pgs+t9hUthZO/D5NPkcZiwvgmdRIcfwukFIG9f38vUuPstDX4qGt1UxRosS4VL4IQbfRJfCQmJvLggw/y4IMPdnmOpmn89Kc/5ac//elA1zaomH4PgGOmFcCJmwFdeTy645hroGIbrPur+n2iKT5UOmVPRRP+pAKVv2ooYcX2CnQdjipMITfZqa6pPwyrfgObnlY5aFAi5pTvw8QTRXQIAqj/D84cWOVbSlwMpQ3tquJFWqwLQtQybma77ChTfo9Eh43ZuUlg7YPd5Zz7jEiFpkoAUXNeYqwWWtw+qixZZIMSH6Epl7qDSnR89mxQdEw8EU65PSBiBEEYPFLjQ+a7JBgl/xL5EISoY9yIj+ykWO6+YA7NLi+2vggPAKsdLng4bJfdamFyZjw7y5vY3Z5MNqA3lbK2uhKw8OX2F+HhX4Lfqy6YfIpKr0xYNhgvRxCECKQ4Q+e7GJEPER+CEHWMG/GRmejgG8smDuo9Z+QksrO8iS0NMZxojUHzucn015CflU7qpw+A7oMpp8HJt0PRkkF9bkEQOpMS2uU0TVqsC0K0Mm7Ex1AwPVu1S99d0YKelI9Wd4A8rYbrsyqh0Qc58+Frr4zwKgVh/GD2+pC0iyBEN33MPwihzDDEx7qDdWxpVo/zLdUsa/9QnTDn4pFamiCMS4KRD0m7CEI0I+JjAMzIUYLjSH0bu9tTALhxRjNxR4yZMXMuGpmFCcI4JTjfJaTFekuVtFgXhChDxMcAyE9xkpGghl/FZU4AYNqRV0H3q3HgaZNHbnGCMA4xJ9vWhw6XkxbrghB1iOdjAFgsGs9ffxwNbW4WVVfD60+Bq1EdlJSLIAw7KQHx4VFTcWOTjS6nlRCXNsKrEwTBRMTHAJmaZcxu8RSEH5CUiyAMO8G0i9FB2Gyx3lIJzBy5hQmCEIakXQYLc7gcqJbtqRNHbCmCMF4xq12a2r14ff5g6mU0mE79/sB8KEEY64j4GCyS84OPJeUiCCNCUmwwmKvKbUNMp9HO2j/Db+cERzkIwhhGxMdgERMPWXPAHi/iQxBGCJvVEhAgYRUvzRUjuKpecsiokvvgl+B1jexaBGGIEc/HYPKN18DdAimFPZ8rCMKQkBofQ2O716h4MXt99C/y4ffrHKlvC1TqpsTbSYq1D9JKO1B/WG2by2HLi7Dwq0PzPIIQBYj4GEziM9SPIAgjRkpcDIdqWlXFi9nltJ8t1m98diP/MYZFAsTYLLz1vycyOTNhMJYajik+AD5+CBZc2fPUbUEYpci/bEEQxhQpzpAupwNIuxysbgkIj7gYK1aLhtvr59P9tYO21gCuZmgz7muPh+pdsOe/g/88ghAliPgQBGFMkRra62MAaZfn1xUDcPL0TLb/9ByuMgZT7qtqHpR1htGgnovYZFh8rXr88e8G/3kEIUqQtIsgCGMKs9dHfZs7PO2y+QX4/Hmo2qW6EKOrra53+l3X/fw/l5f/5/Cj1xdC638DPX2GRHyYKZeUIjjuW/Dpo3B4NRSvg8LFg/98gjDCiPgQBGFMERwu54F4I/Lh98LL/9Pre2hAgvmgcQ8Ur2VK5rEA7K0cSvExAZLyYP5l8NkzsPp38OWn+31bXdfZeLiOmTlJxDvkz70QPci/RkEQxhRmo7H6VrdqsZ45C6p2qA/2BVfA1DPAagdNA80CGNuQ3//vn1tYf7iOZ9L/Tn7zFnA1MSU/HlCDJNvcPpwx1gGv1evzU9bQTqEpPsxmhctuUuJjxxtQsw/Sp/Tr/iu2VXDD0xu44thC7v3i/AGvVxAGCxEfgiCMKcLmuwB8/V/KcJozTwmMHjhU08I/D+1B03JJzcqH5i3gaiAtPoaUODv1rR4OVLcwOy9pQOvcUdbId1/4nO1ljayatItCUGkXgKxZMO1s2LMCVj8M5z/Yr+fYcEiZWLccaRjQWgVhsBHDqSAIY4rgfBdDfCRmQ+78XgkPgOfWKvPnSdMyiUs0htG5mtA0jalGie3eAfg+vD4/v39vLxc88hHby9QgytbK/cbii4InHv+/avvZs/1uD7+zvAmAwzWt/V6vIAwFIj4EQRhTBKtd3H2+1u31888NSnxccWwROBLVgXYlEqYY4mPfAHwf97+1k1+u2IXHp3P6zCxirBbSvEYpcGiDwgnLIP8Y8LlU6/V+sLtCiY/Gdi8NphgThChAxIcgCGOKoOej7x+27+yooLrZTVaig9NnZUGskVpxGeIjS/k++lvxUt/q5ulPlb/jnovm8tdvHMMXZiaTqan7h0U+NA2Ov1k9XvsX1Qukj89V0Rhs015aWgz/+CrsXtGvtQvCYCLiQxCEMYXp+Wjz+Gj3+Pp07bNrlDC47JhC7FYLOEzxoSIIZuSjvxUvz60tps3jY2ZOIl9dUoSmaVwxXR1rwonb1sFHMvM8SJsM7fXw+XN9eq5dRsrFxLbhr7DjdVj5036tXRAGExEfgiCMKRIcNmwW5e+obel96uVQTQsf7a1G0+DLi430R4e0i9nr40B1Cz6/3qd1eXx+nlh9EIBrT5iEZnhQjklRQqbEn8G7uzo0Q7NY4Rij6diuf/fp+XZVhIuP1OJ31IOKrf2edSMIg4WID0EQxhSappGTHAtAWUNbr68zO5qeOC2TwrQ4tTM2PPJRkBpHjNWCy+untL739wb495YyyhvbyUhwcMFReYH91kb1vCV6Jv/cUNL5wimnqe2hT/o07daMfNitGvlUkdG8K3jwwAd9WrsgDDYiPgRBGHMUpDoBKKnrnUBwe/28uF6JgCuPDfFdBNIuqlTVatGYlKF8H32peNF1nb99dACArx03AYctpEeI0eOjRM/kvV2VVDV1EBhZs9SMGm8blKzr9XOa4uO4yemcYd0YflDEhzDCiPgQBGHMkZ+iIhe9FR+m0TTTNJqamOLDSLtAMPUSqHgp2QDv/ATcXZezbjhUx+clDcTYLHzluKLwg8ZcFz25EJ9f57XPS8OPaxpMOkk93t870aDreiDtcsasbM60rFcHJp3cp/sIwlAh4kMQhDFHXyMfz601jaYFymhq0iHtAjAls0PFy3s/h49+qxqCdcFjRtTj4qPyyUhwhB80Ih+TpswE4D9byjrfYLIhGnoZsShraKep3YvNonHaRAdLLDsB8J5xD1hsUH8I6g726l6CMBSI+BAEYcyRHxAfPTfXOlzTyqo9ymh6+eIOUQnTcOpqVAPogCmByEeLOtZaY2xrI96/uLaVFdvKAbjmhEmdTzDEx7y5qv35hsN1VDa2h59jRiyObAgTQl1hRj0mZcSTX7UKu+Zjtz+fMuc01TsEJPohjCgiPgRBGHOYkY8jvTCFPrdOffiHGU1NzLSL3wteJQimdOxyaoqBLkTB31cfxK/DidMymJGTGH7Q065avwMZBdNYWJSCrhMQKwFSJ0DqRLWOQ6t7fE27Db/HjJxELLtVlczb/kUU17b2OYoiCEOBiA9BEMYchalKRBypa0PXuy6JDTeaFnY+ISYBNdqWgO9jspF2qW1xq1JetyFC3J0NqE3tHv5hVNFEjHo0GNUt9nhwpnLOnBwA3uooPqBPfg3TbDor0wF7VInt275jOFzbCpNPUScd+DAQzRGE4UbEhyAIY46c5FgsGri8fqqbu+71sTLMaJrd+QSLJTz1AsTF2MhPUZGVfVXNwc6jETqQ/mNdMc0uL1My4zl5Wmbn+9cfUtuUItA0zpmrxMen+2up69ijpA8RCzPtcpxlB7ibaLSl87k+WYmP/GPAHgctVVC5vcd7CcJQIOJDEIQxh91qISdJ9frozvfxbFdG01Ac4S3WAQrTlPgorWsGj+H96JB28fl1/m40FbvmhElYLBEG2xl+D7Ot+oT0eGblJuHz67y9vSL83IlGxUsPTcK8Pj97jEqcyZ7d6pL049CxKPFhi1FzY0B8H8KIIeJDEIQxSX4PFS/dGk1D6dDlFCDZabRwbwoZVe8OFx//3VZOSV0bKXF2vriwIPK9jTLb0IFyy+d2kXpJyISsOerxwQ+7XO6h2lbcXj9Ou5WUFlVlo2fOAJT5FQhJ4bzf5X0EYSgR8SEIwpikwPR9dGE6fb47o2koEcptU5xqeF1rc4j46JB2Mctrv7KkCGeMlYjU7FXb1ImBXab4+GhPNU3tHYbjTe7Z92H6PaZnJ6AZ93fmqjLew6b4MLumHlylTK+CMMyI+BAEYUxi+jIipV08Pj8vrFdmz4hG01AipF2SjeF1rpbgvlBx8nlxPesP1WG3anx96cSu712xTW2zZgd2Tc1KYHJmPG6fn3d3VoafP6ln38duw+8xLSsBqvcAkDZBRUzqWj00tnsgew4k5oKnFQ73XD0jCIONiA9BEMYkgXLbCGmXd7ZXUN3s6tpoGko3aRdPa2jaJRj5MKMe58/PI9vwnnTC3Qq1+9Xj7LmB3ZqmBVMvWzukXiYsA82qGoTVHYp4W3Pi7oKUdpUK0izE50wjLV5Fa4prW1XX1KmnqwuMahhBGE5EfAiCMCYx0y6RPB+9MpqaREi7JBniw9cWGvlQH/plDW382+hSGrG81qRqJ+h+iMuAhKywQ+fMyQXg/V1VtLl94WvJX6QedxH9MMXHHIdhWE2dCDZHILUU8H1MPdO44O2u1ygIQ4SID0EQxiShhtPQXh+m0RR6MJqaREq7mOIjtMLFOP7E6kN4/TpLJqUxNz+56/uaKZfsOSoSEcLc/CTyU5y0eXx8sLtDZUs3vg+vz8/+alV9M1E3ZsRkTAegKCA+DDE2+RQVRane3WUURRCGChEfgiCMSfJSVLqjzeOjrjVo3AwaTTO6N5qadCM+wspr3c20ujyBOTHXdhf1gBDxMbfTIS2k58dbWzvMegn4Pjo3CSuua8Pt9RNrt5DSdlDtTJ8KQJFRHhwwnTpToHCJeizRD2GYEfEhCMKYxGGzkpWohriZptNQo+lXlvQi6gHBtEsEz4cW2tXU7+WVdftpaPMwIT2uZy9JxVa1zZ4T8bDp+1i5oxK31x88UHgs2JzQUgmVO8Ku2WOYTadkJmAxzKYdIx+HakMMuNPOMC4U34cwvIj4EARhzNJxuq1pNM1I6IXR1CRC5CPFEB+WDi3VV+84CMBXl0zAGqmpmImuh6ddInB0USqZiQ6aXF4+3lcdPGBzQNFx6nEH34c5b2ZqSKULGdMAAlGeklDxYfo+DnwIXlfX6xWEQUbEhyAIY5b8kBkvAM+s6YPR1CTQXj2YYjEjHw5/eBmv2XRsanZC9/dsKoe2WtAskDkz4ikWi8bZc5RAemtLh6qXLnwfeyuU+JiVbgs2MOvo+ahrxec30jU58yAhR3Vp7cXAOkEYLER8CIIwZglGPlp5b2clH+2txmrRuOLYXqZcIGLaxax2iSe8ksbTWg9ARryj+3uaUY/0aWDvohQXWD5XVb28vaMCry8k9WL6Pg59DD5vYLcZ+ZjnrAZ0cKZCXDoAuclObBYNj0+nvNFoLKZpMNVIveyV1IswfIj4EARhzGKKj71Vzdz5mvJYXHP8xN4ZTU0iRD6sFo1Eh40ELbw7qK9dnZOeENP9PXvwe5gcOymNlDg7tS1u1h6sDR7IXQCxySoVVLoJAL9fD5TZTtGMSpf0aYFKGqtFC7wfh2si+T7EdCoMHyI+BEEYs5hdTj/eW0NxbRu5ybHccsb0vt0kgucDVPQjoUPkw+FXv5sNvbqkB7+Hid1q4UzDm3LHq1uDreItVph4onp84H0AShvaaHX7sFk0Mt3hKReTTr0+ACafapTc7goOuhOEIUbEhyAIYxaz0ZjJXefPJt5h69tNYo1eHe5m8AcbfiU77Z3SLom0keCwEWvvYpaLSTdlth256bRp5CbHsq+qhS/+4WN2lhsiaPIpamv4Psyox6SMeKw1ptl0ati9JqSr9+NwqPhwpqgKGpDohzBsiPgQBGHMYkY+AE6bmcXZc3L6fhMz7QKdTKeBtIumxEa81tZz1MPrVlEG6DHyAVCUHsfL317G9OwEKhpdXPrHT1izvybo+yheC562gPiYmpUANeFltoF7pUUQHyC+D2HY6ZP4mDhxIpqmdfq58cYbATjllFM6HbvhhhuGZOGCIAg94YyxsrAohbT4GO6+YA6a1k35a1fYHGA1DKSh5bZxIWmXRCVq4mnv2e9Rswf8XnAkQ3JBr5aQm+zkxW8uY/HEVJravXztb2t5qzxBDYfzueDwpwHxMS0zLqTMtpfiY5pRcrv/Aym5FYaFPomPdevWUVZWFvh5+20Vorv00ksD5/zP//xP2DkPPPDA4K5YEAShD7zwzaV8+L1T+2Yy7UiE+S7JTjvxZuQjUVWlJGptpPfa7zG7U1v17kiOs/PUtUs4a3Y2bq+fbz27iX2JwTkvewzxMTepVU2rtdjUXJcQIno+AHLmQ0K2Krk9/Emv1yQI/aVP4iMzM5OcnJzAzxtvvMGUKVM4+eSTA+fExcWFnZOUlDToixYEQegtdquFhL76PDrSxWTb+E6RjzbSeyyz7V2lSyRi7VYe/eoirlxShK7DHw6qyIm+/4NAd9MZVqMnSOoksNrDrjfFR02Lm2ZXsEQ3rORWfB/CMNBvz4fb7ebpp5/mmmuuCQtlPvPMM2RkZDB37lx+8IMf0Nra2s1dwOVy0djYGPYjCIIQVUSoeEmKtZGAEflIygNU2iWtp7TL4TVqm7ugX0uxWjR+ftFcvnPGdD72KwGjl34G7Q1YNMhv2KBOzOhc1ZMUayc1TgmSsHJbEN+HMKz0++vAq6++Sn19PVdddVVg35VXXsmECRPIy8tj8+bNfP/732fXrl28/PLLXd7n3nvv5e677+7vMgRBEIaeCL0+0mO8WDSjU2hv0y7tjVCyTj2edHLX5/WApmn87xnTyEx0sP/NXCZbyjjOsp0jKYuwrf+rOmn+pRGvLUqLo661gcO1rczOC4lMTzlVdVyt2gn1xZBSGPnJdR12vKZ6iGTP7vdrEMY3/Y58PPbYYyxfvpy8vLzAvuuvv56zzz6befPm8ZWvfIUnn3ySV155hX379nV5nx/84Ac0NDQEfoqLi/u7JEEQhKHBLLdtbwjsSrMrY6YfC8RnAirtkpHQTdrl0GrQfSolkjphwMu6ckkR9mmnALDMso3rYt4BVwNkzoJZF0a8pkvfhzMVCoyS266m3Oo6rPgRvPB1ePn6Aa9fGL/0S3wcOnSId955h+uuu67b85YsUeOa9+7d2+U5DoeDpKSksB9BEISowtHZcJpqVeKjFWfAkBqvtXdfarv/fbU1e3QMAoWLlgOw3LGF81pfUTtPvg0skf+8d1nxAj1PuX33Hvj09+pxc3nkcwShF/RLfDz++ONkZWVx7rnndnveZ599BkBubm5/nkYQBCE6CKRdQkptDfHRQizEqEFyibR1X2o7BOJDdTrVyPaVYXc3KK/H7Iu6PD1iozET0/dx4APVjySUD34Jq34d/N3dvZ9PGEb8/p7PiTL6LD78fj+PP/443/jGN7DZgpaRffv2cc8997BhwwYOHjzIa6+9xte//nVOOukk5s+fP6iLFgRBGFYiDJdLtCizaZMei9+uxEe31S5NFVC1A9Bg0kmDt7a4NMgN+Rt70vdU+/Uu6DLtApCzQKWQ3M3hJbcl6+G9n6nHy25WW0+rSsOMZzztsO+9sM63w07lTrh/Arx//8itoR/0WXy88847HD58mGuuuSZsf0xMDO+88w5nnXUWM2fO5Lvf/S6XXHIJr7/++qAtVhAEYUSIkHYxG4w16U7q/EpwJHTX4fSAaoNO7nwlGAYT07yaPg3mfrHbU820S0ldGz5/B/FgsYRUvYT4Pja/oLZzL4GTv2fs1MEbPlhv3PHKN+Gpi2DLiyO3hm2vqIjcnhUjt4Z+0Odql7POOgs9gtotLCzkgw8+GJRFCYIgRBUR0i5xuhIfzXosh5sspAMJWjsxti6+0w1FysVk6Y3QWArHfavbqAeobqk2i4bb56eisZ28kBb0gBIfnz+nfB9n/Ux9q9/+L3Vs/pfBHtKszdMG9g7XjxdKP4Ptr6rHZuO4keDwarVtqR65NfQDme0iCILQExE6nFo8qqNoC072Nak/pTF4I7cn1/WhFR+JOfClx6DgmB5PtVo0ClKVYDjUsdcHwJTTjJLbHdBQotIvzeWq4mfyqUrcmO3m3S2D+SqGj/YGOPwptNT0/x7v/SL4uGmEzLdeNxQbpdujTHwMsO2fIAjCOMBMu4SU2ppCpBkne+pDosGuZjUPJpSavdB4RH1oFy0d4sX2TGFaHAdrWimubWXplPTwg3FpkH8MlKxV3U7Lt6j9M88Hm5FSsjvVTBlP+FTfaGPDoVo2lzTwteMmYLOGfNd+8SrY9656nJgHOfMgZ66xna9KobuoFgLUML/QNEdT2ZCsv0fKPgev8d/A06LEYEz8yKylj4j4EARB6IkIHU5xqchHsx7Lvup22vQYnJob3E0Q3+ED3Yx6FC2JijRFt+W2oAbNlayF3SuCTdHmXhw8HhMP7fXqAy9K8ft1vvX0RiqbXFQ0urh9+Ux1oLE0KDwAmkrVT6iYsMer9vc584I/WbMhJo52jw//ip8SB8pjU7Nn5CIfhz4O/72lWsSHIAjCmCFC2gW3mXaJZX9VC804ceIOiJIwhjLl0g9M8XGwpgvxMPUMeO/nsPs/6ndnWnhHVlNARXG57cbDdehN5czT6vjjB3DMhFTOmJ0NO95QJxQcC197GSq2Q/lmFeGp2Kr8G54WJb5K1gbup2sWah1FbGlP5xQ24NfsWJbfD09/ceQiH4dWh//eWj0ozeuGAxEfgiAIPRE6WE7X1SA2M+2ix3G4tpVmWyyZWkO4QAFl2DywSj2edMqwLbk7ZuUqMfXfbRVsPdLA3Pzk8BNyj1Ilty1VxgXnhw+pM02nUZx2+c/Wcn4f8xDHWnZxpfuH3PqCjTdvPpFC0zw75yL137Voifox8Xmhdp8SI+VbaDy4Ecq3kOSrI739IKdwEIAt2RewoNC4zt2s/rub/06GA79P+VYAbE6VfhlFvg8xnAqCIPSEmXbxe4KG0oDnIxavX6cFMxrQIfJR+plqee5IhryjhmW5PXHitAzOmJWF2+fn5uc20RI64RaU32HK6cHfO5bvmqH9KE276LrOW1vKmKcdAOCH8a/T2O7lh0+tRDdTFbMuiHyx1YYnbRqv+5dx8Z6zmL/vBua3/J7F7X/gF2k/45+p1/FH73m8lHoNOBKC/zaGO/VSuV39u4pJCIonUyyOAkR8CIIg9ERMAmBM7zZ9H2baRY8FlPFUHe8Q+dj/ntpOOrHHMtjhQtM0fvmlBeQkxbK/uoU7/xWhVHTamWoblwETTgg/ZqZdojTysfVII+6GcuXBAeZ6tnCKcy9Fle+ioUP+ooiD8+pb3Tz6/j5OeuA9bnpuE5sO1xNjtXDJ0QU8ftN5/PDmm9CPv4X7vFdysMUw3ybmqO0QpF5aXF4eeGsn+6sipPIOGU3gCo8NDDYcTeJD0i6CIAg9YbGokLqrUaVeErLCql1AGU+BCOLjfbWNEr+HSWp8DL+7/Ciu+MunvLSxhBOmpXPxwoLgCbMvUt+uJywDa4ePCjPtEqWltv/ZWkahVhm279c577CjRJXWbks5hTkhx/ZWNvG3jw/y8sYS2j2qVXlGQgxfWTKBrxxXRFZibODcnGT1uLzBEF6JOVC9e0giH8+vK+YP7+9je1kjf7/62PCDZgSnaJky/8KoSruI+BAEQegNjiQlPszIh1ntYoiPiGkXdysUr1GPJ586XCvtNUsmp3Pz6dN48J09/PiVrRxVmMqkDCOlYrXB6XdGvjCKPR+6rvPW1nLmm+IjbTLUHSK97EOOt6ro1Xe2TOD3JzVRUt/G4x8f5MPdwYjB7NwkrjlhEucvyMVh6xypyjXER1mD0d3VjDoMQeRjd7kSsusO1OL1+YPlwroebH8/YVmwIknEhyAIwhijY5fTjmkX3Uy7hIiP4k/B54akAkifMlwr7RM3nTaNT/bVsOZALTc9t5GXvrUs4oduGDGm+Ii+apc9lc3sr27hArshKIqWQcFi2PwPNHT226eyuymD5b9bhddoL69pcOasbK45YRJLJqWhaVqX989OUv+9m9q9tLi8xJtpl8bBFx/7jHRLi9vH1tJGjipMUQdq90NzBVhjVAqp7qDaP4rSLuL5EARB6A2J2WpbX6y2hggJpF2IDdsPhKRcTlafcFGI1aLx4OVHkRpnZ+uRRh54a1fPF0Vx2uU/W1T645hk479D6kQ44dbA8awll5GV6MDr10lw2Lj2hEl88H+n8uevH8Nxk9O7FR4AibF2Ehzqe3t5Y7tqUgZDEvnYF+L1+HR/SDdWs8Q2fxHYY1VlEoj4EARBGHNkz1Xb8i0q7B1oMqbEh89upCtC0y5R6vfoSG6yk19+aQEAj310gJU7Krq/IIrTLiu2KfExPcb4sE6dCFkz4bhvQ9oUEo79Ov+8YRm/u/woPvnBadxx3myK0uO6vmEEspNUB9uKhvYQw+ngej5qW9zUtXoCv6+JJD7MbrlmU7vWAbSLH2ZEfAiCIPQGU3xUbFXTXHU1Rr3FiHjoMWZaxjCcttRA2Wb1OLRBV5Ryxuxsrj5+IgD/9+LnlJuehkgE0i7RFfmobnaxvUxFPNI9RiTCbLp1zr1w80ZIyqUoPY4Lj8onMdbexZ26JzdZCc6yhvYh83yYFS42i4rErDtYh9enzLCBYXITjlfb0MhHhMGv0YiID0EQhN6QY0Y+tqqKFwNTfFgCnhAj8nHwQ0BXbbnNlE2Uc/vymczJS6Ku1cMt/9iEz9/FB1mURj7M1MTc7FisTaVqZ+rEQX8e0/eh0i4hkY9B/OA3Uy5LJqeRFGuj2eVlW2mjag9fd1AN/ys0KmDiMtTW5w5P+0UxIj4EQRB6Q8YMsNhVY6eqnQDoMQnqQwCwxRnNpsy0y/4P1DbKUy6hOGxWHrnyaOJjrHy6v5bfv7c38okBz0d0GU5X71Pi45wCL6CrdZpRgUEkN1BuGyI+fC5oqxu059hXpaJK07ISOXaSSqusOVATTLnkzAu2/Y+JM3rREF7xUrEd2uoHbU2DiYgPQRCE3mCLgcwZ6rFR5qjFJJBomA/tzg7D50y/xyhIuYQyKSOen12sojwPvrObtQdqO59kj85ql9V71Qfv8RmGAEyZMCRG3+zkkMiHzaFm38Cgpl72VarXMCUznuMmq/t/ur82xO+xLPyCOMP3YYqP0k3w6DJ4+X8GbU2DiYgPQRCE3mL6PsweC44EkuOUbyA2IUXtczWrsHjdAdCsMPH4YV/mQLl4YQFfPDofvw53/mtr5xOisNT2SH0bB2tasVo0ZsWGmE2HgNykkMgHDInvY3+1inxMyUzguMlKWKw7UIse2t8jlI4VL4dWAzrsfWdQIzKDhYgPQRCE3mL6PoqNpk6ORFKcqs220xQf7uZgyqVg8fAOGxtE7jpvDjFWCzvLm9hZ3sFHEIVTbc2ox/yCZGKbS9TOIZrwmhMa+QBIMsXHIFS8FK9D/9UMFtW/BcCUrARm5SaRGGvD6qpDq9yuzjMrXUw6io/KHWqr+2HfewNf1yAj4kMQBKG3mJEPs8ojJiFQppmbZZj+XE2jpsS2O5Lj7Jw6U32g/euz0vCDZllxFEU+PjH8HsumpAebbg1R5MMUH9XNLtxe/+DOd9nxL7Tmci7QPiLBYSMr0YHVonHsxDSOsexW52RMh4QOXpZ449+fmXYxfEmAin5EGSI+BEEQekvOvPDfHYncc+Fcnr52CYunF6l93vbgMLlRLD4ALliQD8Brn5Wih1ZyBAbLRYf40HWdj/cZfo8pGVB3SB1IGZrIR1pcDHarhq5DZVNouW3/Ih9+v86WkgZVXVSlmrxNt5QwOTM+0PTsuMnpHGsxBEXHqAcExUdrtaq6qewgPvz+wK9bjzTg76qSaZgQ8SEIgtBb4jMgISf4uyORtPgYTpiWgRaaXmmrU9UHBccM/xoHkdNnZREfY+VIfRsbD4f4BmLMyEd0lNrur26hotFFjM3C0RNShzzyYbFogXLbio7ltv3g1c+OcP4jH/GT17YFREOOVsfctKBAWDI5LSA+/B3NphCedmkoAXcTWGwqStVcARVbADhY3cJ5D3/Eab9+n3aPr1/rHQxEfAiCIPQF0/cBwfJGUNUwVkfw9wnLwNq/JlbRQqzdytlz1AdrWOoltL16FDS1Mv0ex0xIJdbbFJzyOkSeD+gwYM6MfDSWdnNF12wuaQDgX2t3Q8PhwP5FzqCYmZ1uYa52AIA9sR0icBAuPsyUS/o0mHSSemykXv65QflhJqTHE2vvYYbPECLiQxAEoS+Epl4cCeHHQn8f5SkXk/OPUrNL3txcFuywaaZddB/4PF1cOXysDvV71Bspl/jMYIRmCMhOitDro5+RD7NqZoJ+JGz/DEtJ4LGtdD02zU+JnsGqKmfnm4SW2ppm06yZMO0M9XjPO/j8Oi9tVPe89JiCfq11sBDxIQiC0BeyQyIfHStZQn8fI+LjhKkZpMXHUNPi5mPjQz7sQ32EW6zvLG9k5c5KAI6fmjHkKReT8EZjxnC55grw9zKV4WqG0s/A5w1UzUzXSsJOyfccDP5ySJXYrvPPUP0+OhKIfISIj8xZMPVM9bh4DZ9s309ZQzspcXbOnD2yXXdFfAiCIPSF0MhHTAfxYf4en6naqo8B7FYLX5hnpl6Mb+ZWu/ITwIiW27a5fdz07CbcXj+nzshUI+eH2GxqEtZiPT5TdbrVfeEdRkPRdajeC5/8Hp68EB6YBH8+GT7+bSDysSBWRU7qdBVBS24K6TBrNBdb65/JuoO1nQ2jpvhorYbKbepx1iyVesqYDrqPnR+/BsBFR+XjsI1cygVEfAiCIPSNtClgUx88XaZdJp8yJJ01R4pz5ihPw7qDId+47SNvOr3nze3sqWwmM9HBry5doCpDhi3yoVIf5Q3tYLVBfJY6EFpu62lXXot/fw8eWgiPLIIVP1Sl2D43APq2f6mKGeCsTGXqXeFTRmVL5XYlWrwuOLIegG22OTS0edjRsfeKmXbR/fjLjcZwWbPU1oh+ZBxZCcCXFo1sygXANtILEARBGFVYbSr6UbIuONDLJMkIv087a/jXNYQUpKoP2ppmd3Cn3anm3IxQ2uWtrWU8u+Ywmga/vewo0hMMs6/p+Rhi8ZGTrJ4v0GgsMQeay5VIOLIe9rytms15Q8SZxa463k47C/IWwuPL0Sq2kKw30mRJJtt1UL02/7FcxgdY2mqVgbR2vyrhjksnLWMu7K5mzf5a5uQlB+9ti8FtTyLG04hF96FbY9BSJ6ljM5bDp7/nIssqmlKKmJv3hSF9b3qDiA9BEIS+8oVfwt6VMOW08P1n3wszz4XZF4/MuoaI9ATVxbXV7aPN7cMZYw1psT78kY8j9W1875+bAfjmSVM4YVqICKzeo7ZDWOkCkGNEPioa2/H7dSyJuVD2Gbz53fATE/Ng2plKcEw+OdwXlDkLqnaw1LKdXYlL0epVpYs7ewFtngnENx9U/o0jG9T5RUs5LjeD93dX8+n+Gq45YVLYUzVZU0j3qIiIO2UKDqvxET/xBJ53fpnL2/7B19qfgTcd8IVfgWXkUi8iPgRBEPpK3kL105HEbJh7yfCvZ4hJcNiIsVlwe/3UtLgoiIkLpl3cwxv58Pr8fOf5z2hs97KgMIXvnjU9eLBqt4p8WOyQu2BI15GV6EDTwOPTqWlxk5m7AHb/R3k/Co6F6WcpwZE9t+sU3OSToWoHx1u2ER8/FVw6xKXz7P+eB88/BzsPKvFhDpObcDxL8tWQubWG78NiCd67Wk/CSL5QbJvIVOPx9rImbq+7kF32OO60/h1t/d+guRIueQzssUPy/vSEeD4EQRCEbtE0jYx4Ff0IpF4CXU6HN/LxyHt7WXuwlgSHjYcuPwq7NeRjbNebajvpJIhNjnyDQcJutZBhpHoqGtvhhO/ANSvgtn1w7Qo48bsqPded98eYeLzMspW5MYZXJNPwaZh+jYotULxGPZ6wlLn5ycTHWKlv9bCroinsdqXuoAdpQ1uwmuWF9cUAVM78OtqlfwdrjOpJ4vf289UPHBEfgiAIQo+YnoqaFpfa0Z/JtroO798H79/fr/4gaw/U8tBKlVb5+cVzmZDeoY/HTkN8zDy3z/fuDzlJIY3G7LFQdBzEpfX+BhOPx4+VSZYKFrmN1ErmDLU1xceON8DVqCqpsudht1pYNFE9x6f7awK3amj1UOoJvh/v1abT1O6h3ePjlU2qSumyxYUw5yL4xuvwlRc7G6aHEREfgiAIQo+kGZGP6kDkox/io3wzvH8vvP8LVW7aXNXrS+tb3dzy/Cb8OlxydAEXHpUffkJTuTIBA8wYHkOlOWDuTx/sY+2BCL03eiI2mUOxSmzMqntX7cucaWwN8WF2ay08VpmdgeMmK/GxJqTfx+7KJqpJCvy+w5fPx3trWLGtnIY2D3nJsZww1fDGFB0XnAUzQoj4EARBEHrENJ3WdBQffenzseP14ONDH8OfT4EjG3u8TNd1bn9pC6UN7UzKiOfuC+d0PmnXv9U2/5jgiPshZvncHKwWjfWH6rjsT59w6R9XU1zbt74nG63zAbDqRgokyxAf6VODvVRAtes3OG6ycnasOVAT6Pexq7yJGl2JD4/moFjP4v1dlYGUy6XHFGK1RE/5t4gPQRAEoUdMf0NNs5F2CXg++mA43a6aXHHS99TckcYSeO4K8IV7D376+nZueGoDewxPw7NrD/PWtnLsVo2HLl9IgiNCrcQwp1wAvnh0Ae999xSuXFJEjNXCuoN1XPvEOlpcvfdSfODt0IzOjHzYYpQAMQkRH/Pyk4mLsVLX6mF3pXqP9lQ0UamnAtCeOh0/Fv69pYyP99agaSPfTr0jIj4EQRCEHkk3DactRuSjr5Ntq3ZB9S5VibL0RviflaoypLlc9bIwaHF5+dvHB3hrWznLf7eKH76yhXve2A7A98+ZybyCCEbS9kbVUwNg5nn9en39pSg9jl9cPI93/+9kshId7K5o5nsvbUbvxcA9v1/n3eaJtOvGAEJnWrBTKQR9H1YH5B0d2G23Wlg0QQkNM/Wyq6KJ9/xHsWfSV3F84ec47VYa25UIOmFqBgWpcYPwagcPER+CIAhCj5iG0+qOkY/epl3MlMvkk8GZoqpRAsPQguKjtD4oZrx+nYIND/CS9n1eTP0D17Y+DusfV0Kjvhj8xqC7vW+D36OiKZkhpbfDSEFqHI9+9WjsVo03N5fx5w/393hNbaubZp+N9bphMs2cGV4dY7boz1/UqSTWTL18ur8GXdfZVd6EixjaT/8FMVNPVnNuDC47pnBgL24IkD4fgiAIQo909nyYkY/I4kPXdepbPRypb+NIfRuL1v2TDOCZxgX4PjnI15dOVC3JW6qgpTJwXYkhPmbmJPL9s6dx8j++ggUd2g7BJx+FP4nVoTqZmmsYxpRLJBZNSOPO8+dwx6tbuf+tnczOS+LEaZldnm/OdPnYtpQT/FuVETSUo7+uPDFLv93p2oDp9EAtVc0u6lo9aBpMzVIVLKfOzOSdHRWkxNk5a87IDpGLhIgPQRAEoUcy4rsvtdV1nT+8r6o+jtS3UVrfRqtbTXgt0Kr4yLEDn67xm8NTqSvexpcXF+IwKy5ChrGZkY+CVCenTnAARvrinPvU3Jba/eqn7iD4XCqVYzLrgqF46X3iq0uK2Fxcz4sbSrjpuU28/v9OoDAtcsqjzBAfq1MvgPMvUhGOUBJz4MrnI147Lz8Fp91KbYubNzerHiET0uJU91ng4oX5bDpcz2kzs0Z8iFwkRHwIgiAIPRIa+dB1Ha1Dk7E9lc38csWuTtdlJDi42rEFWqAk8SgavSn4fTrVzW7yE4xhbM3ByMeROnW/vBQntBqlpDGJcNy3wm/s8yrDqilG4jKgoMOH9wigaRr3XDSXXRVNbC5p4IanN/DSt5YRa+8sAMy5MNnJcTDxmD49T4xN+T4+2lvNU5+oeTbTs4Ot2+NibPzq0qHt8joQRHwIgiAIPWL2+fD6dRrbvCR3aK9+oFptJ2fG89ML5pKf6iQ3OVZ96D72S2iBCSdcTsZ7Dsoa2qlqcpFvToKN4PnIT3FCmyE+4lI7L8hqUymX1ImdZ+yMMLF2K49+dRHnP/wR20ob+eHLW/j1ZcbU3RDKG9RrzU3uX4vz4yan8dHeavYb7/2MnMQerogexHAqCIIg9Eis3UqiUeJa3eIKKbVVaZfDNWo7Jy+ZE6ZlMCkjXgmPpvJge/BZ55GZaBhXm1zBRlch4uNIfUjko02NmMcZQXxEOfkpTh65ciFWi8bLm47wxOqDnc4x0y7Z/RYf6WG/h0Y+oh0RH4IgCEKvMFMvtS3uTp6Pw0ZzraI0Z/hFO98EdOVnSC4g06iaqWp2QUKkyIf6QM5PHd3iA2DZlAx+sFz17fjZmzs6dUE1Daf9jXzML0gh1h78GJfIhyAIgjDmSA9tNNahw2lQfHQwV+4wGovNOh8gEPmoanIFe1oYng+vzx/wQYSlXUap+AC49oRJnL8gD69f59vPbAgIDgiKj5wkZ1eXd4vp+wCwWzUmdpx1E8WI+BAEQRB6RXrofJfAbBeVJjHbiodVdrTWwoFV6rFRiRJRfBjVLuWN7fj8OnarpiIkgchHH4a1RRmapnH/JfOYmZNIdbObG57egMvrQ9f1gNDqb+QDYMkklXqZnJFAjG30fKSPnpUKgiAII0pYr49Ah9MWfH6dEqNKJSzysfst0H2QNQfSpwBB8VHdHCo+qkDXAymX3GQnFos26tMuJnExNv70tUUkxdr4rLien7y2ncZ2b6AUOWcA4uPihflMzUrgyiVFg7XcYUGqXQRBEIRekR7a68OeonZ62qhobMft82OzaOQmh6QQtoenXCA4IyYs8uH3QHs9R+pV9CQ/xbhH6+hPu5hMSI/noSsWcvXf1/Hc2sMBr0ZKnD1iGW5vKUyL451bTx6sZQ4bEvkQBEEQekVY5MNMu/jcHK5uBFRjsMDkVFcT7DPGxM8ONv8KpF2aXapluMMYA99cFYh85Jniw4x8xI3etEsop8zI4rtnqvbvj398EICcpP5HPUYzIj4EQRCEXhE238UeTK+UVdUAHfwee95WHUjTJgdnlECw2qXJ6JQaknoxUzf5qR3ExxiIfJh8+5SpnDU72O58IH6P0YyID0EQBKFXZIROtrU51FRaoLxaiYQwv0egyuWCsGFpZuSj1e1To+cD4qMy2Fo9EPkYO2kXE4tF49eXLWBKpvLMBITWOKNP4mPixIlomtbp58YbbwSgvb2dG2+8kfT0dBISErjkkkuoqKgYkoULgiAIw0tYqa2mBaIfVbVKJATEh6cddv9XPe4wbyXeYSPOmD9S3eyChGDFS1iDMRgT1S6RSIy18/erj+Xq4ydy7QmTR3o5I0KfxMe6desoKysL/Lz99tsAXHrppQB85zvf4fXXX+fFF1/kgw8+oLS0lC9+8YuDv2pBEARh2DE9H3WtHrw+f0B81NQ3ADAh3RAf+98DTwsk5UPewk73iWQ61Zsrgq3VU53g90G7uu9YinyYFKbFcdf5c5iUMXp6cwwmfap2ycwMHw183333MWXKFE4++WQaGhp47LHHePbZZzntNNVn//HHH2fWrFl8+umnHHfccZFuKQiCIIwSUuNi0DTQdahtdZNltFhvaKgHUoOej9AqF0vn77iZiQ4O17Ya4kN1OXU3VAZKT3OTY6GtPniBM2VoXpAwYvTb8+F2u3n66ae55ppr0DSNDRs24PF4OOOMMwLnzJw5k6KiIj755JMu7+NyuWhsbAz7EQRBEKIPq0UjLa5zrw93uxpsVpgWBz4P7Pq3uiCkxDaUzFDjqjHfxVVfDqioSKzdGky5OJLAah+S1yOMHP0WH6+++ir19fVcddVVAJSXlxMTE0NKSkrYednZ2ZSXl3d5n3vvvZfk5OTAT2FhYX+XJAiCIAwxkcpt43CRGmcnKdYOBz+C9no14r5oacR7hHU5Nea7+IwW6/kpRvVHwO+RMjQvRBhR+i0+HnvsMZYvX05eXt6AFvCDH/yAhoaGwE9xcfGA7icIgiAMHeGNxlTaxYkraDY1q1xmnguWyM2zwnp9GJ4Pa6tqsT6Wy2yFIP3qcHro0CHeeecdXn755cC+nJwc3G439fX1YdGPiooKcnJyuryXw+HA4XD0ZxmCIAjCMBOpxbpTc6mUi98HO95QJ3aocgkl3HCqIh8Ol+oVkpfcscx2bFW6CIp+RT4ef/xxsrKyOPfccwP7Fi1ahN1uZ+XKlYF9u3bt4vDhwyxdGjn0JgiCIIwuTOEQGvmIMyMfJeugpRIcyTDppC7vEYx8uAOeD4e/FQduiXyME/oc+fD7/Tz++ON84xvfwGYLXp6cnMy1117LrbfeSlpaGklJSdx0000sXbpUKl0EQRDGCOZkW+X5MCIfuJX42P6kOmnGOWCL6fIegeFyTS6ITQZrDPjcZNAQoceHiI+xSJ/FxzvvvMPhw4e55pprOh377W9/i8Vi4ZJLLsHlcnH22Wfzhz/8YVAWKgiCIIw8aUbapbrZDRmG50NrpyjVCR+/rk7qosrFJNRwqgNafCY0HiFDa+g8VG6MzHURwumz+DjrrLPQdT3isdjYWH7/+9/z+9//fsALEwRBEKIP03BaXNtKXYqdVFTkY4pnNzQcVhUwU07v9h4ZhoBx+/w0tnmJd2ZgazxCutZIgaRdxgUy20UQBEHoNVlJSnzsqmji8bWqPDZec5F54FV1wowvQExcF1crHDYrSbHqu29VczvVJAMwN7mdFKOPiIiPsY2ID0EQBKHXLChI4erjJzI7NwmvVQmRiQk+LNuM6scFl/fqPsHUi5tD7UqsHJ3uC54g1S5jmn6V2gqCIAjjE6tF467z5wDgX7sL/v0MS/VN0NagenZMPrVX98lMdLCvqoWKxnbqGhwsAWYktgVPkMjHmEYiH4IgCEK/sBjpFc0cADf3S2Dt3XfazETVyfTt7RWUeBIAyLY0BU8Q8TGmEfEhCIIg9A97B2/Hgi/3+lJzvst/t5dTrSvPh6W1Sh30eYMTbaXaZUwi4kMQBEHoH6HiI2MG5B7V60szEpWx1OPTqTEMp7SoFusB4QEQmzKwNQpRiYgPQRAEoX+EVrUs+DJoWq8vNSMfQFB8GMPlwifaijVxLCLiQxAEQegfoZGPeZf16VKz2gUgJ7dAPWitUSkX8XuMeURSCoIgCP0je66a4ZIzH1IK+3RpqPhYNGsarE0AdzNUbAkpsxXxMVYR8SEIgiD0D1sMfOP1fl0aKj5OmZUL1afAzjdg938hdYI6IOJjzCJpF0EQBGHYyUxwcMGCPC5YkMecvCSYdpY6sGdFMO0ilS5jFol8CIIgCMOOpmk8dMXC4A5TfBzZqNI4IJGPMYxEPgRBEISRJykXchcAOmx/Ve0T8TFmEfEhCIIgRAfTzlbbQLWLpF3GKiI+BEEQhOhg+tnhv0vkY8wi4kMQBEGIDvKOhriM4O8iPsYsIj4EQRCE6MBigWlnBn+Xapcxi4gPQRAEIXoITb1I5GPMIqW2giAIQvQw5TSwxYLuh/jMkV6NMESI+BAEQRCih9hk+Nor4GkDZ8pIr0YYIkR8CIIgCNHFhGUjvQJhiBHPhyAIgiAIw4qID0EQBEEQhhURH4IgCIIgDCsiPgRBEARBGFZEfAiCIAiCMKyI+BAEQRAEYVgR8SEIgiAIwrAi4kMQBEEQhGFFxIcgCIIgCMOKiA9BEARBEIYVER+CIAiCIAwrIj4EQRAEQRhWRHwIgiAIgjCsRN1UW13XAWhsbBzhlQiCIAiC0FvMz23zc7w7ok58NDU1AVBYWDjCKxEEQRAEoa80NTWRnJzc7Tma3huJMoz4/X5KS0tJTExE07SRXk5U0djYSGFhIcXFxSQlJY30csY08l6PDPK+Dx/yXo8MY/l913WdpqYm8vLysFi6d3VEXeTDYrFQUFAw0suIapKSksbcP9poRd7rkUHe9+FD3uuRYay+7z1FPEzEcCoIgiAIwrAi4kMQBEEQhGFFxMcowuFwcNddd+FwOEZ6KWMeea9HBnnfhw95r0cGed8VUWc4FQRBEARhbCORD0EQBEEQhhURH4IgCIIgDCsiPgRBEARBGFZEfAiCIAiCMKyI+BgE7r33XhYvXkxiYiJZWVlcdNFF7Nq1K+yc9vZ2brzxRtLT00lISOCSSy6hoqIicPzzzz/niiuuoLCwEKfTyaxZs/jd734Xdo+PPvqI448/nvT0dJxOJzNnzuS3v/1tj+vTdZ0777yT3NxcnE4nZ5xxBnv27Ak7Z+PGjZx55pmkpKSQnp7O9ddfT3Nz8wDelcEn2t/nl19+mbPOOov09HQ0TeOzzz7rdE5P64tGxsL7/uc//5lTTjmFpKQkNE2jvr6+X+/FUDPa3+va2lpuuukmZsyYgdPppKioiJtvvpmGhob+vynDwHC976F8/PHH2Gw2jjrqqB7X15u/4T//+c9ZtmwZcXFxpKSk9On1jwi6MGDOPvts/fHHH9e3bt2qf/bZZ/oXvvAFvaioSG9ubg6cc8MNN+iFhYX6ypUr9fXr1+vHHXecvmzZssDxxx57TL/55pv1999/X9+3b5/+1FNP6U6nU3/44YcD52zcuFF/9tln9a1bt+oHDhzQn3rqKT0uLk7/05/+1O367rvvPj05OVl/9dVX9c8//1y/4IIL9EmTJultbW26ruv6kSNH9NTUVP2GG27Qd+7cqa9du1ZftmyZfskllwzyOzUwov19fvLJJ/W7775b/8tf/qID+qZNmzqd09P6opGx8L7/9re/1e+991793nvv1QG9rq5uwO/LUDDa3+stW7boX/ziF/XXXntN37t3r75y5Up92rRpUfe3pCPD9b6b1NXV6ZMnT9bPOussfcGCBT2ur6e/4bqu63feeaf+m9/8Rr/11lv15OTkAb0fw4GIjyGgsrJSB/QPPvhA13Vdr6+v1+12u/7iiy8GztmxY4cO6J988kmX9/n2t7+tn3rqqd0+18UXX6x/9atf7fK43+/Xc3Jy9F/+8peBffX19brD4dCfe+45Xdd1/U9/+pOelZWl+3y+wDmbN2/WAX3Pnj3dv9gRJJre51AOHDgQ8Q9zf9cXbYy29z2U9957L6rFR0dG83tt8sILL+gxMTG6x+Pp1b2jgaF+37/85S/rP/7xj/W77rqrR/HRm7/hoTz++OOjQnxI2mUIMEOMaWlpAGzYsAGPx8MZZ5wROGfmzJkUFRXxySefdHsf8x6R2LRpE6tXr+bkk0/u8pwDBw5QXl4e9tzJycksWbIk8Nwul4uYmJiwQUBOpxNQ4dloJZre597Q3/VFG6PtfR/NjIX3uqGhgaSkJGy2qBsl1iVD+b4//vjj7N+/n7vuuqtXa+nN3/DRyOj51zBK8Pv93HLLLRx//PHMnTsXgPLycmJiYjrl4bKzsykvL494n9WrV/OPf/yDN998s9OxgoICqqqq8Hq9/OQnP+G6667rcj3m/bOzs7t87tNOO41bb72VX/7yl/zv//4vLS0t3H777QCUlZX17oUPM9H2PveG/qwv2hiN7/toZSy819XV1dxzzz1cf/31g3rfoWQo3/c9e/Zw++23s2rVql6Lsd78DR+NSORjkLnxxhvZunUrzz//fL/vsXXrVi688ELuuusuzjrrrE7HV61axfr16/njH//Igw8+yHPPPQfAM888Q0JCQuBn1apVvXq+OXPm8MQTT/DrX/+auLg4cnJymDRpEtnZ2T2ORR4pRuP7PBaQ9334GO3vdWNjI+eeey6zZ8/mJz/5Sb9fw3AzVO+7z+fjyiuv5O6772b69OkRrxtX/8ZHOu8zlrjxxhv1goICff/+/WH7V65cGTHPXFRUpP/mN78J27dt2zY9KytL/+EPf9ir57znnnv06dOn67qu642NjfqePXsCP62trfq+ffsi5mZPOukk/eabb+50v/Lycr2pqUlvbm7WLRaL/sILL/RqHcNJNL7PoXSVD+/L+qKR0fq+hzJaPB+j/b1ubGzUly5dqp9++ulhpshoZyjf97q6Oh3QrVZr4EfTtMC+lStXDsrf8NHi+RDxMQj4/X79xhtv1PPy8vTdu3d3Om6alf75z38G9u3cubOTWWnr1q16VlaWftttt/X6ue+++259woQJ3a4tJydH/9WvfhXY19DQ0KVZyeSxxx7T4+LiouqPdDS/z6H0ZDjtaX3Rxmh/30OJdvExFt7rhoYG/bjjjtNPPvlkvaWlpdfPP5IMx/vu8/n0LVu2hP1861vf0mfMmKFv2bIlrLKm49r68jdcxMc44lvf+paenJysv//++3pZWVngJ/Tbwg033KAXFRXp7777rr5+/Xp96dKl+tKlSwPHt2zZomdmZupf/epXw+5RWVkZOOeRRx7RX3vtNX337t367t279b/+9a96YmKi/qMf/ajb9d133316SkqK/q9//UvfvHmzfuGFF3Yq03r44Yf1DRs26Lt27dIfeeQR3el06r/73e8G8V0aONH+PtfU1OibNm3S33zzTR3Qn3/+eX3Tpk16WVlZr9cXjYyF972srEzftGlToET0ww8/1Ddt2qTX1NQM4js1cEb7e93Q0KAvWbJEnzdvnr53796w5/d6vYP8bg0ew/W+d6Q31S663ru/4YcOHdI3bdqk33333XpCQoK+adMmfdOmTXpTU1P/3pQhRsTHIABE/Hn88ccD57S1tenf/va39dTUVD0uLk6/+OKLw/443nXXXRHvEfpN5KGHHtLnzJmjx8XF6UlJSfrChQv1P/zhD2ElspHw+/36HXfcoWdnZ+sOh0M//fTT9V27doWd87WvfU1PS0vTY2Ji9Pnz5+tPPvnkoLw3g0m0v8+PP/54xHvfddddvV5fNDIW3veunj/0NUQDo/29NiNLkX4OHDgwiO/U4DJc73tHeis+evM3/Bvf+EbE53/vvff6+G4MD5qu63pHH4ggCIIgCMJQEZ2lDIIgCIIgjFlEfAiCIAiCMKyI+BAEQRAEYVgR8SEIgiAIwrAi4kMQBEEQhGFFxIcgCIIgCMOKiA9BEARBEIYVER+CIAiCIAwrIj4EQRAEQRhWRHwIgiAIgjCsiPgQBEEQBGFYEfEhCIIgCMKw8v8BkC8Vr1YqFIcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cv_df['ds'], cv_df['y'])\n",
    "plt.plot(cv_df['ds'], cv_df['NHITS'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b5564b23-8552-45b2-999a-4806c687bde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  184.1131820678711\n"
     ]
    }
   ],
   "source": [
    "model_mae = np.abs(cv_df['y'] - cv_df['NHITS']).sum()\n",
    "print(\"Model: \",model_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "84c32634-9137-480f-a36e-9e326bfcd05f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ds'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cutoff \u001b[38;5;129;01min\u001b[39;00m cv_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcutoff\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mStatsForecast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcv_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcutoff == @cutoff\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcutoff\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_insample_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatplotlib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsforecast/core.py:1314\u001b[0m, in \u001b[0;36m_StatsForecast.plot\u001b[0;34m(df, forecasts_df, unique_ids, plot_random, models, level, max_insample_length, plot_anomalies, engine, id_col, time_col, target_col, resampler_kwargs)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Plot forecasts and insample values.\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \n\u001b[1;32m   1284\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;124;03m    its `show_dash` method.\u001b[39;00m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutilsforecast\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_series\n\u001b[0;32m-> 1314\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mensure_time_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(df, pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;129;01mand\u001b[39;00m df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m id_col:\n\u001b[1;32m   1316\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1317\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the ids as the index is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1318\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease provide them as a column instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1319\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1320\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/utilsforecast/validation.py:50\u001b[0m, in \u001b[0;36mensure_time_dtype\u001b[0;34m(df, time_col)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mensure_time_dtype\u001b[39m(df: DataFrame, time_col: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m     48\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Make sure that `time_col` contains timestamps or integers.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    If it contains strings, try to cast them as timestamps.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     times \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtime_col\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_dt_or_int(times):\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3807\u001b[0m     ):\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ds'"
     ]
    }
   ],
   "source": [
    "for cutoff in cv_df['cutoff'].unique():\n",
    "    StatsForecast.plot(\n",
    "        df, \n",
    "        cv_df.query('cutoff == @cutoff').drop(columns=['y', 'cutoff']), \n",
    "        max_insample_length=7 * 4, \n",
    "        engine='matplotlib'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3883373-abbc-4525-8592-d4aa27d9b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cv = cv_df.copy()\n",
    "new_cv.columns = new_cv.columns.str.replace('-median', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08dc5a7f-9229-48b9-aad7-b545ce7c8def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x350 with 1 Axes>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StatsForecast.plot(df, new_cv.drop(columns=['y', 'cutoff']), engine='matplotlib', max_insample_length=7 * 3, level=[80, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27d5da7b-c749-47af-bbe3-93b7a6042553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f04d7b50>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj0AAAGdCAYAAAD5ZcJyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABcuElEQVR4nO3deXhU1f0G8PfOTDKTTDLZV7KHhAAhQFhCUJAaytoKaFWEWqUqSrEFrUJxp+IPtFapu0WlLihWW9GKgoiCoCGEsIQ1IRsEspGQZLKQSTJzfn8kjBmykP3OZN7P89wnM+fee+73ZDLMy527SEIIASIiIqIBTiF3AURERET9gaGHiIiI7AJDDxEREdkFhh4iIiKyCww9REREZBcYeoiIiMguMPQQERGRXWDoISIiIrugkruA3mAymVBQUABXV1dIkiR3OURERNQJQghUVVUhMDAQCkXf74cZEKGnoKAAwcHBcpdBRERE3ZCfn4+goKA+386ACD2urq4Amn5pOp1O5mqIiIioM/R6PYKDg82f431tQISey19p6XQ6hh4iIiIb01+HpvBAZiIiIrILDD1ERERkFxh6iIiIyC4w9BAREZFdYOghIiIiu8DQQ0RERHaBoYeIiIjsAkMPERER2QWGHiIiIrILPQo969atgyRJWL58uUV7cnIyrr/+emi1Wuh0OkyePBmXLl3qsK9XX30VYWFh0Gg0SEhIwP79+3tSGhEREZGFboee1NRUvPnmm4iLi7NoT05OxowZMzBt2jTs378fqampuP/++zu8e+rHH3+MBx98EE8++SQOHjyIkSNHYvr06SgpKelueUREREQWJCGE6OpK1dXViI+Px2uvvYY1a9Zg1KhRWL9+PQBgwoQJ+OUvf4mnn3660/0lJCRg3LhxeOWVVwAAJpMJwcHB+OMf/4i//OUvV11fr9fDzc0NlZWVvPcWERGRjejvz+9u7elZunQpZs+ejalTp1q0l5SUICUlBb6+vpg4cSL8/Pxw3XXXYe/eve32VV9fj7S0NIu+FAoFpk6diuTk5DbXMRgM0Ov1FhMREZE1MTY2YtMrTyFl52dyl0LNuhx6Nm/ejIMHD2Lt2rWt5uXk5AAAnnrqKdxzzz3Ytm0b4uPjkZSUhNOnT7fZX2lpKYxGI/z8/Cza/fz8UFRU1OY6a9euhZubm3kKDg7u6jCIiIj61P5/rcDC0heRsOdO1Hz3d6DrX6xQL+tS6MnPz8eyZcuwadMmaDSaVvNNJhMA4N5778WiRYswevRovPjiixgyZAjeeeed3qkYwKpVq1BZWWme8vPze61vIiKinjry3b+ReO5t83PtD38F/rcMMDbIWBV1KfSkpaWhpKQE8fHxUKlUUKlU2L17N1566SWoVCrz3pphw4ZZrDd06FCcPXu2zT69vb2hVCpRXFxs0V5cXAx/f/8211Gr1dDpdBYTERGRNSjIy0DYD8sBACneNwIzngUgAQffBTbdDNRVylqfPetS6ElKSsLRo0dx+PBh8zR27FgsXLgQhw8fRkREBAIDA5GRkWGxXmZmJkJDQ9vs09HREWPGjMHOnTvNbSaTCTt37kRiYmI3hkRERCSPuks1qHl/AdxQg0xVNEbd/Sow4T7gto8AB2cg53vg7elARds7AqhvqbqysKurK2JjYy3atFotvLy8zO0PP/wwnnzySYwcORKjRo3Cu+++i1OnTuHTTz81r5OUlIR58+bh/vvvBwA8+OCDuOOOOzB27FiMHz8e69evR01NDRYtWtTT8REREfWbI28tQYIxC+Vwhe53H0KtcW6aMWQmsOhr4MNbgQsngQ1JwG2bgaAx8hZsZ7oUejpj+fLlqKurwwMPPICLFy9i5MiR2LFjByIjI83LZGdno7S01Pz81ltvxYULF/DEE0+gqKgIo0aNwrZt21od3ExERGStUre8hoSyz2ESEvJ/8Q/EhURZLhA4CrhnZ1PwKT4G/Gs2cOM/gWE3yFKvPerWdXqsDa/TQ0REcso9ngL/f/8KTlI99gXfgwl3Pd/+woYq4NPfA6e/ASABv/wrMPGPgCT1W73Wwiau00NERERN9BVlUH16J5ykeqRrxmL8Hes6XkHtCsz/CBh3DwAB7Hgc+HI5z+zqBww9RERE3SRMJmRtuAPBogBF8EbwXR9AoerEkSNKFTDrb8CMdQAkIO1fwIe38MyuPsbQQ0RE1E0pHz6N+Jo9qBdK6G94Gx4+AZ1fWZKACUuA+ZuazuzK/g54ZwbP7OpDDD1ERETdcGLfNow9vR4AcGjYSkTHT+leRzGzgUVfAS7+QMmJpjO7zqf1Wp30M4YeIiKiLiotOgufbfdBJZlwQDcV429+uGcdBo5uOrPLdzhQUwJsnA2c/F/vFEtmDD1ERERd0NhQj+J3FsIH5chTBGPY4ncgKXrh49QtCPj9NmDwVKDxEvDx7cBPL/OeXb2IoYeIiKgLUt/5M4bXp6NGaKCY/wGcXdx6r3ONDrjtY2DsXQAE8M1jwNYHAWNj723DjjH0EBERddKhHZuQWPgeAOBUwjqERI/q/Y0oVcDsvwPT/w+ABBx4p/nMLn3vb8vOMPQQERF1wvmc44j88SEAwD7fWzBmVh/eKkmSgMSlwK0fNJ/ZtbP5zK78vtumHWDoISIiuoq62mrUbVoIHWpxymEYxtz9cv9seOivgDu3Ai5+QMlx4K0koOBQ/2x7AGLoISIiuor0f96DSGMuLkIHzzs/hIOjpv82PigeuLv5zK7qYmDjLODU1v7b/gDC0ENERNSB/f9Zj/EVX8EoJBQkvQLfQeH9X4R7cNOZXZFJQEMtsHkhkPwqz+zqIoYeIiKidmQd+REj09cAAFLD/4DYSXPkK0ajAxb8GxizCIAAtj8CbP0zz+zqAoYeIiKiNlReLIXTlkVQSw047DQB429/Wu6Sms7s+tWLwLQ1aDqz623go1t5ZlcnMfQQERFdwWQ0Ivet32KQKEaB5Ivwez6AQqmUu6wmkgRM/CNw6/uAygnI+hbYOBOoPCd3ZVaPoYeIiOgKKR88gVG1yTAIB9TOeQdunj5yl9Ta0F8Di5rP7Co+1nTPLp7Z1SGGHiIiohaO/fg/jM95FQBwZMQjGDxqkswVdWDQGODubwHfYUB1UfOZXV/JXZXVYughIiJqVnI+DwE7lkIpCaS6z8C4G5fLXdLVuYc0n9l1ffOZXQuA5Nd4ZlcbGHqIiIgANNQbUPav2+CFSuQowhB7z1u9cyPR/qBxu+LMrlXAVw/zzK4r2MirSURE1LfS3l6GoQ0nUCWc4LhgE5y0rnKX1DVKh6Yzu375NAAJSN0AbL4NMFTJXZnVYOghIiK7d/DrjZhQ/BEAIOuavyFocKzMFXWTJAHX/Am45b2mM7tOfwO8MxOoPC93ZVaBoYeIiOxa/ukjiN63CgCwz38hRk+7XeaKesGwG5rO7NL6AsVHm+/ZdVjuqmTH0ENERHartroSjR/dDhfpEk44jsDYu9bLXVLvGTQGuGcn4DMUqCpsupZPxtdyVyUrhh4iIrJLwmTCiX/ehXDTGZTBHb53boLKwVHusnqXewhw13Yg4hdNZ3Z9dBuw7w25q5INQw8REdml/Z/+HWP1O9AoFCie/ga8A0PlLqlvaNyAhZ8A8XcAEMC2lXZ7ZhdDDxER2Z3Mgz9g9PF1AIADg/+IYYkzZa6ojykdgF//A/jlX5ue7/9n0/V87OzMLoYeIiKyKxWlRXD94vdwlBpxyPkaJCx8Su6S+ockAdcsaz6zSwOc3m53Z3Yx9BARkd0wGY0489ZvEYALOCcFIHLx+7ZzAcLeMmwOcOdWQOvz85ldhUfkrqpf2NkrTURE9izlvUcwsi4VdcIBhhv/BZ27l9wlySNoLHD3TsAnpunMrndmAhnb5K6qzzH0EBGRXUjf/RkS8t4EABwd/SQiR0yQuSKZeYQCv98OREwBGmqart6c8qbcVfUphh4iIhrwivKzEPz9H6GQBPZ7/hrj5v5R7pKsg5M7sPBTIP53gDABX68AvloBmIxyV9YnGHqIiGhAqzfUofLdBfBAFbKUkYi7Z2DvzegypQPw65eAqaubnu9/s/nMrmp56+oDDD1ERDSgHXxrKYY0ZkAPLZx/+yE0Tlq5S7I+kgRcuxy4+d2mM7sytzVdwVlfIHdlvYqhh4iIBqwDWzdgwoVPAQC5k15AYHiMzBVZueFzgTu+bDqzqygd2JAEFKbLXVWvYeghIqIB6czJNAzb/ygAIHnQnRiZNF/mimxE8Djg7m8B7yFAVQHwzgwgc7vcVfUKhh4iIhpwqvXlwCe/g7NkwDH1KIxf9He5S7ItHmHAXd8A4dc1ndn10Xwg5Z9yV9VjDD1ERDSgCJMJGRsWIdR0DiXwRMDvN0GpUsldlu1xcgd++x9g9O1NZ3Zt+wtwIUPuqnqEfwVERDSgpHy8DhOqvkeDUOLi7H8ixi9I7pJsl9IBuOFlwDOi6calPkPkrqhHGHqIiGjAOJX6LeJPPQ9IQNqQBzBh/C/lLsn2SRIw6UG5q+gV/HqLiIgGhIsl5+GxdTEcJSMOulyHhPmPyl0SWRmGHiIisnnGxkacf3sh/FCGs4pBiF78rv3dSJSuin8RRERk8/b/awVGGA6hVqhhuvk9uOg85C6JrFCPQs+6desgSRKWL19ubpsyZQokSbKY7rvvvg77ufPOO1utM2PGjJ6URkREduLId/9G4rm3AQAnxvwVYUPHylwRWatuH8icmpqKN998E3Fxca3m3XPPPfjrX/9qfu7s7HzV/mbMmIGNGzean6vV6u6WRkREdqIgLwNhPywHAKR434iEGzr+TzbZt26FnurqaixcuBAbNmzAmjVrWs13dnaGv79/l/pUq9VdXoeIiOxX3aUa1Ly/AIGoQaYqGqPuflXuksjKdevrraVLl2L27NmYOnVqm/M3bdoEb29vxMbGYtWqVaitrb1qn7t27YKvry+GDBmCJUuWoKysrN1lDQYD9Hq9xURERPblyFtLEGXMQjlcofvdh1Brrv6tAtm3Lu/p2bx5Mw4ePIjU1NQ25y9YsAChoaEIDAxEeno6Vq5ciYyMDPz3v/9tt88ZM2bgxhtvRHh4OLKzs/HII49g5syZSE5OhlKpbLX82rVrsXr16q6WTkREA0Tq568hoexzmISE/F/8A3EhUXKXRDZAEkKIzi6cn5+PsWPHYseOHeZjeaZMmYJRo0Zh/fr1ba7z3XffISkpCVlZWYiMjOzUdnJychAZGYlvv/0WSUlJreYbDAYYDAbzc71ej+DgYFRWVkKn03V2OEREZINyj6fA/9+/gpNUj+Tge5B41/Nyl0TdpNfr4ebm1m+f3136eistLQ0lJSWIj4+HSqWCSqXC7t278dJLL0GlUsFoNLZaJyEhAQCQlZXV6e1ERETA29u73XXUajV0Op3FREREA5++ogyqT++Ek1SPdM1YjL9jndwlkQ3p0tdbSUlJOHr0qEXbokWLEBMTg5UrV7b5VdThw4cBAAEBAZ3ezrlz51BWVtaldYiIaGATJhOyNtyBeFGAIngj+K4PeCNR6pIu/bW4uroiNjbWok2r1cLLywuxsbHIzs7Ghx9+iFmzZsHLywvp6el44IEHMHnyZItT22NiYrB27VrMmzcP1dXVWL16NW666Sb4+/sjOzsbK1aswODBgzF9+vTeGSUREdm8lI+exoSaPagXSujnvI1oH/7HmLqmVyOyo6Mjvv32W6xfvx41NTUIDg7GTTfdhMcee8xiuYyMDFRWVgIAlEol0tPT8e6776KiogKBgYGYNm0ann76aV6rh4iIAAAn9m3D2Mz1gAQcGrYSCfFT5C6JbFCXDmS2Vv19IBQREfWf0qKzEG9Mhg/KcUA3FWOWf8L7ag0QVn0gMxERUX9qbKhH8TsL4YNy5CmCMWzxOww81G38yyEiIquV+s6fMbw+HTVCA+nWD+Ds4iZ3SWTDGHqIiMgqHd7xIRIL3wMAnEpYh9Aho+QtiGweQw8REVmd8znHEfHjnwEA+3xvwZhZi2SuiAYChh4iIrIqdZdqULfpt9ChFqcchiH+rpflLokGCIYeIiKyKke/eReRxhxchA6ed34IR7VG7pJogGDoISIiq6I4vR0AkBl0M3wHhctcDQ0kDD1ERGQ1GuoNiKreDwBwHzVb5mpooGHoISIiq3E67TvoUIty6BA16jq5y6EBhqGHiIisRmX6lwCAbF0CbyZKvY6hh4iIrIZ/8Z6mB0N4w2nqfQw9RERkFYrOnka46QyMQkJU4ly5y6EBiKGHiIiswpl9nwEAMh2Hwc3TR+ZqaCBi6CEiIqugzt0JAKgI+oXMldBAxdBDRESyq6utxpDagwAAvzE3yFwNDVQMPUREJLvMlG1wkupRDC+EDxsndzk0QDH0EBGR7C4d/woAkOd1LSQFP5qob/Avi4iIZCVMJgSX7QUAqGNmyFwNDWQMPUREJKuzp9MRKIpRL1SITuStJ6jvMPQQEZGsClO3AABOOY2Es4ubvMXQgMbQQ0REsnLJ/x4AUBuaJHMlNNAx9BARkWyqKi9iSN1RAEDQuDkyV0MDHUMPERHJ5nTyF3CQjMiXAhE0OFbucmiAY+ghIiLZNJ7aDgA47ztZ5krIHjD0EBGRLExGIyIqfgIAaIfPkrkasgcMPUREJIucY8nwRgVqhAZDEqbLXQ7ZAYYeIiKSxYWD/wMAZLqMhaNaI3M1ZA8YeoiISBae55tOVW+ImCpzJWQvGHqIiKjfXSw5j6iGTABAeOI8mashe8HQQ0RE/S47+XMoJIFsZQR8AsPkLofsBEMPERH1O0XWDgBAif91MldC9oShh4iI+lVjQz2iqlIAAB6jfiVzNWRPGHqIiKhfZaZ9Bx1qUA5XRI2eInc5ZEcYeoiIqF9Vpm8FAGTrEqBUqWSuhuwJQw8REfUr/6Ifmh5ETZO3ELI7DD1ERNRvivKzEG7Kg1FIiJo4V+5yyM4w9BARUb85s28LACDTcSjcvPzkLYbsDkMPERH1G3XutwCAykG/kLkSskcMPURE1C/qLtUguuYgAMBnzA0yV0P2iKGHiIj6RWbKNjhLBpTAExHDx8tdDtkhhh4iIuoXtce/BgDkeV4DScGPH+p/PfqrW7duHSRJwvLly81tU6ZMgSRJFtN9993XYT9CCDzxxBMICAiAk5MTpk6ditOnT/ekNCIisiLCZEJQ6R4AgEPMDJmrIXvV7dCTmpqKN998E3Fxca3m3XPPPSgsLDRPzz33XId9Pffcc3jppZfwxhtvICUlBVqtFtOnT0ddXV13yyMiIiuSn5WOIFGEeqFCdCJvPUHy6Fboqa6uxsKFC7FhwwZ4eHi0mu/s7Ax/f3/zpNPp2u1LCIH169fjsccew5w5cxAXF4f33nsPBQUF2LJlS3fKIyIiK1OQ+gUAIEMTB62ru7zFkN3qVuhZunQpZs+ejalTp7Y5f9OmTfD29kZsbCxWrVqF2tradvvKzc1FUVGRRV9ubm5ISEhAcnJym+sYDAbo9XqLiYiIrJfL2Z0AgJrQ62WuhOxZl296snnzZhw8eBCpqaltzl+wYAFCQ0MRGBiI9PR0rFy5EhkZGfjvf//b5vJFRUUAAD8/y4tU+fn5meddae3atVi9enVXSyciIhlU68sRXXcUkIBB4+fKXQ7ZsS6Fnvz8fCxbtgw7duyARqNpc5nFixebH48YMQIBAQFISkpCdnY2IiMje1Zts1WrVuHBBx80P9fr9QgODu6VvomIqHdlJn+JeMmIfCkQwYNHyF0O2bEufb2VlpaGkpISxMfHQ6VSQaVSYffu3XjppZegUqlgNBpbrZOQkAAAyMrKarNPf39/AEBxcbFFe3FxsXneldRqNXQ6ncVERETWqfFU06nq532ulbkSsnddCj1JSUk4evQoDh8+bJ7Gjh2LhQsX4vDhw1Aqla3WOXz4MAAgICCgzT7Dw8Ph7++PnTt3mtv0ej1SUlKQmJjYlfKIiMjKCJMJ4eU/AQC0sbNkrobsXZe+3nJ1dUVsbKxFm1arhZeXF2JjY5GdnY0PP/wQs2bNgpeXF9LT0/HAAw9g8uTJFqe2x8TEYO3atZg3b575Oj9r1qxBVFQUwsPD8fjjjyMwMBBz587tlUESEZE8so8mYzDKUSvUiB4/Xe5yyM51+UDmjjg6OuLbb7/F+vXrUVNTg+DgYNx000147LHHLJbLyMhAZWWl+fmKFStQU1ODxYsXo6KiAtdeey22bdvW7nFDRERkGy4c+h8GA8jQjsFojbPc5ZCdk4QQQu4iekqv18PNzQ2VlZU8voeIyIqcWjMBMY0nsT/2SYz/zYNXX4HsSn9/fvPmJ0RE1CfKLxQiuuEUACB0whyZqyFi6CEioj6Snfw5FJJAtjIcfkG9c8kSop5g6CEior5x+hsAQInfZJkLIWrC0ENERL3O2NiIqKp9AACPkbzBKFkHhh4iIup1p9O+gxtqUAEXRI3h/bbIOjD0EBFRrys/8iUAIMs1AUpVr14dhajbGHqIiKjX+Rb/0PQgapq8hRC1wNBDRES9qvhcNiKNuTAJCZGJPFWdrAdDDxER9aq85C0AgEyHGHj4tH3fRSI5MPQQEVGvcsz9FgBQPug6mSshssTQQ0REvcZQV4shNWkAAJ/4G2SuhsgSQw8REfWazP3b4SwZcAEeiByRKHc5RBYYeoiIqNfUHPsKAJDrMRGSgh8xZF34F0lERL0m6MIeAIAqZqbMlRC1xtBDRES9Ij/rKIJEIeqFEtGJvPUEWR+GHiIi6hXn928BAGRqRsBF5yFvMURtYOghIqJeoT3zHQCgOiRJ5kqI2sbQQ0REPVZTVYEhdekAgMBxPFWdrBNDDxER9Vhm8pdwlBpxTvJH8OA4ucshahNDDxER9VjDqW0AgPPe1/JUdbJa/MskIqIeESYTwi7+CABwGj5L5mqI2sfQQ0REPZJzfD98cRG1Qo3ohBlyl0PULoYeIiLqkQtpXwAAMrXx0DhpZa6GqH0MPURE1CPu578HABjCp8pcCVHHGHqIiKjbKkqLEFV/EgAQmjBH5mqIOsbQQ0RE3ZaV/DmUkkCuIgz+IVFyl0PUIYYeIiLqvtPfAACK/CfLXAjR1TH0EBFRtxgbGxGpTwEAuMXNlrkaoqtj6CEiom45ffB7eKAKemgRPeZ6ucshuiqGHiIi6pbyI1sBAKddx0Pl4ChzNURXx9BDRETd4lu0GwBgGjxN5kqIOoehh4iIuqzkfC4ijTkwCQmRiTxVnWwDQw8REXVZ3r4tAIDTDtHw9B0kbzFEncTQQ0REXeaQvQMAcHHQL2SuhKjzGHqIiKhLDHW1iK5JAwB4j/6VzNUQdR5DDxERdUnm/h3QSnUohTsiR0yUuxyiTmPoISKiLqk5/hUAIMd9IhRKpczVEHUeQw8REXXJoJIfAACqmOkyV0LUNQw9RETUaeeyjiFYFKBBKBGVeIPc5RB1CUMPERF12rnUzwEAmepYuLp5ylwNUdcw9BARUac5n9kJAKgK4b22yPYw9BARUafUVlci5tIRAEDAuLnyFkPUDT0KPevWrYMkSVi+fHmreUIIzJw5E5IkYcuWLR32c+edd0KSJItpxowZPSmNiIh6WWbyVjhKjSiQ/BASFSd3OURdpuruiqmpqXjzzTcRF9f2H/769eshSVKn+5sxYwY2btxofq5Wq7tbGhER9QHDya8BAPle1yJQwS8KyPZ066+2uroaCxcuxIYNG+Dh4dFq/uHDh/H3v/8d77zzTqf7VKvV8Pf3N09t9UtERPIQJhPCLv4IANAMnylzNUTd063Qs3TpUsyePRtTp05tNa+2thYLFizAq6++Cn9//073uWvXLvj6+mLIkCFYsmQJysrK2l3WYDBAr9dbTERE1HdyT6TCD2W4JBwxJIGhh2xTl7/e2rx5Mw4ePIjU1NQ25z/wwAOYOHEi5syZ0+k+Z8yYgRtvvBHh4eHIzs7GI488gpkzZyI5ORnKNq72uXbtWqxevbqrpRMRUTcVp32BCAAZzvEY5ewidzlE3dKl0JOfn49ly5Zhx44d0Gg0reZ/8cUX+O6773Do0KEuFTF//nzz4xEjRiAuLg6RkZHYtWsXkpKSWi2/atUqPPjgg+bner0ewcHBXdomERF1nvu57wEAhvDW/yYT2Youfb2VlpaGkpISxMfHQ6VSQaVSYffu3XjppZegUqmwY8cOZGdnw93d3TwfAG666SZMmTKl09uJiIiAt7c3srKy2pyvVquh0+ksJiIi6huVZcWIrj8BAAhJ6PxefCJr06U9PUlJSTh69KhF26JFixATE4OVK1fC29sb9957r8X8ESNG4MUXX8Svf/3rTm/n3LlzKCsrQ0BAQFfKIyKiPnB63xcYKwnkKUIQFjpE7nKIuq1LocfV1RWxsbEWbVqtFl5eXub2tg5eDgkJQXh4uPl5TEwM1q5di3nz5qG6uhqrV6/GTTfdBH9/f2RnZ2PFihUYPHgwpk/nzeyIiGSXsR0AUOg3GWHyVkLUI7JcaCEjIwOVlZUAAKVSifT0dNxwww2Ijo7GXXfdhTFjxmDPnj28Vg8RkcyMjY2I1KcAANzifiVzNUQ90+2LE162a9euDucLITpsc3Jywvbt23taBhER9YHTh3cjBnro4YyoMbzfFtk2XlKTiIjaVX74SwDAaZfxcHDk3neybQw9RETULp/C3QAA0+BfylwJUc8x9BARUZtKC85gsDEbJiEhInGu3OUQ9RhDDxERtSl33xYAQJZDFLz8guQthqgXMPQQEVGblNk7AABlgVPkLYSolzD0EBFRK/WGOkRXHwAAeI/u/MVliawZQw8REbWSmfoNXKRLKIU7IuOukbscol7B0ENERK1UH/0KAJDrngiFUilzNUS9g6GHiIhaCbiwBwCgiObtgGjgYOghIiIL53NOItR0Dg1CiaiJN8hdDlGvYeghIiIL+SmfAQAy1cOhc/eSuRqi3sPQQ0REFpzPfAcAqAr+hcyVEPUuhh4iIjKrra7EkEuHAQABY+fIWwxRL2PoISIis8yUr6GWGlAIH4QMGS13OUS9iqGHiIjMDCe+BgCc9Z4EScGPCBpY+BdNREQAAGEyIbRsLwBAM2ymzNUQ9T6GHiIiAgDknUqDP0pRJxwQncDQQwMPQw8REQEAig58AQDIcB4NJ62rzNUQ9T6GHiIiAgC4nfseAFAXliRzJUR9g6GHiIhQefECog3HAQDBCfNkroaobzD0EBERspI/h0oyIU8RjMCwIXKXQ9QnGHqIiAimzG8AAEW+k2WuhKjvMPQQEdk5k9GIyMpkAIDriNkyV0PUdxh6iIjsXNaRPfCEHlXCCdHjpspdDlGfYeghIrJzZYf+BwA47ToODo5qmash6jsMPUREds67YBcAoDFymryFEPUxhh4iIjtWWnQWUcYsAEBEIu+qTgMbQw8RkR3LSd4CADitioK3f4i8xRD1MYYeIiI7psreAQAoDbhO5kqI+h5DDxGRnWqoNyCqKhUA4DX61zJXQ9T3GHqIiOxURuo3cJUu4SJ0GDxyktzlEPU5hh4iIjtVffRrAEC2WyIUSqXM1RD1PYYeIiI7FVDyAwBAMWS6zJWQLRBCyF1Cj6nkLoCIiPpfQe4phJry0SgUGMxT1e2WMBphrKhAY1kZjGVlaCwtQ2NZqeXj0jI0lpUBAKJ275K34B5i6CEiskP5+7cgEECmejiGeXjLXY4FYTLBWFEBSaGAQquF5OAgd0k2RTQ0oPFiOYxlpWgsK2sdaJpDTGNZGYwXLwImU+c6liSIxkZIKtuNDrZbORERdZsm91sAgD7oF/2+bZPBgMbCQjQUFKChsBANBYXNPwvQUFiAxsIiiPp68/KSWg2FiwsULlootFootS5Nz7Xan9tcXKDQXm5rWlZpftzc7uwMyUaPXTLV18NY2hxiSpv3xJRdvCLEND02VlR0uX+luzuU3l5QeXlD5eX182NvLyg9PaHybmqHjf7+LmPoISKyM5dqqjDk0mFAAvzG3tCrfQshYCwvbw4yBWgsKPg51DQHG2PzVyWd7tNggNFg6PJ6bZGcnX8OQ1cGpCtCkzlMXV5W+/OykrMzJEnqUS2m2lrLENPyq6UrAo2pqqprnSsUTWHFy6t1iPFqGWi8oPL0sJu9aQw9RER2JjNlK0ZKDSiCD8JixnRpXVFfj4biYjScb95LU1iAhoICNLYINqKu7qr9SE5OcAgMhENAQNM0qOmxKiCgqd3XF5AkmGpqYKyugammGqaaGpiqq2Gqroaxpgam6ubnNT/PN1ZXN7VfsSwaG5vqr61FY20tcOFCt353ZgoFFM7OHeyBcoFC6wyFVgtx6VJzoGn+mql5ErW1XdumgwNUzUGm3RDj5QWVtzeUbm42u1erLzH0EBHZmboT2wEAZ7yugb/i55N4hRAwVVb+vFemjWDTWFoKdOIsHqWPNxwCAtsNNkp3907tKVG6u0Pp7t7tsV4el6iv/zkgVbcRkGqqm55fGaaqq2GqbQ5ezW0wmQCTyRyqekLSaH4OMZ5e7YYYlZcXFDpdj/cu2TuGHiIiOyEaGlBfVITAE3tRWesE5xoXFD7xpDnYNBYUwtSJvQ+SWt0UYgIDoDKHmkA4BDbtpVH5+0Ph6NgPI+ocSZKajgtSqwEvrx71JYSAuHTJMiC12AvVag9UdTUkJ02bIUbp5Q2Ftudfk1HnMfQQEdkIIQRgNEI0NjZNDQ0QDQ3A5ceNjRAGAxpKSpr2zFw+SLj5gOHGkpLmM3VUqIYHVPgOFW1sR+nl9fPemctBpkWwUXp62u0HtSRJkJydoXB2lrsU6oYehZ5169Zh1apVWLZsGdavX28xTwiBWbNmYdu2bfjss88wd+7cdvsRQuDJJ5/Ehg0bUFFRgWuuuQavv/46oqKielIeEdkIIUTTVyZXTKJpZuv2phlttIvLHbZub3edn9tFw+XwcEWQaNFuDhnm0NHiccv5DS3Wb7winFis02K+xTo/P0ZzuBGNjZ36aqnD37VSAUenehhctfCYMKv18TQBAVBoND3aBpG16nboSU1NxZtvvom4uLg2569fv77T/xN47rnn8NJLL+Hdd99FeHg4Hn/8cUyfPh0nTpyAhm8+uyeMRjQUFMCQnY36nFw0XrjQ/L/VFh9mLT/IzO1XzGuv3WJeD9uFgEAXt2Fep+ftvb4NoO3tdBRIuthOPSRJkBwcmiaVCnB0gMrHx/J4mua9NQ4BAcj451wMbjiGlJi/YPj8VXJXT9SvuhV6qqursXDhQmzYsAFr1qxpNf/w4cP4+9//jgMHDiAgIKDDvoQQWL9+PR577DHMmdN0VdD33nsPfn5+2LJlC+bPn9+dEskGmerqUJ+Xh/qcHBiyc2DIaQo59Xl5EAaD3OWRLZOkVpPURrukUpnDgzlEOKggOTg2tV0xHw4qSCqHVutIDs3zzW0t5juoLNub21r1rXIw92NRj6q5nsvrdOEMHX1FGYbUnwAkIGj83L76bRNZrW6FnqVLl2L27NmYOnVqq9BTW1uLBQsW4NVXX4W/v/9V+8rNzUVRURGmTp1qbnNzc0NCQgKSk5PbDD0GgwGGFh+Cer2+O8MgmTSWlzcFm5wc1GfnwJDb9LPh/Pl2/+cvOTrCMSwMjpERcAgIhKRUAGj5gYWmDy1Jar+9jXldbW+7r05u4/I8oP15bfVnntdee8d9WbS36Kvt9u6s00Z78zxJQpvt5nXQ1vwu9tdOgPn574EuO/3TFxgjmXBGEYTQiKFyl0PU77ocejZv3oyDBw8iNTW1zfkPPPAAJk6caN5rczVFRUUAAD8/P4t2Pz8/87wrrV27FqtXr+5C1dTfhMmEhoJC1OfmmL+WMuRkoz47B8by8nbXU7i5QR0RAceIcKgjIpt+RkbCYdAgXnOCqIdMGdsAAIU+kxAqcy1EcuhS6MnPz8eyZcuwY8eONo+1+eKLL/Ddd9/h0KFDvVZgW1atWoUHH3zQ/Fyv1yM4OLhPt0ltM9XXoz4374pwk4P63NwOL1CmCgz4OdS0CDf2fFYIUV8yGY2IqEwGALiMmCVzNUTy6FLoSUtLQ0lJCeLj481tRqMRP/zwA1555RUsWbIE2dnZcL/iQlI33XQTJk2ahF27drXq8/JXYMXFxRbH/xQXF2PUqFFt1qFWq6FWq7tSOvWQsbKyKcy0/FoqJwcN5861f7M6Bweow0LhGB4Bx8iI5j04EVCHhUGh1fbvAIjsXNaRvYhGJaqFE6LHTZO7HCJZdCn0JCUl4ejRoxZtixYtQkxMDFauXAlvb2/ce++9FvNHjBiBF198Eb/+9a/b7DM8PBz+/v7YuXOnOeTo9XqkpKRgyZIlXSmPekgIgcbCQhhyclGfk93imJtcGEtL211P4eLSHGoioY5sDjYREXAICrLpu/ESDSRlh78EAGS6jEW8mmfFkn3q0ieSq6srYmNjLdq0Wi28vLzM7W0dvBwSEoLw8HDz85iYGKxduxbz5s2DJElYvnw51qxZg6ioKPMp64GBgR1e24e6T9TXo/7sWRiyc5q/lmreg5Ob2+G9YFT+/lBHhMPxiq+lVD4+/EqKyMp5FewCABgjfylvIUQykuW/4RkZGaisrDQ/X7FiBWpqarB48WJUVFTg2muvxbZt23iNnl4iGhpw4aWXzOGmPj8fMBrbXlilgmNISNMem/AI854bx/AIKF34lRSRLSotykd0YyYAIHzCXHmLIZKRJITtXx1Mr9fDzc0NlZWV0Ol0cpdjdYQQyJyQCFOLoKnQas1fQzlGtAg3wcFN1wghogEjdcsrGHf4UWQpIzH48YNyl0Nk1t+f3zzgwg5IkgTvxYshqdVNX09FRkLl68uvpIjshDLrGwBAacAUDJa5FiI5MfR0QAiBbceKkFFcheVTo+Uup0e87vq93CUQkQwa6g0YXN10XTX3UbNlroZIXgw9HTheoMeSTQehkIDpw/0xNIBfnRGRbck8sBPDUYty6BA16jq5yyGSlULuAqxZ7CA3zBrhD5MAntl6EgPg8CcisjNV6U2nqmfrEqDkJSTIzjH0XMXKGTFwVCqwN6sUuzIuyF0OEVGX+JfsaXowZLq8hRBZAYaeqwj10uLOa8IAAGu2nkCDsZ2rDxMRWZnCMxkIM52FUUiISpwrdzlEsmPo6YSlvxgMD2cHZF+oweb9Z+Uuh4ioU86mfA4AyHQcBjdPH5mrIZIfQ08nuDk54IFfNp299eK3p6Gva5C5IiKiq9PkfgsAqAj6hcyVEFkHhp5Oum18CCJ9tLhYU49Xv8+Suxwiog7V1VYjuvYQAMBvzA0yV0NkHRh6OslBqcCjs4cCADbuzUP+xfbvUUVEJLeMlK/hJNWjGF4IHzZO7nKIrAJDTxf8Yogvrh3sjXqjCeu2nZK7HCKidtUd/woAkOd1LSQF/6knAhh6ukSSJDw6eygkCdiaXoi0MxflLomIqBVhMiG4bC8AQB0zQ+ZqiKwHQ08XDQ3Q4daxwQCAv355EiYTL1hIRNblbOZhBIoS1AsVohN56wmiyxh6uuHBadFwdlTiSH4F/pdeIHc5REQWCg80nap+ymkknF3cZK6GyHow9HSDr6sGf5gSCQB4blsG6hqMMldERPQz17PfAwBqQ5NkroTIujD0dNPdkyIQ6KbB+YpLeHtvrtzlEBEBAPQVZYg2HAMABI2bI3M1RNaFoaebNA5KrJgRAwB47fssXKgyyFwRERGQlfwFHCQj8qVABA2OlbscIqvC0NMDN4wMxMggN9TUG/HCjky5yyEiQmPGNwCA876TZa6EyPow9PSAQiHhsV8NAwB8nHoWp4r0MldERPbMZDQiouInAIB2+CyZqyGyPgw9PTQuzBMzY/1hEsAzW09CCJ7CTkTyOJmyHd6oQI3QYEjCdLnLIbI6DD294C8zY+CglLDndCl2ZV6QuxwisjOGulokv/MworbfDgA45ToBjmqNzFURWR+Gnl4Q6qXFnRPDADTt7Wk0muQtiIjsxonkr1H03Dgknv0nHKVGpGvGIfS3L8tdFpFVYujpJfdfHwUPZwdklVRjc2q+3OUQ0QBXWVaM/f9YgGHb5yPUdA6lcEfauL9jxIpv4O0fInd5RFaJoaeXuDk5YPnUaADAizsyoa9rkLkiIhqIhMmEA1+8AePLYzG+fCsAIMVrDhz+dABjZt/Nm4sSdYDvjl60ICEEET5alNXU47Xvs+Uuh4gGmPM5x3Hs2SSMPbgSntAjTxGMUzM/QcIf34Obp4/c5RFZPYaeXuSgVODRWUMBAO/szUX+xVqZKyKigaDeUIfkdx+B17vXYYThIAzCAfvCliJw5QHEJEyTuzwim8HQ08uuj/HFNYO9UG804dltp+Quh4hs3Kn9O3D+2fFIzH0VGqkBx9SjcOH2XZhw5//xDC2iLmLo6WWSJOHRWcMgScCX6YVIO1Mud0lEZIMqy0uR8vIdiN56M8JNZ1AOHVJHr8Xwld/z9hJE3cTQ0weGBepwy5hgAMDTX57gBQuJqNOEyYS0r95Gwz/GIKFsCxSSwH73WZDuT8W4OX/ggcpEPaCSu4CB6s/TovG/9AIczq/A/9ILccPIQLlLIiIrV5CXgQsf348xl/YDAPKlQOinPo/x18yWuTKigYH/ZegjvjoNllwXCQB49utTqGswylwREVmrxoZ67PvgSbhvnISRl/ajXqiQHHwPfFemYTgDD1GvYejpQ3dPikCAmwbnKy7hnR9z5S6HiKxQ5sHdOLMuAROy1sNZMuCE4wgULtiJxLueh1rjLHd5RAMKQ08fcnJUYsWMIQCA177PxoUqg8wVEZG1qNaXI+XVuzD48zmINOagElqkxv0VMSt3I3TIKLnLIxqQGHr62JyRgxAX5IZqQyNe/DZT7nKIyAoc+uYD1L4Qj4QLn0IhCRzQTUXjkv0Yd+MyKJRKucsjGrAYevqYQiHhsdnDAACb959FRlGVzBURkVyKz2Xj0HOzMPqnpfDFRZyT/HH0+n9h7IP/gZdfkNzlEQ14DD39YHy4J2bG+sMkgGe+Oil3OUTUz4yNjdj30TNw2TARo2t/RINQInnQnfB+OA0jJs+Tuzwiu8FT1vvJX2bG4NuTxfgh8wJ2ZZRgyhBfuUsion6QdeRHiP8tw4TG04AEnFINhfrGl5E4bJzcpRHZHe7p6SehXlrckRgGAPi/r06i0WiStyAi6lO11ZXY9/p9CPvvrxDVeBp6OCNl2GOIXvUjwhl4iGTB0NOP/nh9FNydHZBZXI2PD+TLXQ4R9ZEj3/0blc+PwYTij6CSTEhzmYL6xfuQcMvDPFCZSEYMPf3IzdkBy5OiAAAvfJOJqroGmSsiot5UWnAGB5+/ASN/uAcBuIBC+ODI5A0Y89Dn8A4Mlbs8IrvH0NPPFk4IRYS3FmU19XhtV7bc5RBRLzAZjUj599/g+M8JiK/ejUahwD7/hXB7KA0jr79F7vKIqFmPQs+6desgSRKWL19ubrv33nsRGRkJJycn+Pj4YM6cOTh16lSH/dx5552QJMlimjFjRk9Ks1oOSgUemTUUAPD23lzkX6yVuSIi6oncE6nIXHsNEk6sgQ61OK2KwpmbtmLCfa/B2cVN7vKIqIVuh57U1FS8+eabiIuLs2gfM2YMNm7ciJMnT2L79u0QQmDatGkwGju+99SMGTNQWFhonj766KPulmb1kob6YmKkF+obTXhue4bc5RBRN9TVViP5n39C0MfTEdN4EjVCg31DViDiL/sQGTdR7vKIqA3dCj3V1dVYuHAhNmzYAA8PD4t5ixcvxuTJkxEWFob4+HisWbMG+fn5yMvL67BPtVoNf39/83RlvwOJJEl4dPZQSBLwvyMFSDtTLndJRNQFR3/4DGV/i0diwbtwkIw45HwNqu/5CRNuexRKFa8EQmStuhV6li5ditmzZ2Pq1KkdLldTU4ONGzciPDwcwcHBHS67a9cu+Pr6YsiQIViyZAnKysq6U5rNGB7ohpvHNF2Bdc3WExBCyFwREV1NWfE5HHjhJoz47k4MEsUogScOTXwVo1d8Bb+gSLnLI6Kr6HLo2bx5Mw4ePIi1a9e2u8xrr70GFxcXuLi44Ouvv8aOHTvg6OjY7vIzZszAe++9h507d+LZZ5/F7t27MXPmzHa/EjMYDNDr9RaTLfrztCFwdlTi0NkKfJleKHc5RNQOYTJh/3/WQ/X6eIzVfwuTkLDP52Y4P3gQo6f9Vu7yiKiTJNGFXQz5+fkYO3YsduzYYT6WZ8qUKRg1ahTWr19vXq6yshIlJSUoLCzE888/j/Pnz+PHH3+ERqPp1HZycnIQGRmJb7/9FklJSa3mP/XUU1i9enWr9srKSuh0us4Oxyq8tPM0XtiRiUHuTtj55+ugceA1PIisyZmMw6j5z/0YVn8UAJCtjIBx9npEx18nc2VEtk+v18PNza3fPr+7FHq2bNmCefPmQdni4lpGoxGSJEGhUMBgMFjMA4D6+np4eHjgrbfewm233dbpwnx8fLBmzRrce++9reYZDAYYDAbzc71ej+DgYJsMPZfqjfjF87tQpK/DyhkxWDKFu8iJrEHdpRoc+vAJjDm7EY6SEbVCjfSoP2DsrY9A5dD+nmsi6rz+Dj1dOuIuKSkJR48etWhbtGgRYmJisHLlylaBBwCEEBBCWISUqzl37hzKysoQEBDQ5ny1Wg21Wt2V0q2Wk6MSK2YMwYP/PoJXv8/CzWOD4O0yMMZGZKuO/7gVum8fQqIoACTgiNN4+Nz6CiaEDZG7NCLqgS4d0+Pq6orY2FiLSavVwsvLC7GxscjJycHatWuRlpaGs2fP4qeffsLNN98MJycnzJo1y9xPTEwMPvvsMwBNZ4I9/PDD2LdvH/Ly8rBz507MmTMHgwcPxvTp03t3tFZq7qhBGDHIDdWGRry4I1PucojsVkVpEfavvw3DdyxAsChAKdyRNn494h7ejkAGHiKb16tXZNZoNNizZw9mzZqFwYMH49Zbb4Wrqyt++ukn+Pr+fFfxjIwMVFZWAgCUSiXS09Nxww03IDo6GnfddRfGjBmDPXv2DJi9OVejUEh4bHbTBQs/2n8WmcVVMldEZF/qDXVI3fIqxCvjML7iK5iEhBSvuXBYloYxsxZBUvDi9UQDQZeO6bFW/f2dYF+57/00bDtehClDfPCvRePlLodowCotOouzR3ajPjcZbmWHEV6fCY3UdC+8XEUoDDNfQMy4ji/JQUQ9Z9XH9FDf+svMGOw8VYxdGRewO/MCrov2kbskIpvXUG9A3on9KDu5B6qCAwisPopAUQLvlgtJQDlccSr8dxgz/wk4qjt3pikR2RaGHisS5q3F7xLD8PbeXDyz9QSuiZwElZK71Ym6oqz4HM4e2YW63BS4lR1CuCEDUVI9olosYxISzihDUOI+ElLwePgPn4TgwXFI5NdYRAMaQ4+V+dP1UfjPwXPILK7Gvw+cw4KEELlLIrJajQ31yDuRirJTe6E8vx8BVUcxSBTDq+VCEqCHFnmaYajxjYfL4ESExk1GuLsXwuUqnIhkwdBjZdycHbAsKQqr/3cCL+zIwK9HBsBV4yB3WURWofxCIc4c2YVLOcnQlTbtxRksGTD4iuXyFMEocYsDgsbDb/hkBEeNRFwbl9QgIvvC0GOFfjshFO8nn0FOaQ1e35WNFTNi5C6JqN8ZGxuRd/IASk/ugeJ8KgL06QgShbC4FbEEVAkn5DoNQ41PPLSRiQgdeR3CPLwRJlPdRGS9GHqskINSgVWzhuKe9w7grb25WJAQgiAPZ7nLIupTFaVFOJO+C7XZ++BaegjhdacQKdXhymuUn1EEoVgXBwSNg8+wSQgdEs+9OETUKQw9VmrqUF8kRnghOacMz23LwEu3jZa7JKJeY2xsxNmMNJSc2AvF+VT46dMRYjoP95YLSUCN0CBXE4NqnzFwikxEWNxkhHr5IVSmuonItjH0WClJkvDo7KH49St78cWRAtx5TRjiQzyuviKRFaq8eAFnjuxGTU4yXErSEF53CuHSpVYHEudLgSjSxcEUNA4+QychNGYMYlX8Z4qIegf/NbFisYPc8Jv4IHySdg5rvjyB/yyZCEmS5C6LqEMmoxFnMw+h5MQeIH8//PRHEWrKR1zLhSSgVqiRq46B3mc0nCISERp3HYJ9AhAsV+FENOAx9Fi5h6YPwZfphTh4tgJbjxbiV3GBcpdEZEFfUYYzR3ajOjsZ2pKDCKs7gTDUtjqQ+Jzkj0JdHEyDxsE75lqEDh2L4bxbORH1I4YeK+en0+C+6yLx4reZWPf1KUwd6geNAw/aJHmYjEbkZx1FyfHdEPn74VuZjhBjPkZIlnezadqLEw2992g4hSciOG4ygvyCECRT3UREAEOPTbhncjg+2n8W58ov4V8/5eG+6648n4Wob1RVXkTekT2ozv4JzsVpCKs7gVDUWB5ILAEFkh8KXEfAGDgWXkMnIXToOAx3tI8bBhOR7WDosQHOjio8PH0I/vzJEbz6XRZ+MyYI3i78QKHeJUwmnMs+iqLje2DK3w/f8iMINZ5ptRenTjggx3EIKr1HQdO8FyfQPwT84pWIrB1Dj42YN3oQNv6Ui2Pn9Vj/bSbWzB0hd0lk42qqKpB75AdUZf0E5+KDCLl0AsGosjyQWAIK4YMC1xFoCBwLzyHXImx4AobxhpxEZIMYemyEQiHhsdnDMP+f+/DR/nzckRiGKD9XucsiGyFMJpzPOYHC4z/AdDYF3hXpCGvMRewVe3EMwgG5jlGo8BoNdXgCgkdMQUBgKAJkqpuIqDcx9NiQCRFemD7cD9uPF+P/vjqJjYvGy10SWana6krkpv8I/em9cCo+iJDa4wiC3vJAYgkogjfOu8SiIXAsPKKvQfiIiYjhXhwiGqAYemzMX2YOxXenSvB9xgX8kHkBk6N95C6JZCZMJhTkZaDw2G4Yz6bAq/wIwhpzMVwyWSxXL1TIdRiMcq9RcAidgKC4yfAPioS/THUTEfU3hh4bE+6txe8Sw/D23lw8s/UkrhnsDaWCFyy0J3W11chJ3wt95o9QF6UhuPY4BqECg1ouJAEl8MQ5l1jUB4yFe/NenCEa3sONiOwXQ48N+uP1g/Fp2jlkFFfh3wfycdv4ELlLoj4iTCYUnj2NgmO7YTyTAs/yIwhryMEwyWixXL1QIs8hEhc9R8EhNAGDRlwHv6BI+CoUMlVORGR9GHpskLuzI5YlReGvX57A37/JwK9HBsJFzZdyIKi7VIO89B9RcfpHOBamIbjmGAJRbnk6uASUwh352lgYAsbCPeoahI2YiGhnF7nKJiKyCfyktFG/nRCK9/edQW5pDV7flYWHp8fIXRJ1Q1F+Fs4f3Y2GvH3wvHgYYQ3ZiLliL06DUCLPIQIXPUZCGZqAwNjrEBASBW/uxSEi6hKGHhvlqFJg1cwYLH4/DRv25OK28SEI8uDxGtbMUFeL3KM/oSLzRzgWHkBQ9TH446LlgcQSUAY3nHUejjr/sXCLmojwuGsRpeXlCYiIeoqhx4b9cpgfJkR4Yl/ORfxtewb+MX+03CVRCyXnc3EufRfq81LgXnYYEQ2nESM1WizTKBTIU4WjzGMklCEJCIi9DoFhQ+DFvThERL2OoceGSVLTBQt//cpefH64AHdODMPoEA+5y7JL9YY65B3fh4un9sCh4AAGVR+DP0rh23IhCSiHDmech+OSXzx0g69B+MhrMdjFDYPlKpyIyI4w9Ni42EFuuCk+CJ+mncOarSfx6X2JkCSewt7XSgvOIP/oLhhyU+BWdgjh9acRLTVYLGMUEvJUYSh1HwlFSAIChk/GoIhh8OBeHCIiWTD0DAAPTRuCremFSDtTjq+OFmF2HG8a0Jsa6g3IO56CslN74VCQisCqowjABXi3XEgCKuCCM07DUesXD9fBExEWNwmROg9EylU4ERFZYOgZAPzdNLj3ugis//Y01m07iaShvtA4KOUuy2aVFuUjP3036nKT4VZ6GOH1mYiS6hHVYhmTkHBGGYoS9zhIwePhP3wSggfHYST34hARWS2GngFi8eQIfLT/LPIvXsK7P+Xh3uu4f6EzGhvqkXdiP8pO7YXyfCoCqo5ikChutRdHDy3yNMNQ4zcGLpETETZyEsLdPBEuV+FERNRlDD0DhLOjCg9Pj8FDnxzBK99l4TdjguDlopa7LKtzseQ8zqb/gEs5P0FXegjhhkwMlgwWBxKbhISzymCUuDXtxfEdNgnBUSMRp+TeMyIiW8bQM4DcOHoQ/vVTLo6d1+MfO0/jr3Ni5S5JVo0N9Thz8gBKT+2F4nwqAvRHESQK4dlyIQnQwxl5mqGo8YmHy+CJCImbjDAPb4TJVDcREfUNhp4BRKGQ8OisYbhtwz5sSjmL3yWGYrCv/VzUrqK0CGfSd6E2ex90Fw4i3HAKkZKh1YHEZxTBKNaNAJr34oREj+ZeHCIiO8DQM8AkRnph2jA/fHOiGP/31Sm8c+c4uUvqE8bGRpw5lYYLJ/dAcS4V/vp0BIsCuLdcSAKqhRNyNTGo8YmHU2QiwuImI9TLD6Ey1U1ERPJh6BmAVs0aiu9OleC7UyXYc/oCJkX5yF1St+krynAh/zT0hVkwlOYBFWehrcxEeN0pREiXEHHF8vlSIIp0cTAFjYfvsGsRMmQMRqj4Z05ERAw9A1K4txa/SwzDOz/m4pmtJ7H1T95QKqzzgoVVlRebQ0026kpzgYqzUFefg2tdIXyNRdChBrq2VpSAGqFBriYGVd6j4Rw5AaFxUxDs7Y/g/h4EERHZBIaeAepPSYPxn4PncKqoCp8cyMf88SGy1FGtL8eF/NOoLMxG3YWmUONYfQ66ugJ4G4vhjmpc7aijcuhQqvJDlSYA9S7BkLwi4D1kIkKHjkWsg2O/jIOIiGwfQ88A5e7siD8lReHpL0/g+W8y8auRgXBR9/7LXVNVgQvnslBZkIW6C7kQ5WfgWH0ers2hxgNVcLlKH+VwRanSD1WaQNS7DILkEQq1TzjcAwfDJ2gwPFzdwTuKERFRTzH0DGC3TwjF+8l5yCurxRu7svHQ9CFd7qO2uhIX8rNQUZiNugs5EOVn4VidD9e6Qng3FsMDemiv0kcFXFCq9INeE4h6lyDAPQQan3DoAiPhGxQFD50HQw0REfU5hp4BzFGlwKpZQ3Hv+2nYsCcHtyWEYJC7k8UydbVVKD57ujnU5EKU58Gx6hxc6grh3VgET+gRCnR4tlMltLig9EeVJgCGy6HGOxy6gEh4B0fB3c3T8qwqIiIiGTD0DHDThvlhQpg71Gd3Y/u/fsRQp0o4Vp2Fa10BvBqL4YXKq4YaPbS4oPSDXv1zqFF7h0EXMBjewVFwc/eCW38NiIiIqJsYegY4SZLw2K+GI2LDPDhXGICK1stUCSeUqPyvCDXh0PlHwDs4Gm4e3m2fQUVERGRDGHrsQGyQO874XYPy6jrUaQcB7iFwbA41PsHR0Hl4w1WyzlPaiYiIegtDj50I/cNnvAoxERHZNUVPVl63bh0kScLy5cvNbffeey8iIyPh5OQEHx8fzJkzB6dOneqwHyEEnnjiCQQEBMDJyQlTp07F6dOne1IaERERkYVuh57U1FS8+eabiIuLs2gfM2YMNm7ciJMnT2L79u0QQmDatGkwGo3t9vXcc8/hpZdewhtvvIGUlBRotVpMnz4ddXV13S2PiIiIyIIkhBBdXam6uhrx8fF47bXXsGbNGowaNQrr169vc9n09HSMHDkSWVlZiIy88n7XTXt5AgMD8ec//xkPPfQQAKCyshJ+fn7417/+hfnz51+1Hr1eDzc3N1RWVkKn4yG3REREtqC/P7+7tadn6dKlmD17NqZOndrhcjU1Ndi4cSPCw8MRHNz2HZFyc3NRVFRk0ZebmxsSEhKQnJzc5joGgwF6vd5iIiIiIupIl0PP5s2bcfDgQaxdu7bdZV577TW4uLjAxcUFX3/9NXbs2AFHx7bvkVRUVAQA8PPzs2j38/Mzz7vS2rVr4ebmZp7aC1REREREl3Up9OTn52PZsmXYtGkTNBpNu8stXLgQhw4dwu7duxEdHY1bbrmlV4/PWbVqFSorK81Tfn5+r/VNREREA1OXTllPS0tDSUkJ4uPjzW1GoxE//PADXnnlFRgMBiiVSvMemKioKEyYMAEeHh747LPPcNttt7Xq09/fHwBQXFyMgIAAc3txcTFGjRrVZh1qtRpqtborpRMREZGd61LoSUpKwtGjRy3aFi1ahJiYGKxcuRJKpbLVOkIICCFgMBja7DM8PBz+/v7YuXOnOeTo9XqkpKRgyZIlXSmPiIioXwkhUNtYi4uXLqKsrqxputT083KbzlGHpyY+JXephC6GHldXV8TGxlq0abVaeHl5ITY2Fjk5Ofj4448xbdo0+Pj44Ny5c1i3bh2cnJwwa9Ys8zoxMTFYu3Yt5s2bZ77Oz5o1axAVFYXw8HA8/vjjCAwMxNy5c3tlkERERJ1lEiboDXpzgLlYd9Hy8eVQ0/y4ztjx4Rv+Wv9+qpyuplevyKzRaLBnzx6sX78e5eXl8PPzw+TJk/HTTz/B19fXvFxGRgYqKyvNz1esWIGamhosXrwYFRUVuPbaa7Ft27YOjxsiIrJHQghUGipRWFNonopqilBUU4TCmkJcqL0AlUIFrYMWWgctXBxc4OzgDBcHF3Nby6nVfEcttCotlIrWe+5tWYOpAeV15Z0KMeV15WgUjV3q30nlBE+NJ7ycvJp+arzMj/2c/a7eAfWLbl2nx9rwOj1ENFDUG+tRXFPcKtS0fHyp8VKf1+GkcoKzyhkuji7mn1rVz6Ho8s/25rs4NoWpvgxQlxovtRtcrnxcaai8eodX0Dnq2gwxXk5e8NJYPnZ2cO6DEQ58/f35zXtvERH1EyEEyg3lTeGluqjNYFN6qbRTfXlqPBGgDUCANgD+Wv+mxy4B8HX2hdFkRHVDNWobalHdUI2ahppWU1vzqxuq0Whq2sNxqfFSU6ioK+vxuJ1UTm3uZdI6tB+gnFXOqG6otgwxlyz30NQ21napDqWkhIfGo1MhxlPjCQelQ4/HTtaFoYeIqJfUNdahuLZ5L0116z00hTWFMBjbPqmjJbVSbRlmLj92aXrs5+wHjapvvv6vN9a3G4quFpqunH9lgOpsoOsKR4WjOah0GGKcPOGudodC6tEtJ8nGMfQQEXWCSZhwse4iCqvbPpamsKYQF+sudqovbyfvVqEmQBsAf5em5x5qD0iS1Mcjapuj0hGOSkd4aDx63Fe9sb7boam2oRZaB23bIabFV05aB61svyuyPQw9RGR3hBAQaLqchgkmCCHQYGpAcW1xu187FdUUocHUcNW+nVRObX7tFKANgL+zP/y0fnBUtn2F+oHGUekIT6UnPDWecpdCBIChh2xUWx9aJmGCSZgANP2v/HL75WVM4uflWq5rEiZAoM1lrvzZcjstn7da9srttKznimXaar/82LwcWrebx3nldnGV7bexTEfbaVUz2th+y3Xa2U5Hr01HNbb7u+igljbXveL16g4JEnycfSz3zlwRbHSOOu55ILJSDD0DnMFowBn9GeRW5qLsUhlMwgSjMLb902Q0f/CYTK3nt1qnnWXa3cZV+mzzcTvrdPdDi6gjzipnBLoEtj6WpsVBwg4KHtxKZKsYegaI8rpy5FTmILcy12I6X32eAaGZBAkKSQEJEiSp6fHlgxoVkgIKKMztFstAAUiWy1zuSyE1r3O5vfmxRb9XLtNy3RbbablMR7W03E7LZTrcTovnHdV4ZW1d+X2Z+265zuXtSDA/brf2K7Zj8btB57bTapxtvGbtvX4KSQEnlRP30hANYAw9NsRoMuJ89fmfQ43+53BTYahodz1XB1eEu4fDz9kPKkkFhUIBpaSEQvr55+WprXalQtnmvJY/JUn6+Xknlr+yBov1r7J8qw/lTnyIX/5wJCIi+8XQY4VqG2otAs3l6Yz+TIcHUgZqAxHuHo5wXTjC3X6evDRe/MAnIiK7x9AjEyEELly6YA40Lb+aKq4tbnc9tVKNMF2YRagJdwtHqC4UTiqnfhwBERGRbWHo6WMNxgbkV+W3Pt5Gn4uahpp21/PUeP4capr33ES4RyBAG8CLaxEREXUDQ08vqTRUtjrWJq8yD/lV+TAKY5vrKCQFgl2DW30dFe4WDje1Wz+PgIiIaGBj6OkCkzChsKaw1bE2OZU5HV6JVeugbTPYBLsG281FyoiIiOTG0NOBqvoqvH/ifYsDieuMde0u7+fs1yrYhOvC4evsywOJiYiIZMbQ0wGlpMTrR163aHNQOCBUF4pwt3DzAcUR7hEI04VB66CVqVIiIiK6GoaeDjg7OOOOYXfA28nbvOcm0CUQKgV/bURERLaGn95X8dC4h+QugYiIiHoBz30mIiIiu8DQQ0RERHaBoYeIiIjsAkMPERER2QWGHiIiIrILDD1ERERkFxh6iIiIyC4w9BAREZFdYOghIiIiu8DQQ0RERHaBoYeIiIjsAkMPERER2QWGHiIiIrILA+Iu60IIAIBer5e5EiIiIuqsy5/blz/H+9qACD1VVVUAgODgYJkrISIioq6qqqqCm5tbn29HEv0Vr/qQyWRCQUEBXF1dIUlSr/at1+sRHByM/Px86HS6Xu27P3Ec1oXjsD4DZSwch3XhODomhEBVVRUCAwOhUPT9ETcDYk+PQqFAUFBQn25Dp9PZ9B/sZRyHdeE4rM9AGQvHYV04jvb1xx6ey3ggMxEREdkFhh4iIiKyCww9V6FWq/Hkk09CrVbLXUqPcBzWheOwPgNlLByHdeE4rMuAOJCZiIiI6Gq4p4eIiIjsAkMPERER2QWGHiIiIrILDD1ERERkF6wm9Kxduxbjxo2Dq6srfH19MXfuXGRkZFgsU1dXh6VLl8LLywsuLi646aabUFxcbJ5/5MgR3HbbbQgODoaTkxOGDh2Kf/zjH+1u88cff4RKpcKoUaOuWp8QAk888QQCAgLg5OSEqVOn4vTp0xbL3HDDDXB3d4dCoYBCoYBGo8GMGTM6HIdWq0VwcDAiIiKgUCiwfPnyVuMICgpCcHAw3N3dodVqMWrUKLz//vs2N46Wr8fmzZshSRLmzp1rc+MIDAyEJEkWk0ajsblxDB06FOvWrcPSpUsREBAAtVqN6OhofPXVV302jpCQEKhUKjg4OMDBwQHe3t4dvtc9PT3h4OAAFxcXSJKE5cuXA7B8ryuVylavhyRJmD17tk2+JvPmzcOQIUPg5OSE4OBgPPDAA6irq7OpccTExGDmzJmIjIyERqPByJEjsW3bNqt6PZycnODr6wsvLy/odDokJibi9ddfb/V6/OY3v0FYWBg0Gg0SEhKwf/9+mxtHaGgohg8fbv63a8uWLRb99dV7XaPRICAgALfffjsKCgo67Pe///0vfvnLX8LHx8c8ju3bt1ss05mc0JkBWIXp06eLjRs3imPHjonDhw+LWbNmiZCQEFFdXW1e5r777hPBwcFi586d4sCBA2LChAli4sSJ5vlvv/22+NOf/iR27dolsrOzxfvvvy+cnJzEyy+/3Gp75eXlIiIiQkybNk2MHDnyqvWtW7dOuLm5iS1btogjR46IG264QYSHh4tLly6Zl3nhhRdEQkKC+Nvf/ibef/99ERcXJ9zd3TscxxdffCH8/f3F4MGDxahRo8SyZctajeORRx4Rjo6O4tFHHxVZWVli/fr1QqlUim3bttnUOC6/Hk899ZQYNGiQmDRpkpgzZ47NvR733HOPACCeeeYZUVhYKAoLC0VRUZHNjWPjxo1CoVCIYcOGib1794rc3Fyxa9cucfjw4T4bR3Jyspg8ebJ45JFHxMiRI0VcXFyH7/VNmzaJ+fPni8jISKHVasWyZcuEEJbv9bS0NPHyyy8LjUYjnnnmGXHs2DGhVCrFxo0bbe41WbJkiQAg7rjjDpGbmyu2b98uAgICxAMPPGBT45g9e7aQJEncd999Ijs7W7z22mtCo9GIgwcPWs045s+fL0JCQkRcXJzIzMwUq1atEkqlUtx2223mcSxdulQAEAsXLhTHjx8X99xzj3B3dxfFxcU2NY6HHnpIqFQqcffddwsA4rPPPjP31Zfv9by8PPHjjz+KxMREkZiY2GG/y5YtE88++6zYv3+/eRwODg7i4MGD5mU6kxOuxmpCz5VKSkoEALF7924hhBAVFRXCwcFBfPLJJ+ZlTp48KQCI5OTkdvv5wx/+IH7xi1+0ar/11lvFY489Jp588smrvtAmk0n4+/uLv/3tb+a2iooKoVarxUcffdTuep9//rkA0OlxjB492vyP+tXGMXr0aPHYY4/Z3DiWLFkidDqdeOutt8Qdd9xhDj22NI6NGzcKR0dHm/+7ev3114VOpxNTpkyRbRySJInz5893eiy33HJLu/1dfo+8+OKLwtXV1fwPoS29JkuXLhWDBg2y+Nt68MEHxTXXXGNT4wgICBCTJk2yGMeNN94oFi5caJXjuPwZMmzYMLF69Wrz/PHjx4vY2FjzOIxGowgMDBRr1661qXEI8fP748rQ05/v9fr6+g77v1Jb42jpypzQGVbz9daVKisrAQCenp4AgLS0NDQ0NGDq1KnmZWJiYhASEoLk5OQO+7ncx2UbN25ETk4OnnzyyU7Vkpubi6KiIottu7m5ISEhod1tX7x4EZs2bUJ8fHynx6HX6686DiEEdu7ciYyMDFy6dMnmxrF37164uLjgrrvuMrfZ4uvR0NCAffv2ITg4GHPmzMHx48dtbhxffPEFPD09cebMGfj5+SE2Nhb/93//h7fffrvfxjFx4kTU1tZ2aixqtRqFhYXt1nH5PfL2229j/vz50Gq1NveaTJw4ESUlJebnOTk5+Oqrr+Dn52dT4zAYDKivr7f4t9fJyQnbtm2zynEkJyfDZDKhqqrKvHx9fT3S0tLg6elpblMoFJg6dSo+/vhjmxnHZXJ/Fk6cOBEODg6d2g6AdsfR0pU5oTOsMvSYTCYsX74c11xzDWJjYwEARUVFcHR0hLu7u8Wyfn5+KCoqarOfn376CR9//DEWL15sbjt9+jT+8pe/4IMPPoBK1bn7rV7u38/P76rbXrlyJbRaLby8vHDmzBl4eXl1ehz19fUdjuPLL7+Eo6MjZs+ejcceewzvv/++TY3j9ddfx9GjR7F+/XpzW3V1tc29HvX19VAoFPj73/+ODz74ACaTCQkJCVixYoVNjeP48ePIy8szH8fz+OOP47nnnsOyZcv6ZRxnz57FZ5991un3uqOjozkgXenye2Ty5Mk4duwY7r77bpt8r4eFhcFoNOKHH36Ag4MDIiMjMWrUKOzdu9emxhEfH4+UlBTMnj0bJpMJO3bswKeffoqysjKrHEdRURGef/55VFdX45ZbbgEAlJaWwmg04scff7T4DHF0dMSxY8dsZhyA/J+FZ8+exeeff96pbVzW1jhaaisndIZVhp6lS5fi2LFj2Lx5c7f7OHbsGObMmYMnn3wS06ZNAwAYjUYsWLAAq1evRnR0dJvrbdq0CS4uLuZpz549Xdruww8/jEOHDuGbb77BmTNnsHfvXnz00UcAABcXF/z+979HfX097rvvvi6N44knnsCxY8eQmpqKp59+Go8//jgWLlxoM+NISUnB/fffj9tvvx0333wzgKY/2rS0NJt7PR599FE89dRTWLJkCa677jp88sknaGxsxLhx42xqHOfPn4dOp8PWrVsxZswY/OY3v4FOp4NSqeyXcSiVSowdO9b8Xr/c5+9//3s0NjZ2us+W7/Xjx49jxIgRGDNmjE2+12fNmgUnJye88cYbOHjwID755BP85z//QUJCgk2N49ChQ4iJicHdd98NR0dHLF26FDqdDiqVyirHceLECaxevRr//ve/4evrCwA4deoUAOD3v/+9xWfIl19+iaCgIJsZhzV8FiqVSvzud7+DaL4BRMt+2xrHhx9+2GocV+p2TujSF2z9YOnSpSIoKEjk5ORYtO/cuVMAEOXl5RbtISEh4oUXXrBoO378uPD19RWPPPKIRXt5ebkAIJRKpXmSJMnctnPnTqHX68Xp06fNU21trcjOzhYAxKFDhyz6mzx5svjTn/7U7jgCAgIEAPHTTz8JIYQ4ffq0eO+99wQAkZmZ2WockZGRFt+PX20ckiTZzDg8PT1b/e7R/F11y3ZrH8dAeT18fX1FcHCwSEpKajWO/ng9hBDijjvuEADEp59+ah5Hy7Fc+V5Xq9Vi0qRJFm0tX5Pq6mqh0+nE+vXrbfa9HhQUJB566CFZXpO+eI9cunRJnDt3Tly8eNFqx+Ht7S0cHBzEl19+2WockiS1OujXWt/rHY2j5b9ZAMQHH3zQb+8PIYTIz89vNY7LU3FxscWyH330kXBycrIYR1u/m7ZyQmdYTegxmUxi6dKlIjAwsNWLKcTPB29d/gdSCCFOnTrV6kDmY8eOCV9fX/Hwww+36sNoNIqjR49aTEuWLBFDhgwRR48ebfcI8MsHbz3//PPmtsrKyjYP3mo5jl27dgkA4vvvv+/UOFoeFHi1ccydO1eMHTvWZsbxwAMPtPrd33DDDWL8+PHiv//9rzh48KBNjKOt16O+vl6EhYWJ22+/3WZej4cfflisWrVKhIaGCqPRKIRo+rtauXKl8Pb27rNxtByLn59fq3FcbSwtD2S+8jXZuHGjUKvVorS01Gbf6/Hx8WLFihXm5Y1Go3j22WeFWq0Whw8ftplxXKmurk4EBQWJu+++26pej+eff14AEM8++6y5reU4xo8fL+6//37zvIaGBuHr6yuWLVtmU+NoCYD4z3/+0+fvj5bOnDnT5nv9Sh9++KHQaDRiy5Yt7W6/o5zQGVYTepYsWSLc3NzErl27zKcBFxYWitraWvMy9913nwgJCRHfffedOHDgQKvT4I4ePSp8fHzEb3/7W4s+SkpK2t1uZ45YF6LpND13d3fx+eefi/T0dDFnzhyL0/T27dsnXn75ZXHzzTcLV1dX8cILL4ixY8eK0NBQkZeX1+E44uLiRFxcnBgzZoxYsGCB+OSTT4Snp6d5HKtWrRKbN28W+/fvFydOnBDPP/+8UKlUYsOGDTY1jitfj5Znb9nSOB566CHx0Ucfif3794u0tDQxf/58odFoxPHjx21qHAcOHBBarVbcddddIiMjQ3z55ZfC19dXrFmzps/GcejQIfHb3/5WaLVaMXz4cPM4Onqvb9q0ScTFxQmtVisWLFggDh06JLZs2dLqvT5+/PhWf08t2cJr8uc//1lotVrx5ptvipycHPHNN9+IyMhIi7BnC+PYunWreOutt8T+/fvFDz/8IK6//noRHh5usfdO7nGsWbNGABDh4eHmv6Hvv/9eeHt7m8fxxhtvCEdHR/HSSy+JEydOiMWLFwt3d3fzJSpsZRxZWVlix44d5m9MXnjhBXHo0CFx5syZPhvHoUOHRF5enti5c6eYOHGiiIyMFHV1de32u2nTJqFSqcSrr75q8XlRUVFhXqYzOeFqrCb0tPyqo+V0+VobQjTtKv3DH/4gPDw8hLOzs5g3b54oLCw0z3/yySfb7CM0NLTd7Xb2hTaZTOLxxx8Xfn5+Qq1Wi6SkJJGRkWGen56ebj4dsKvjaG+dtiYPDw+RmJgoNm/ebLPjuPx69CT0WMM4AAg/Pz8xa9Ysi2tJ2No4HB0dhVqtFhEREeKZZ54RjY2NfTaOy19zdmUsbS3r5ubW7uvRHlt6TVQqldBoNCI4OFj84Q9/6FZYsIZxABBeXl7i9ttvF+fPn7eq10OhUHR6DEqlUjg6Oorx48eLffv22ew4rpzuuOOOPhuHp6enUKvVIiwsTNx3333i3LlzHfZ73XXXXbXGzvxurkZq7oiIiIhoQLPKs7eIiIiIehtDDxEREdkFhh4iIiKyCww9REREZBcYeoiIiMguMPQQERGRXWDoISIiIrvA0ENERER2gaGHiIiI7AJDDxEREdkFhh4iIiKyCww9REREZBf+H4Oz6EQsDvAfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cv_df.iloc[:7]['ds'], cv_df.iloc[:7]['y'])\n",
    "plt.plot(cv_df.iloc[7:]['ds'], cv_df.iloc[7:]['y'])\n",
    "plt.plot(cv_df.iloc[:7]['ds'], cv_df.iloc[:7]['AutoNHITS-median'])\n",
    "plt.plot(cv_df.iloc[7:]['ds'], cv_df.iloc[7:]['AutoNHITS-median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ddd417-a364-4cce-b2b4-eb611b98a897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
